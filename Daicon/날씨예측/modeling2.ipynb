{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6abe3c-5ba9-4c03-b87a-38aa7727e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer, roc_auc_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from prophet.diagnostics import cross_validation\n",
    "import joblib\n",
    "# import optuna\n",
    "# import xgboost as xgb\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import performance_metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba51056-c8ce-45e5-b4c6-c0f34a5c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_changer(data):\n",
    "    data = data.rename(columns = {\"y\": \"평균기온\", \"월\":\"months\"})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fccfb2-efdb-47a7-b19f-88dbfc27ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./prep_data.csv')\n",
    "data.ds = pd.to_datetime(data.ds)\n",
    "data = data.rename(columns = {\"평균기온\":\"y\"})\n",
    "data['days'] = data.ds.dt.day\n",
    "data['years'] = data.ds.dt.year\n",
    "summit_form = pd.read_csv('./sample_submission.csv')\n",
    "regressors = [x for x in data.columns if x != \"y\" and x != \"ds\"]\n",
    "data = y_changer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e012a8fd-83c1-4a80-a167-95db8626a1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['최고기온', '최저기온', '일교차', '강수량', '평균습도', '평균풍속', '일조합', '일사합', '일조율',\n",
       "       '평균기온', 'months', 'ds', 'days', 'years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fa2c01-e16d-4143-a05c-fa5376ecff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"평균기온\",'일교차', '일조합','ds'], axis = 1)\n",
    "y = data.평균기온"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3deb52b7-419f-43f5-a801-ae32b1b879b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y[365:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb37dc3f-c5bc-452e-8408-0f041ece52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X[:-365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27883f85-5f5a-4f81-9825-0e0bf04e3dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46261533-8970-4281-aece-07db1f2f7f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22646"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbfbf420-22d2-4173-82d4-f69cd69a9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_new[:-365], X_new[-365:]\n",
    "y_train, y_test = y_new[:-365], y_new[-365:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "452de06e-f648-47c9-8db9-3e78d979041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>최고기온</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>강수량</th>\n",
       "      <th>평균습도</th>\n",
       "      <th>평균풍속</th>\n",
       "      <th>일사합</th>\n",
       "      <th>일조율</th>\n",
       "      <th>months</th>\n",
       "      <th>days</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22281</th>\n",
       "      <td>1.6</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.61</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>67.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22282</th>\n",
       "      <td>-1.4</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.18</td>\n",
       "      <td>38.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11.34</td>\n",
       "      <td>93.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22283</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>56.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22284</th>\n",
       "      <td>0.3</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>7.44</td>\n",
       "      <td>47.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22285</th>\n",
       "      <td>-2.1</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.46</td>\n",
       "      <td>88.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22641</th>\n",
       "      <td>-3.9</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.09</td>\n",
       "      <td>39.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22642</th>\n",
       "      <td>-0.9</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>0.66</td>\n",
       "      <td>73.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.32</td>\n",
       "      <td>17.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22643</th>\n",
       "      <td>5.9</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>72.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.64</td>\n",
       "      <td>18.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22644</th>\n",
       "      <td>0.2</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.14</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22645</th>\n",
       "      <td>-3.9</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>0.23</td>\n",
       "      <td>35.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>11.70</td>\n",
       "      <td>93.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       최고기온  최저기온   강수량  평균습도  평균풍속    일사합   일조율  months  days  years\n",
       "22281   1.6  -9.8  0.61  64.0   2.0   9.54  67.7     1.0     1   2021\n",
       "22282  -1.4  -8.4  0.18  38.5   2.6  11.34  93.8     1.0     2   2021\n",
       "22283  -2.0  -9.1  0.09  45.0   2.0   8.80  56.7     1.0     3   2021\n",
       "22284   0.3  -8.4  0.00  51.4   1.7   7.44  47.4     1.0     4   2021\n",
       "22285  -2.1  -9.9  0.00  52.8   2.9  10.46  88.7     1.0     5   2021\n",
       "...     ...   ...   ...   ...   ...    ...   ...     ...   ...    ...\n",
       "22641  -3.9 -12.9  0.00  60.9   1.7   6.09  39.6    12.0    27   2021\n",
       "22642  -0.9  -8.5  0.66  73.8   2.2   4.32  17.7    12.0    28   2021\n",
       "22643   5.9  -3.8  0.20  72.9   2.6   4.64  18.8    12.0    29   2021\n",
       "22644   0.2  -6.8  0.00  48.5   3.3   9.14  76.0    12.0    30   2021\n",
       "22645  -3.9  -8.8  0.23  35.9   3.5  11.70  93.8    12.0    31   2021\n",
       "\n",
       "[365 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ca669b4-bdb4-4b9a-a3cd-eb77599600c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: OrderedDict([('colsample_bytree', 0.8780741118210806), ('gamma', 0), ('learning_rate', 0.12473347174963892), ('max_depth', 8), ('n_estimators', 456), ('subsample', 0.6080385860401739)])\n",
      "Cross-Validation Score: 2.758964698078302\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 탐색 범위 정의\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 1.00, 'uniform'),\n",
    "    'max_depth': (3, 12),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'subsample': (0.10, 1.00, 'uniform'),\n",
    "    'colsample_bytree': (0.10, 1.00, 'uniform'),\n",
    "    'gamma': (0, 1.0, 'uniform'),\n",
    "}\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "# BayesSearchCV를 사용하여 베이지안 최적화 수행\n",
    "opt = BayesSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter=50,  # 반복 횟수\n",
    "    cv=5,  # 교차 검증 폴드 수\n",
    "    n_jobs=1,  # 병렬 처리를 위한 CPU 코어 수 (-1은 모든 가능한 코어 사용)\n",
    ")\n",
    "\n",
    "# 최적의 하이퍼파라미터로 모델 학습\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Parameters:\", opt.best_params_)\n",
    "\n",
    "# 최적의 모델 평가 (여기서는 교차 검증 점수 출력)\n",
    "print(\"Cross-Validation Score:\", -opt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61127148-e98b-403e-973d-a11144e1fb32",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesSearchCV' object has no attribute 'best_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4532\\3156724161.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BayesSearchCV' object has no attribute 'best_estimators'"
     ]
    }
   ],
   "source": [
    "opt.best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0db83069-a70d-44a9-86c6-5b825dac87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b727619f-3614-4425-ad10-7fd852c02a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict(X_test)\n",
    "\n",
    "mean_absolute_error(y_test, pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae0b0ea9-0200-4bff-9034-08e102826585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_label(data, labels, label):\n",
    "\n",
    "    # X = data.drop([\"평균기온\",'일교차', '일조합','ds', label], axis = 1)\n",
    "    X = data[labels].drop([label], axis = 1)\n",
    "    y = data[label]\n",
    "    \n",
    "    return X, y \n",
    "\n",
    "def train_test_data(X,y):\n",
    "    \n",
    "    X_train, X_test = X[:-365], X[-365:]\n",
    "    y_train, y_test = y[:-365], y[-365:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def make_model(X_train, y_train):\n",
    "    \n",
    "    # 하이퍼파라미터 탐색 범위 정의\n",
    "    param_space = {\n",
    "        'learning_rate': (0.01, 1.00, 'uniform'),\n",
    "        'max_depth': (3, 12),\n",
    "        'n_estimators': (100, 1000),\n",
    "        'subsample': (0.10, 1.00, 'uniform'),\n",
    "        'colsample_bytree': (0.10, 1.00, 'uniform'),\n",
    "        'gamma': (0, 1.0, 'uniform'),\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_jobs = -1, random_state=42)\n",
    "\n",
    "    # BayesSearchCV를 사용하여 베이지안 최적화 수행\n",
    "    opt = BayesSearchCV(\n",
    "        model,\n",
    "        param_space,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_iter=50,  # 반복 횟수\n",
    "        cv=5,  # 교차 검증 폴드 수\n",
    "        # n_jobs=1,  # 병렬 처리를 위한 CPU 코어 수 (-1은 모든 가능한 코어 사용)\n",
    "    )\n",
    "\n",
    "    # 최적의 하이퍼파라미터로 모델 학습\n",
    "    opt.fit(X_train, y_train)\n",
    "\n",
    "    # 최적의 하이퍼파라미터 출력\n",
    "    print(\"Best Parameters:\", opt.best_params_)\n",
    "\n",
    "    # 최적의 모델 평가 (여기서는 교차 검증 점수 출력)\n",
    "    print(\"Cross-Validation Score:\", -opt.best_score_)\n",
    "    \n",
    "    return opt\n",
    "    \n",
    "\n",
    "def socoring(opt, y_test, X_test):\n",
    "    \n",
    "    pred = opt.best_estimator_.predict(X_test)\n",
    "\n",
    "    mean_absolute_error(y_test, pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    print(mae)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "def progress(data, labels):\n",
    "    \n",
    "    \n",
    "    data = data\n",
    "    \n",
    "    labels = labels\n",
    "    \n",
    "    for label in labels:\n",
    "    \n",
    "        X, y = select_label(data, labels, label)\n",
    "\n",
    "        X_train,X_test, y_train, y_test = train_test_data(X,y)\n",
    "\n",
    "        opt = make_model(X_train,y_train)\n",
    "\n",
    "        label = label + \"_model\"\n",
    "        \n",
    "        print(label)\n",
    "\n",
    "        globals()[label] = opt\n",
    "\n",
    "        mae = socoring(opt, y_test, X_test)\n",
    "\n",
    "        return print(mae)\n",
    "\n",
    "def modeling(params, X_train, y_train):\n",
    "    \n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\", **params, n_jobs = -1, random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def model_predict(data, label, params):\n",
    "    \n",
    "    data = data\n",
    "    \n",
    "    label = label\n",
    "    \n",
    "    X, y = select_label(data, label)\n",
    "    \n",
    "    X_train,X_test, y_train, y_test = train_test_data(X,y)\n",
    "    \n",
    "    model = modeling(params, X_train, y_train)\n",
    "    \n",
    "    model_pred = model.predict(X_test)\n",
    "    \n",
    "    return model_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e2c305a-349b-487c-b463-84ca47dcebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tmp = dict([('colsample_bytree', 0.7489488665614384), ('gamma', 0), ('learning_rate', 0.2303112080128232), ('max_depth', 3), ('n_estimators', 1000), ('subsample', 1.0)])\n",
    "high_tmp = dict([('colsample_bytree', 0.785843038567719), ('gamma', 1), ('learning_rate', 0.01), ('max_depth', 3), ('n_estimators', 1000), ('subsample', 0.36837214707260824)])\n",
    "low_tmp = dict([('colsample_bytree', 0.9307064570326005), ('gamma', 0), ('learning_rate', 0.01), ('max_depth', 5), ('n_estimators', 1000), ('subsample', 1.0)])\n",
    "avg_hum = dict([('colsample_bytree', 1.0), ('gamma', 0), ('learning_rate', 0.011022102502535366), ('max_depth', 4), ('n_estimators', 1000), ('subsample', 0.11499728444446672)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d52b54c4-8f3d-457e-bc59-503eea3f6169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7489488665614384,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.2303112080128232,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 1000,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f859ee6e-2495-4431-8075-361864c7eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: OrderedDict([('colsample_bytree', 0.7489488665614384), ('gamma', 0), ('learning_rate', 0.2303112080128232), ('max_depth', 3), ('n_estimators', 1000), ('subsample', 1.0)])\n",
      "Cross-Validation Score: 0.39732766430568645\n",
      "0.3690247294970164\n",
      "0.3690247294970164\n",
      "Best Parameters: OrderedDict([('colsample_bytree', 0.785843038567719), ('gamma', 1), ('learning_rate', 0.01), ('max_depth', 3), ('n_estimators', 1000), ('subsample', 0.36837214707260824)])\n",
      "Cross-Validation Score: 0.39090319278662566\n",
      "0.3763858020795535\n",
      "0.3763858020795535\n",
      "Best Parameters: OrderedDict([('colsample_bytree', 0.9307064570326005), ('gamma', 0), ('learning_rate', 0.01), ('max_depth', 5), ('n_estimators', 1000), ('subsample', 1.0)])\n",
      "Cross-Validation Score: 0.3902358750681939\n",
      "0.37210015173235994\n",
      "0.37210015173235994\n",
      "Best Parameters: OrderedDict([('colsample_bytree', 1.0), ('gamma', 0), ('learning_rate', 0.011022102502535366), ('max_depth', 4), ('n_estimators', 1000), ('subsample', 0.11499728444446672)])\n",
      "Cross-Validation Score: 0.38985762876514507\n",
      "0.37554962341916076\n",
      "0.37554962341916076\n"
     ]
    }
   ],
   "source": [
    "labels = [\"평균기온\", \"최고기온\", \"최저기온\", \"평균습도\"]\n",
    "for label in labels :\n",
    "    progress(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9382f0e6-5e77-41d2-963d-1e2d6d6902d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('colsample_bytree', 1.0), ('gamma', 0), ('learning_rate', 0.01), ('max_depth', 3), ('n_estimators', 1000), ('subsample', 1.0)])\n",
      "OrderedDict([('colsample_bytree', 1.0), ('gamma', 1), ('learning_rate', 0.219519027392961), ('max_depth', 8), ('n_estimators', 1000), ('subsample', 0.5209965334687984)])\n",
      "OrderedDict([('colsample_bytree', 1.0), ('gamma', 0), ('learning_rate', 0.01), ('max_depth', 5), ('n_estimators', 978), ('subsample', 0.6873473201351862)])\n",
      "OrderedDict([('colsample_bytree', 1.0), ('gamma', 0), ('learning_rate', 0.011022102502535366), ('max_depth', 4), ('n_estimators', 1000), ('subsample', 0.11499728444446672)])\n"
     ]
    }
   ],
   "source": [
    "print(최고기온_model.best_params_)\n",
    "print(최저기온_model.best_params_)\n",
    "print(평균습도_model.best_params_)\n",
    "print(평균기온_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9298418a-77c9-4ac1-854c-ed8ce127ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = {\"최고기온\" : high_tmp, \"최저기온\" : low_tmp, \"평균습도\" : avg_hum}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "65514b13-a2b2-4ab1-bd44-0cbaae0951ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.785843038567719, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.36837214707260824}\n",
      "{'colsample_bytree': 0.9307064570326005, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 1.0}\n",
      "{'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.011022102502535366, 'max_depth': 4, 'n_estimators': 1000, 'subsample': 0.11499728444446672}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = select_label(data, labels, \"평균기온\")\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_data(X,y)\n",
    "\n",
    "base_m = modeling(avg_tmp, X_train, y_train)\\\n",
    "\n",
    "for k,v in label_dic.items() :\n",
    "    \n",
    "    X1, y1 = select_label(data, labels, k)\n",
    "    \n",
    "    X_train1,X_test1, y_train1, y_test1 = train_test_data(X1,y1)\n",
    "    \n",
    "    print(v)\n",
    "    \n",
    "    m = modeling(v, X_train1, y_train1)\n",
    "    \n",
    "    X_test[k] = m.predict(X_test1)\n",
    "    \n",
    "\n",
    "# y_pred = base_m.predict(X_test)\n",
    "\n",
    "# mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "# print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d0303ae-2844-44a5-abbd-57f0d73a7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8153716568097678\n"
     ]
    }
   ],
   "source": [
    "y_pred = base_m.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfd18f-1d6f-4a14-ae98-918992074452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a411e63a-77d8-47e5-8fd2-1f7d397cfc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>최고기온</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>평균습도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22646</th>\n",
       "      <td>-0.155919</td>\n",
       "      <td>-8.238092</td>\n",
       "      <td>60.601475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22647</th>\n",
       "      <td>3.271398</td>\n",
       "      <td>-5.182496</td>\n",
       "      <td>56.391415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22648</th>\n",
       "      <td>2.114505</td>\n",
       "      <td>-5.983513</td>\n",
       "      <td>57.746731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22649</th>\n",
       "      <td>2.158552</td>\n",
       "      <td>-6.311744</td>\n",
       "      <td>54.248131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22650</th>\n",
       "      <td>1.312312</td>\n",
       "      <td>-6.560971</td>\n",
       "      <td>55.886009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23006</th>\n",
       "      <td>1.562991</td>\n",
       "      <td>-6.547873</td>\n",
       "      <td>54.769093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23007</th>\n",
       "      <td>1.144488</td>\n",
       "      <td>-6.849960</td>\n",
       "      <td>56.458641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008</th>\n",
       "      <td>1.172052</td>\n",
       "      <td>-6.911513</td>\n",
       "      <td>56.207546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009</th>\n",
       "      <td>2.602852</td>\n",
       "      <td>-5.330601</td>\n",
       "      <td>57.111187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23010</th>\n",
       "      <td>3.258527</td>\n",
       "      <td>-4.911651</td>\n",
       "      <td>60.328079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           최고기온      최저기온       평균습도\n",
       "22646 -0.155919 -8.238092  60.601475\n",
       "22647  3.271398 -5.182496  56.391415\n",
       "22648  2.114505 -5.983513  57.746731\n",
       "22649  2.158552 -6.311744  54.248131\n",
       "22650  1.312312 -6.560971  55.886009\n",
       "...         ...       ...        ...\n",
       "23006  1.562991 -6.547873  54.769093\n",
       "23007  1.144488 -6.849960  56.458641\n",
       "23008  1.172052 -6.911513  56.207546\n",
       "23009  2.602852 -5.330601  57.111187\n",
       "23010  3.258527 -4.911651  60.328079\n",
       "\n",
       "[365 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3748f8e-6537-46b5-ad60-d168bda3f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = select_label(data, labels, \"평균기온\")\n",
    "\n",
    "# X_train,X_test, y_train, y_test = train_test_data(X,y)\n",
    "X_test = pd.DataFrame()\n",
    "\n",
    "base_m = modeling(avg_tmp, X, y)\n",
    "\n",
    "for k,v in label_dic.items() :\n",
    "    \n",
    "    X1, y1 = select_label(data, labels, k)\n",
    "    \n",
    "    # X_train1,X_test1, y_train1, y_test1 = train_test_data(X1,y1)\n",
    "    \n",
    "    print(v)\n",
    "    \n",
    "    m = modeling(v, X1, y1)\n",
    "    \n",
    "    X_test[k] = m.predict(X_test1)\n",
    "    \n",
    "\n",
    "# y_pred = base_m.predict(X_test)\n",
    "\n",
    "# mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "# print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5069e637-fbb5-415e-bcd8-420b9e7e1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_select_label(data, labels, label):\n",
    "    \n",
    "    X = data[[\"years\", \"months\", \"days\"]]\n",
    "    y = data[label]\n",
    "    \n",
    "    return X, y \n",
    "\n",
    "def train_test_data(X,y, level):\n",
    "    \n",
    "    X_train, X_test = X[:-level], X[-level:]\n",
    "    y_train, y_test = y[:-level], y[-level:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def progress(data, labels):\n",
    "    \n",
    "    \n",
    "    data = data\n",
    "    \n",
    "    labels = labels\n",
    "    \n",
    "    for label in labels:\n",
    "    \n",
    "        X, y = select_label(data, labels, label)\n",
    "\n",
    "        X_train,X_test, y_train, y_test = train_test_data(X,y)\n",
    "\n",
    "        opt = make_model(X_train,y_train)\n",
    "\n",
    "        label = label + \"_model\"\n",
    "        \n",
    "        print(label)\n",
    "\n",
    "        globals()[label] = opt\n",
    "    \n",
    "def make_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # 하이퍼파라미터 탐색 범위 정의\n",
    "    param_space = {\n",
    "        'learning_rate': (0.0001, 0.1, 'uniform'),\n",
    "        'max_depth': (3, 12),\n",
    "        'n_estimators': (100, 3000),\n",
    "        'subsample': (0.10, 1.00, 'uniform'),\n",
    "        'colsample_bytree': (0.10, 1.00, 'uniform'),\n",
    "        'gamma': (0, 10.0, 'uniform'),\n",
    "        'eval_set' : [(X_test, y_test)]\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\", eval_metric='mae', n_jobs = -1, random_state=42)\n",
    "\n",
    "    # BayesSearchCV를 사용하여 베이지안 최적화 수행\n",
    "    opt = BayesSearchCV(\n",
    "        model,\n",
    "        param_space,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_iter=50,  # 반복 횟수\n",
    "        cv=5,  # 교차 검증 폴드 수\n",
    "        n_jobs=1,  # 병렬 처리를 위한 CPU 코어 수 (-1은 모든 가능한 코어 사용)\n",
    "    )\n",
    "    \n",
    "    # 최적의 하이퍼파라미터로 모델 학습\n",
    "    opt.fit(X_train, y_train)\n",
    "\n",
    "    # 최적의 하이퍼파라미터 출력|\n",
    "    print(\"Best Parameters:\", opt.best_params_)\n",
    "\n",
    "    # 최적의 모델 평가 (여기서는 교차 검증 점수 출력)\n",
    "    print(\"Cross-Validation Score:\", -opt.best_score_)\n",
    "    \n",
    "    return opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a94e521b-7d87-4cdc-a1b6-7defa6c8c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['최고기온', '최저기온', '일교차', '강수량', '평균습도', '평균풍속', '일조합', '일사합', '일조율',\n",
       "       '평균기온', 'months', 'ds', 'days', 'years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "377d3ea1-80dd-41b3-b47a-3ee35447502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\",\"일사합\", \"일조율\", \"강수량\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec4003b9-cf1f-43bc-a3cf-013e3135e850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21916</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21917</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21918</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21919</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21920</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23006</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23007</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23010</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       years  months  days\n",
       "21916   2020       1     2\n",
       "21917   2020       1     3\n",
       "21918   2020       1     4\n",
       "21919   2020       1     5\n",
       "21920   2020       1     6\n",
       "...      ...     ...   ...\n",
       "23006   2022      12    27\n",
       "23007   2022      12    28\n",
       "23008   2022      12    29\n",
       "23009   2022      12    30\n",
       "23010   2022      12    31\n",
       "\n",
       "[1095 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "368c7d13-c058-47ae-ba95-d0bfb164f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['months'] = X['months'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23c30844-5fb0-46ee-8a80-6228d8dfca33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_data(X,y, 1095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b25c4a6-4dce-4d89-9959-790bec88ea5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model_opt(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    X_train = X_train\n",
    "    y_train = y_train\n",
    "    X_test = X_test\n",
    "    y_test = y_test\n",
    "    \n",
    "    \n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'mae',\n",
    "            'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.1, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1.0),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300)\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "        predictions = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        return mae\n",
    "\n",
    "\n",
    "\n",
    "    # Optuna 베이지안 최적화를 사용하여 파라미터 튜닝 실행\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    # 최적의 파라미터 출력\n",
    "    print('Best trial:')\n",
    "    print('  Value: {}'.format(study.best_trial.value))\n",
    "    print('  Params: ')\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))\n",
    "        \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a542899-0dc3-475a-9f47-9afe94fb8762",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:57:23,182] A new study created in memory with name: no-name-b300644d-95a8-4278-9f63-0c90383d4a93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:57:23,434] Trial 0 finished with value: 8.578939764815377 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 8.578939764815377.\n",
      "[I 2023-12-26 15:57:23,573] Trial 1 finished with value: 8.742557395691197 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 0 with value: 8.578939764815377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:57:23,778] Trial 2 finished with value: 9.972721559271966 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 0 with value: 8.578939764815377.\n",
      "[I 2023-12-26 15:57:24,293] Trial 3 finished with value: 4.736537847823747 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:24,413] Trial 4 finished with value: 8.661733107719247 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 3 with value: 4.736537847823747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:57:24,808] Trial 5 finished with value: 15.886512465629405 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:33,944] Trial 6 finished with value: 12.753835635250562 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:34,192] Trial 7 finished with value: 14.39645875421289 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:34,626] Trial 8 finished with value: 5.335223742013279 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:35,383] Trial 9 finished with value: 17.053237812813013 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:35,862] Trial 10 finished with value: 5.36755045202769 and parameters: {'booster': 'gbtree', 'lambda': 0.0059279800152147654, 'alpha': 0.5705541732383875, 'max_depth': 10, 'subsample': 0.5522780959073166, 'colsample_bytree': 0.3529613975730607, 'learning_rate': 0.08308860966122086, 'n_estimators': 219}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:36,412] Trial 11 finished with value: 5.3971728643363335 and parameters: {'booster': 'gbtree', 'lambda': 1.133353977171156e-08, 'alpha': 4.286903479306445e-05, 'max_depth': 6, 'subsample': 0.9399284834163196, 'colsample_bytree': 0.6913604664348699, 'learning_rate': 0.06167020181123221, 'n_estimators': 174}. Best is trial 3 with value: 4.736537847823747.\n",
      "[I 2023-12-26 15:57:36,851] Trial 12 finished with value: 4.120780708638772 and parameters: {'booster': 'gbtree', 'lambda': 1.1552904638878947e-08, 'alpha': 1.7326467047416007e-08, 'max_depth': 3, 'subsample': 0.7153268197860511, 'colsample_bytree': 0.987005007454463, 'learning_rate': 0.03604182605436954, 'n_estimators': 174}. Best is trial 12 with value: 4.120780708638772.\n",
      "[I 2023-12-26 15:57:37,382] Trial 13 finished with value: 5.612746780648079 and parameters: {'booster': 'gbtree', 'lambda': 1.9266437161286105e-05, 'alpha': 1.1134445656355971e-08, 'max_depth': 3, 'subsample': 0.6859142228544353, 'colsample_bytree': 0.1026918590516594, 'learning_rate': 0.028961603572682054, 'n_estimators': 225}. Best is trial 12 with value: 4.120780708638772.\n",
      "[I 2023-12-26 15:57:37,758] Trial 14 finished with value: 3.3069527658697675 and parameters: {'booster': 'gbtree', 'lambda': 0.9375038170603618, 'alpha': 0.5125424925605241, 'max_depth': 3, 'subsample': 0.41476871750718386, 'colsample_bytree': 0.9688041514589095, 'learning_rate': 0.03661206023497895, 'n_estimators': 143}. Best is trial 14 with value: 3.3069527658697675.\n",
      "[I 2023-12-26 15:57:39,423] Trial 15 finished with value: 3.293456353488034 and parameters: {'booster': 'dart', 'lambda': 3.404731677920906e-07, 'alpha': 0.024882938540769794, 'max_depth': 3, 'subsample': 0.635052734611574, 'colsample_bytree': 0.9931505519983992, 'learning_rate': 0.03743309561243859, 'n_estimators': 128}. Best is trial 15 with value: 3.293456353488034.\n",
      "[I 2023-12-26 15:57:41,036] Trial 16 finished with value: 11.992427013628015 and parameters: {'booster': 'dart', 'lambda': 2.971149161396231e-07, 'alpha': 0.047117837012289915, 'max_depth': 4, 'subsample': 0.4508877590689758, 'colsample_bytree': 0.9795500444483756, 'learning_rate': 0.004362597510446986, 'n_estimators': 121}. Best is trial 15 with value: 3.293456353488034.\n",
      "[I 2023-12-26 15:57:44,817] Trial 17 finished with value: 3.224749384579593 and parameters: {'booster': 'dart', 'lambda': 0.004164772880107863, 'alpha': 0.09512809197951652, 'max_depth': 3, 'subsample': 0.6195156721989623, 'colsample_bytree': 0.8316773921712752, 'learning_rate': 0.04223100011762775, 'n_estimators': 200}. Best is trial 17 with value: 3.224749384579593.\n",
      "[I 2023-12-26 15:57:45,334] Trial 18 finished with value: 3.1143804206151398 and parameters: {'booster': 'dart', 'lambda': 0.0038731263135072095, 'alpha': 0.0012985436721082472, 'max_depth': 5, 'subsample': 0.9061604145189801, 'colsample_bytree': 0.8146006285512841, 'learning_rate': 0.0996295217058502, 'n_estimators': 200}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:57:45,970] Trial 19 finished with value: 3.1301541074879093 and parameters: {'booster': 'dart', 'lambda': 0.004097122794454539, 'alpha': 0.0007773719805212235, 'max_depth': 5, 'subsample': 0.9116827872988783, 'colsample_bytree': 0.771524478825641, 'learning_rate': 0.09420095408245553, 'n_estimators': 254}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:57:46,806] Trial 20 finished with value: 3.2782380101071102 and parameters: {'booster': 'dart', 'lambda': 0.0032718874813048465, 'alpha': 0.0009226553537561671, 'max_depth': 5, 'subsample': 0.9921494765292398, 'colsample_bytree': 0.7280950265211468, 'learning_rate': 0.09936106821457055, 'n_estimators': 274}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:57:47,997] Trial 21 finished with value: 3.259215950138493 and parameters: {'booster': 'dart', 'lambda': 0.006843288301831139, 'alpha': 0.0005727675440051244, 'max_depth': 5, 'subsample': 0.8596688871783933, 'colsample_bytree': 0.8184434410390575, 'learning_rate': 0.06180447478148859, 'n_estimators': 199}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:57:48,600] Trial 22 finished with value: 3.1717463069256038 and parameters: {'booster': 'dart', 'lambda': 0.0009488228287163314, 'alpha': 0.003253679858154362, 'max_depth': 6, 'subsample': 0.8405651638077337, 'colsample_bytree': 0.7815757868347001, 'learning_rate': 0.09543541435020143, 'n_estimators': 252}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:57:49,268] Trial 23 finished with value: 3.1621478455741654 and parameters: {'booster': 'dart', 'lambda': 0.00010907223409670967, 'alpha': 0.0035842130921358373, 'max_depth': 6, 'subsample': 0.8713684580708427, 'colsample_bytree': 0.75326741104541, 'learning_rate': 0.09986031210637725, 'n_estimators': 254}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:57:56,405] Trial 24 finished with value: 4.062965853911012 and parameters: {'booster': 'dart', 'lambda': 4.799516869546045e-05, 'alpha': 0.0002719711920064683, 'max_depth': 7, 'subsample': 0.9061435647083985, 'colsample_bytree': 0.6410508986715179, 'learning_rate': 0.058801048672904865, 'n_estimators': 255}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:07,145] Trial 25 finished with value: 12.392902120585855 and parameters: {'booster': 'dart', 'lambda': 0.03171105893322408, 'alpha': 1.1627162336786306e-05, 'max_depth': 5, 'subsample': 0.9616041292750489, 'colsample_bytree': 0.9071945701386377, 'learning_rate': 0.002255327060436387, 'n_estimators': 300}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:15,070] Trial 26 finished with value: 7.3207859458498765 and parameters: {'booster': 'dart', 'lambda': 0.00012926542536540554, 'alpha': 0.004398118104221483, 'max_depth': 6, 'subsample': 0.8494472369324885, 'colsample_bytree': 0.450933074488428, 'learning_rate': 0.020155222519084887, 'n_estimators': 251}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:16,165] Trial 27 finished with value: 3.3458700183156416 and parameters: {'booster': 'dart', 'lambda': 0.031008363341048614, 'alpha': 0.00014477664559588697, 'max_depth': 7, 'subsample': 0.9997137522100932, 'colsample_bytree': 0.759350942735353, 'learning_rate': 0.07793263639778783, 'n_estimators': 274}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:21,071] Trial 28 finished with value: 5.86087404830815 and parameters: {'booster': 'dart', 'lambda': 0.00018100995613234408, 'alpha': 0.001826637884996049, 'max_depth': 4, 'subsample': 0.9076059375551829, 'colsample_bytree': 0.6278217422559684, 'learning_rate': 0.04862258520014812, 'n_estimators': 199}. Best is trial 18 with value: 3.1143804206151398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:58:21,438] Trial 29 finished with value: 8.54847924097488 and parameters: {'booster': 'gblinear', 'lambda': 0.0006413367340583174, 'alpha': 0.00797599808377965, 'max_depth': 4, 'subsample': 0.7893440336797639, 'colsample_bytree': 0.9070907786915121, 'learning_rate': 0.07460523160570239, 'n_estimators': 237}. Best is trial 18 with value: 3.1143804206151398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:58:21,867] Trial 30 finished with value: 8.556253026152309 and parameters: {'booster': 'gblinear', 'lambda': 0.0010159350564142003, 'alpha': 6.310267690620994e-05, 'max_depth': 5, 'subsample': 0.726805962077857, 'colsample_bytree': 0.8688558741520077, 'learning_rate': 0.026671597072497975, 'n_estimators': 274}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:22,528] Trial 31 finished with value: 3.148890851774172 and parameters: {'booster': 'dart', 'lambda': 0.00135595079702644, 'alpha': 0.0015678521908078758, 'max_depth': 6, 'subsample': 0.8582599381302772, 'colsample_bytree': 0.7565565987717684, 'learning_rate': 0.09614756803317727, 'n_estimators': 251}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:23,281] Trial 32 finished with value: 3.151634813895509 and parameters: {'booster': 'dart', 'lambda': 0.0016862303044139573, 'alpha': 0.00031432252704294755, 'max_depth': 6, 'subsample': 0.8982409036506349, 'colsample_bytree': 0.7302601131820358, 'learning_rate': 0.09489977062911092, 'n_estimators': 212}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:25,973] Trial 33 finished with value: 3.250259233620613 and parameters: {'booster': 'dart', 'lambda': 0.01509573748271799, 'alpha': 2.0245047978388288e-05, 'max_depth': 5, 'subsample': 0.9293399301988327, 'colsample_bytree': 0.6985331074445218, 'learning_rate': 0.049328976385313125, 'n_estimators': 207}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:32,969] Trial 34 finished with value: 3.969868262788476 and parameters: {'booster': 'dart', 'lambda': 0.0012295926693498232, 'alpha': 0.00022731228213720723, 'max_depth': 7, 'subsample': 0.7920144414749759, 'colsample_bytree': 0.6172834968476596, 'learning_rate': 0.06933368073537434, 'n_estimators': 236}. Best is trial 18 with value: 3.1143804206151398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:58:33,269] Trial 35 finished with value: 8.610555701930773 and parameters: {'booster': 'gblinear', 'lambda': 0.0022493864404703233, 'alpha': 0.0013348616862954956, 'max_depth': 8, 'subsample': 0.8228053163746516, 'colsample_bytree': 0.8963799654700655, 'learning_rate': 0.010318541029835177, 'n_estimators': 188}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:40,272] Trial 36 finished with value: 4.522096368101635 and parameters: {'booster': 'dart', 'lambda': 0.013750776009991954, 'alpha': 0.00029540397536568635, 'max_depth': 6, 'subsample': 0.8899830333834201, 'colsample_bytree': 0.5079461827856991, 'learning_rate': 0.0493805608252111, 'n_estimators': 237}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:41,500] Trial 37 finished with value: 3.233967479265988 and parameters: {'booster': 'dart', 'lambda': 0.14657286899354768, 'alpha': 5.896426185511481e-06, 'max_depth': 5, 'subsample': 0.9543667064579991, 'colsample_bytree': 0.7918793048211766, 'learning_rate': 0.07646040886198147, 'n_estimators': 216}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:50,277] Trial 38 finished with value: 3.1313803518634953 and parameters: {'booster': 'dart', 'lambda': 0.00038493580282604657, 'alpha': 0.1072878037181065, 'max_depth': 4, 'subsample': 0.28847788105641814, 'colsample_bytree': 0.8610582572041792, 'learning_rate': 0.019021704405993094, 'n_estimators': 269}. Best is trial 18 with value: 3.1143804206151398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:58:50,746] Trial 39 finished with value: 8.56646868283346 and parameters: {'booster': 'gblinear', 'lambda': 2.046290913871177e-06, 'alpha': 0.12851530584176235, 'max_depth': 4, 'subsample': 0.49214556069796767, 'colsample_bytree': 0.8556764954655459, 'learning_rate': 0.017566152589312507, 'n_estimators': 286}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:58:58,678] Trial 40 finished with value: 5.372605993410224 and parameters: {'booster': 'dart', 'lambda': 0.00040315143776353514, 'alpha': 0.017668117082479666, 'max_depth': 4, 'subsample': 0.3021952781275219, 'colsample_bytree': 0.9292427422651659, 'learning_rate': 0.006789207414959893, 'n_estimators': 262}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:03,148] Trial 41 finished with value: 3.980854759564683 and parameters: {'booster': 'dart', 'lambda': 0.002029956340394691, 'alpha': 0.0009371758744869081, 'max_depth': 5, 'subsample': 0.28860515133196235, 'colsample_bytree': 0.7307617069617117, 'learning_rate': 0.013350965416551952, 'n_estimators': 188}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:09,701] Trial 42 finished with value: 9.217077547055945 and parameters: {'booster': 'dart', 'lambda': 5.0131302753635196e-05, 'alpha': 5.959656954603991e-07, 'max_depth': 4, 'subsample': 0.11031582841402213, 'colsample_bytree': 0.8007661523483176, 'learning_rate': 0.0034452688829377204, 'n_estimators': 238}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:12,325] Trial 43 finished with value: 4.300959841306896 and parameters: {'booster': 'dart', 'lambda': 0.06911901503638601, 'alpha': 0.2336422091877532, 'max_depth': 6, 'subsample': 0.20195263863712798, 'colsample_bytree': 0.5783625383552642, 'learning_rate': 0.08431383991436557, 'n_estimators': 285}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:19,915] Trial 44 finished with value: 3.2940098806929914 and parameters: {'booster': 'dart', 'lambda': 0.01065753170783096, 'alpha': 0.00011551516272152067, 'max_depth': 5, 'subsample': 0.7567077131736557, 'colsample_bytree': 0.6687526408915216, 'learning_rate': 0.029472653556678316, 'n_estimators': 266}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:21,579] Trial 45 finished with value: 3.179039185760228 and parameters: {'booster': 'dart', 'lambda': 0.0002664818743817848, 'alpha': 2.849388361253184e-05, 'max_depth': 6, 'subsample': 0.6352318399816724, 'colsample_bytree': 0.8542768788585439, 'learning_rate': 0.0634174626935207, 'n_estimators': 159}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:24,209] Trial 46 finished with value: 3.2939207287357273 and parameters: {'booster': 'dart', 'lambda': 0.0005850943487956709, 'alpha': 0.00867702899500909, 'max_depth': 7, 'subsample': 0.8268623195763647, 'colsample_bytree': 0.9334832717670536, 'learning_rate': 0.05181578014339375, 'n_estimators': 219}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:25,058] Trial 47 finished with value: 3.1708190675848695 and parameters: {'booster': 'dart', 'lambda': 2.7513978916395636e-05, 'alpha': 0.0005270597328063876, 'max_depth': 4, 'subsample': 0.2376602317239644, 'colsample_bytree': 0.7376641920326662, 'learning_rate': 0.08651147508247185, 'n_estimators': 244}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:32,614] Trial 48 finished with value: 4.651123380922291 and parameters: {'booster': 'dart', 'lambda': 0.002328794383748738, 'alpha': 0.041548782472926114, 'max_depth': 7, 'subsample': 0.32227714397070545, 'colsample_bytree': 0.701103442048724, 'learning_rate': 0.009416867348962635, 'n_estimators': 228}. Best is trial 18 with value: 3.1143804206151398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 15:59:33,060] Trial 49 finished with value: 8.55979156598653 and parameters: {'booster': 'gblinear', 'lambda': 0.06584886447616096, 'alpha': 8.76966689405391e-08, 'max_depth': 8, 'subsample': 0.6811875687369611, 'colsample_bytree': 0.7750685386561074, 'learning_rate': 0.021900478054360267, 'n_estimators': 287}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:37,520] Trial 50 finished with value: 5.727761894992497 and parameters: {'booster': 'dart', 'lambda': 0.007187981987817156, 'alpha': 9.753138137363917e-05, 'max_depth': 6, 'subsample': 0.5156094657568786, 'colsample_bytree': 0.39717585228174856, 'learning_rate': 0.041272017747729775, 'n_estimators': 185}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:38,197] Trial 51 finished with value: 3.1483740429355676 and parameters: {'booster': 'dart', 'lambda': 0.0001143062576642723, 'alpha': 0.0019033627351361488, 'max_depth': 6, 'subsample': 0.8827496062932537, 'colsample_bytree': 0.817406164067789, 'learning_rate': 0.09976364307290461, 'n_estimators': 265}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:39,823] Trial 52 finished with value: 3.2292544906106713 and parameters: {'booster': 'dart', 'lambda': 0.00029763375524296534, 'alpha': 0.00840905136167595, 'max_depth': 5, 'subsample': 0.960301783792206, 'colsample_bytree': 0.823210640331267, 'learning_rate': 0.06990477080023458, 'n_estimators': 265}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:40,679] Trial 53 finished with value: 3.2691664335226904 and parameters: {'booster': 'dart', 'lambda': 9.036587384673965e-06, 'alpha': 0.0018623459096481563, 'max_depth': 6, 'subsample': 0.8864102754775427, 'colsample_bytree': 0.9421090076525394, 'learning_rate': 0.08727935698890586, 'n_estimators': 210}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:41,071] Trial 54 finished with value: 6.174282980626576 and parameters: {'booster': 'gbtree', 'lambda': 5.6616677828258496e-05, 'alpha': 0.0004728854592530943, 'max_depth': 5, 'subsample': 0.9278262491913557, 'colsample_bytree': 0.8594513037451019, 'learning_rate': 0.09782469536761698, 'n_estimators': 226}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:42,720] Trial 55 finished with value: 3.2009009567787654 and parameters: {'booster': 'dart', 'lambda': 0.0011603580437779754, 'alpha': 0.002407194614341223, 'max_depth': 6, 'subsample': 0.7628642341299812, 'colsample_bytree': 0.8169050484165089, 'learning_rate': 0.056797044756227814, 'n_estimators': 247}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:43,618] Trial 56 finished with value: 3.1791615176091996 and parameters: {'booster': 'dart', 'lambda': 0.003980363489560052, 'alpha': 0.0010325600092300575, 'max_depth': 7, 'subsample': 0.8180475655404418, 'colsample_bytree': 0.6699868320765818, 'learning_rate': 0.07015406532680965, 'n_estimators': 279}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 15:59:54,006] Trial 57 finished with value: 4.65429956447044 and parameters: {'booster': 'dart', 'lambda': 0.0005273352689027158, 'alpha': 0.04137917027242144, 'max_depth': 5, 'subsample': 0.9749867611715602, 'colsample_bytree': 0.26163447321289823, 'learning_rate': 0.04395282877396858, 'n_estimators': 295}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:00,069] Trial 58 finished with value: 3.2506851118666944 and parameters: {'booster': 'dart', 'lambda': 0.00018049366333188605, 'alpha': 0.005090160961937676, 'max_depth': 5, 'subsample': 0.8685702437696357, 'colsample_bytree': 0.7627528747880793, 'learning_rate': 0.03237776761212337, 'n_estimators': 260}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:00,582] Trial 59 finished with value: 6.699981015115024 and parameters: {'booster': 'gbtree', 'lambda': 8.534642266742174e-05, 'alpha': 0.00020842947167217627, 'max_depth': 9, 'subsample': 0.9245910660802852, 'colsample_bytree': 0.7218018458681651, 'learning_rate': 0.09871059512529337, 'n_estimators': 227}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:03,945] Trial 60 finished with value: 12.761286726803538 and parameters: {'booster': 'dart', 'lambda': 2.2806468997510293e-05, 'alpha': 0.7431389738242418, 'max_depth': 6, 'subsample': 0.3901805961091301, 'colsample_bytree': 0.887326147446885, 'learning_rate': 0.002782894526757019, 'n_estimators': 156}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:05,228] Trial 61 finished with value: 3.256590097282575 and parameters: {'booster': 'dart', 'lambda': 0.00012848979529919168, 'alpha': 0.00276425256769512, 'max_depth': 6, 'subsample': 0.8769185248983613, 'colsample_bytree': 0.7543139316959773, 'learning_rate': 0.08158234242968075, 'n_estimators': 256}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:06,907] Trial 62 finished with value: 3.2803964298119825 and parameters: {'booster': 'dart', 'lambda': 0.0018267224689189178, 'alpha': 0.000498863970585946, 'max_depth': 6, 'subsample': 0.8560612671926437, 'colsample_bytree': 0.8367282535850312, 'learning_rate': 0.06280580203014255, 'n_estimators': 270}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:07,579] Trial 63 finished with value: 3.1922302960260818 and parameters: {'booster': 'dart', 'lambda': 1.1210027927417932e-05, 'alpha': 0.013952455355831296, 'max_depth': 7, 'subsample': 0.90423765076851, 'colsample_bytree': 0.7952865329440812, 'learning_rate': 0.09787913067153149, 'n_estimators': 246}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:11,780] Trial 64 finished with value: 4.304763365200121 and parameters: {'booster': 'dart', 'lambda': 2.9858138202680893e-06, 'alpha': 0.004403202981785397, 'max_depth': 6, 'subsample': 0.7949785022128251, 'colsample_bytree': 0.6078925125727362, 'learning_rate': 0.07706372635591467, 'n_estimators': 209}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:20,229] Trial 65 finished with value: 13.680033660348693 and parameters: {'booster': 'dart', 'lambda': 0.00528341425743414, 'alpha': 0.0011860265145938133, 'max_depth': 3, 'subsample': 0.7116088809826787, 'colsample_bytree': 0.7126376774250754, 'learning_rate': 0.0014046017935892556, 'n_estimators': 280}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:27,923] Trial 66 finished with value: 4.700692547837349 and parameters: {'booster': 'dart', 'lambda': 7.601859607267594e-05, 'alpha': 0.2944935297265033, 'max_depth': 5, 'subsample': 0.9875828328397959, 'colsample_bytree': 0.6621815853129421, 'learning_rate': 0.05511962301495149, 'n_estimators': 255}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:29,514] Trial 67 finished with value: 3.3799665297928465 and parameters: {'booster': 'dart', 'lambda': 0.022353732234286577, 'alpha': 0.06855817484785928, 'max_depth': 6, 'subsample': 0.9404935501040094, 'colsample_bytree': 0.7490942167281489, 'learning_rate': 0.06866360771269514, 'n_estimators': 293}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:29,658] Trial 68 finished with value: 8.567432191230392 and parameters: {'booster': 'gblinear', 'lambda': 0.0009845336037338543, 'alpha': 8.097145987148659e-05, 'max_depth': 5, 'subsample': 0.8095168797881305, 'colsample_bytree': 0.7835357666803389, 'learning_rate': 0.08576584743658038, 'n_estimators': 55}. Best is trial 18 with value: 3.1143804206151398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:00:30,179] Trial 69 finished with value: 5.210741772820416 and parameters: {'booster': 'gbtree', 'lambda': 0.00022711435768482438, 'alpha': 0.00035843433162438044, 'max_depth': 4, 'subsample': 0.841039265621709, 'colsample_bytree': 0.8774056014561427, 'learning_rate': 0.0889493302822768, 'n_estimators': 232}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:35,063] Trial 70 finished with value: 5.420742446026302 and parameters: {'booster': 'dart', 'lambda': 0.00814292603970049, 'alpha': 0.000713094386961929, 'max_depth': 7, 'subsample': 0.5850771952392998, 'colsample_bytree': 0.5293096328470425, 'learning_rate': 0.04377823687950913, 'n_estimators': 197}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:35,949] Trial 71 finished with value: 3.1176540799554626 and parameters: {'booster': 'dart', 'lambda': 2.737675543363743e-05, 'alpha': 0.001618779450902611, 'max_depth': 4, 'subsample': 0.19837499944622933, 'colsample_bytree': 0.8131866370689199, 'learning_rate': 0.08788466092752027, 'n_estimators': 243}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:36,711] Trial 72 finished with value: 3.1329585058395173 and parameters: {'booster': 'dart', 'lambda': 0.0006300401585274955, 'alpha': 0.001996970526731167, 'max_depth': 4, 'subsample': 0.15257518211507207, 'colsample_bytree': 0.8307014786947667, 'learning_rate': 0.09937989130996606, 'n_estimators': 243}. Best is trial 18 with value: 3.1143804206151398.\n",
      "[I 2023-12-26 16:00:38,411] Trial 73 finished with value: 3.087851895981183 and parameters: {'booster': 'dart', 'lambda': 0.0006717420192621094, 'alpha': 0.0014385639357021873, 'max_depth': 3, 'subsample': 0.14351385539483336, 'colsample_bytree': 0.8438339544044834, 'learning_rate': 0.06413224468950361, 'n_estimators': 241}. Best is trial 73 with value: 3.087851895981183.\n",
      "[I 2023-12-26 16:00:39,643] Trial 74 finished with value: 3.1147614931298175 and parameters: {'booster': 'dart', 'lambda': 0.0007462667354156672, 'alpha': 0.0015465538811498568, 'max_depth': 3, 'subsample': 0.1861612470476013, 'colsample_bytree': 0.9574640391412249, 'learning_rate': 0.07536308092903654, 'n_estimators': 242}. Best is trial 73 with value: 3.087851895981183.\n",
      "[I 2023-12-26 16:00:41,250] Trial 75 finished with value: 3.105517583045785 and parameters: {'booster': 'dart', 'lambda': 0.0006357129098743681, 'alpha': 0.02220855124286317, 'max_depth': 3, 'subsample': 0.15686433237349945, 'colsample_bytree': 0.9676952078706504, 'learning_rate': 0.06259224313821544, 'n_estimators': 241}. Best is trial 73 with value: 3.087851895981183.\n",
      "[I 2023-12-26 16:00:42,959] Trial 76 finished with value: 3.103545964602466 and parameters: {'booster': 'dart', 'lambda': 0.0005137057311591145, 'alpha': 0.02561479049740376, 'max_depth': 3, 'subsample': 0.15005655239207588, 'colsample_bytree': 0.9646933236800053, 'learning_rate': 0.06001040698620799, 'n_estimators': 241}. Best is trial 73 with value: 3.087851895981183.\n",
      "[I 2023-12-26 16:00:44,143] Trial 77 finished with value: 3.1081298846414644 and parameters: {'booster': 'dart', 'lambda': 0.0035009150030078013, 'alpha': 0.016002896309954058, 'max_depth': 3, 'subsample': 0.11498573484733118, 'colsample_bytree': 0.958954100967905, 'learning_rate': 0.05777243441509582, 'n_estimators': 96}. Best is trial 73 with value: 3.087851895981183.\n",
      "[I 2023-12-26 16:00:45,945] Trial 78 finished with value: 3.081674730723307 and parameters: {'booster': 'dart', 'lambda': 0.004339883738876296, 'alpha': 0.01723494204948881, 'max_depth': 3, 'subsample': 0.1088245517198344, 'colsample_bytree': 0.9589516240443191, 'learning_rate': 0.05738772771390091, 'n_estimators': 147}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:47,200] Trial 79 finished with value: 3.262334488124064 and parameters: {'booster': 'dart', 'lambda': 0.016783697518882184, 'alpha': 0.022539118205419584, 'max_depth': 3, 'subsample': 0.11714551854576995, 'colsample_bytree': 0.9657481379931351, 'learning_rate': 0.037036273210269255, 'n_estimators': 101}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:48,708] Trial 80 finished with value: 3.097375680932171 and parameters: {'booster': 'dart', 'lambda': 0.0031040183818198497, 'alpha': 0.013432391235403284, 'max_depth': 3, 'subsample': 0.15369185341097158, 'colsample_bytree': 0.9916850045935178, 'learning_rate': 0.055201559952326146, 'n_estimators': 111}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:50,171] Trial 81 finished with value: 3.105416211167427 and parameters: {'booster': 'dart', 'lambda': 0.0036369937631845033, 'alpha': 0.01262223871743478, 'max_depth': 3, 'subsample': 0.15378423115364517, 'colsample_bytree': 0.9932906665015591, 'learning_rate': 0.056391195978256745, 'n_estimators': 109}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:51,580] Trial 82 finished with value: 3.1228287556617773 and parameters: {'booster': 'dart', 'lambda': 0.003188490610450971, 'alpha': 0.012959683066110138, 'max_depth': 3, 'subsample': 0.1413271939640714, 'colsample_bytree': 0.9970040096886645, 'learning_rate': 0.053538357598855, 'n_estimators': 106}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:52,582] Trial 83 finished with value: 3.221645729117198 and parameters: {'booster': 'dart', 'lambda': 0.0029118763272936864, 'alpha': 0.02458714053261616, 'max_depth': 3, 'subsample': 0.1674437109757147, 'colsample_bytree': 0.9628270203893129, 'learning_rate': 0.04589413501142254, 'n_estimators': 85}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:54,027] Trial 84 finished with value: 3.101315158295305 and parameters: {'booster': 'dart', 'lambda': 0.005338764172290682, 'alpha': 0.006800850188947522, 'max_depth': 3, 'subsample': 0.2471907342763599, 'colsample_bytree': 0.9176353118439058, 'learning_rate': 0.06291374756844671, 'n_estimators': 107}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:55,626] Trial 85 finished with value: 3.158834292790661 and parameters: {'booster': 'dart', 'lambda': 0.00971791190930292, 'alpha': 0.007169748844703082, 'max_depth': 3, 'subsample': 0.24048537982101553, 'colsample_bytree': 0.9079490789409743, 'learning_rate': 0.039726795573485296, 'n_estimators': 114}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:57,278] Trial 86 finished with value: 3.0870939197932206 and parameters: {'booster': 'dart', 'lambda': 0.004687563084795513, 'alpha': 0.038726998040189156, 'max_depth': 3, 'subsample': 0.10052839146914938, 'colsample_bytree': 0.9216122815897864, 'learning_rate': 0.062435568694335405, 'n_estimators': 135}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:59,421] Trial 87 finished with value: 3.168383825990163 and parameters: {'booster': 'dart', 'lambda': 0.051487027899953304, 'alpha': 0.06424515208416685, 'max_depth': 3, 'subsample': 0.10211182842861274, 'colsample_bytree': 0.9223555851054249, 'learning_rate': 0.03350388595999865, 'n_estimators': 136}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:00:59,606] Trial 88 finished with value: 8.563821447712101 and parameters: {'booster': 'gblinear', 'lambda': 0.006161753584037465, 'alpha': 0.037747028851843514, 'max_depth': 3, 'subsample': 0.13662674338854994, 'colsample_bytree': 0.9757378413953696, 'learning_rate': 0.060500177787422796, 'n_estimators': 89}. Best is trial 78 with value: 3.081674730723307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:01:01,319] Trial 89 finished with value: 3.1156632215247306 and parameters: {'booster': 'dart', 'lambda': 0.28027625907731185, 'alpha': 0.20068502069095176, 'max_depth': 3, 'subsample': 0.22141190220905882, 'colsample_bytree': 0.997296106637143, 'learning_rate': 0.048889331803079056, 'n_estimators': 118}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:01,741] Trial 90 finished with value: 3.187406074358448 and parameters: {'booster': 'gbtree', 'lambda': 0.001637142484934754, 'alpha': 0.011355877777390222, 'max_depth': 3, 'subsample': 0.25983712495481504, 'colsample_bytree': 0.9469872532382082, 'learning_rate': 0.06602142434906817, 'n_estimators': 128}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:03,783] Trial 91 finished with value: 3.0976974193363973 and parameters: {'booster': 'dart', 'lambda': 0.0041362377656664374, 'alpha': 0.02976647692558114, 'max_depth': 3, 'subsample': 0.16871609840290586, 'colsample_bytree': 0.9214836894137582, 'learning_rate': 0.05530730015822604, 'n_estimators': 147}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:04,470] Trial 92 finished with value: 3.254654007828943 and parameters: {'booster': 'dart', 'lambda': 0.004871026080886143, 'alpha': 0.02971762273906285, 'max_depth': 3, 'subsample': 0.16376867000659753, 'colsample_bytree': 0.9207441821515154, 'learning_rate': 0.054888480419542016, 'n_estimators': 70}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:06,309] Trial 93 finished with value: 3.101679412763412 and parameters: {'booster': 'dart', 'lambda': 0.022083236746170447, 'alpha': 0.005834958064060414, 'max_depth': 3, 'subsample': 0.12654274253816364, 'colsample_bytree': 0.9805429233314578, 'learning_rate': 0.04926610746379222, 'n_estimators': 146}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:08,661] Trial 94 finished with value: 3.293048909810036 and parameters: {'booster': 'dart', 'lambda': 0.022424645091271705, 'alpha': 0.06426364001632734, 'max_depth': 3, 'subsample': 0.1369935003066296, 'colsample_bytree': 0.9812647465373692, 'learning_rate': 0.02662018589556322, 'n_estimators': 141}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:11,148] Trial 95 finished with value: 3.105238710473117 and parameters: {'booster': 'dart', 'lambda': 0.009069551378924618, 'alpha': 0.00523368347402128, 'max_depth': 3, 'subsample': 0.18556606596716574, 'colsample_bytree': 0.8978582955246065, 'learning_rate': 0.04697056228377408, 'n_estimators': 154}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:13,719] Trial 96 finished with value: 3.1153581097136898 and parameters: {'booster': 'dart', 'lambda': 0.040259479765675336, 'alpha': 0.006630392014049401, 'max_depth': 3, 'subsample': 0.18421098499918281, 'colsample_bytree': 0.8919150517792029, 'learning_rate': 0.03891744476647813, 'n_estimators': 149}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:16,385] Trial 97 finished with value: 3.0835460961137184 and parameters: {'booster': 'dart', 'lambda': 0.013541988088342767, 'alpha': 0.005520186130930931, 'max_depth': 3, 'subsample': 0.206539571418768, 'colsample_bytree': 0.9098653880587054, 'learning_rate': 0.04798049180131222, 'n_estimators': 167}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:18,894] Trial 98 finished with value: 3.0922887149793374 and parameters: {'booster': 'dart', 'lambda': 0.008703924768133992, 'alpha': 0.003741201959838288, 'max_depth': 3, 'subsample': 0.21049731242537592, 'colsample_bytree': 0.941696985196655, 'learning_rate': 0.049010095593885326, 'n_estimators': 171}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:22,441] Trial 99 finished with value: 3.1204749322917364 and parameters: {'booster': 'dart', 'lambda': 0.09248660482357712, 'alpha': 0.0032710595754491573, 'max_depth': 3, 'subsample': 0.20935162513461547, 'colsample_bytree': 0.9289739131679166, 'learning_rate': 0.0336934238017538, 'n_estimators': 177}. Best is trial 78 with value: 3.081674730723307.\n",
      "[I 2023-12-26 16:01:22,446] A new study created in memory with name: no-name-6f2a7e1a-3f56-42a9-89db-5077f63fe250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 3.081674730723307\n",
      "  Params: \n",
      "    booster: dart\n",
      "    lambda: 0.004339883738876296\n",
      "    alpha: 0.01723494204948881\n",
      "    max_depth: 3\n",
      "    subsample: 0.1088245517198344\n",
      "    colsample_bytree: 0.9589516240443191\n",
      "    learning_rate: 0.05738772771390091\n",
      "    n_estimators: 147\n",
      "[16:01:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:01:22,795] Trial 0 finished with value: 8.922615738785975 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 8.922615738785975.\n",
      "[I 2023-12-26 16:01:22,990] Trial 1 finished with value: 9.023102010352426 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 0 with value: 8.922615738785975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:01:23,300] Trial 2 finished with value: 8.245994966280515 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 2 with value: 8.245994966280515.\n",
      "[I 2023-12-26 16:01:24,100] Trial 3 finished with value: 4.5812735447382815 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 3 with value: 4.5812735447382815.\n",
      "[I 2023-12-26 16:01:24,264] Trial 4 finished with value: 8.997853911064531 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 3 with value: 4.5812735447382815.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:01:24,839] Trial 5 finished with value: 10.772262383900822 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 3 with value: 4.5812735447382815.\n",
      "[I 2023-12-26 16:01:36,549] Trial 6 finished with value: 8.788133454339146 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 3 with value: 4.5812735447382815.\n",
      "[I 2023-12-26 16:01:36,878] Trial 7 finished with value: 10.338348925470216 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 3 with value: 4.5812735447382815.\n",
      "[I 2023-12-26 16:01:37,425] Trial 8 finished with value: 3.440425970065811 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 8 with value: 3.440425970065811.\n",
      "[I 2023-12-26 16:01:38,348] Trial 9 finished with value: 11.289222426751977 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 8 with value: 3.440425970065811.\n",
      "[I 2023-12-26 16:01:38,831] Trial 10 finished with value: 3.366271206418129 and parameters: {'booster': 'gbtree', 'lambda': 1.116805293160088e-08, 'alpha': 1.1491548505141235e-08, 'max_depth': 3, 'subsample': 0.9786917711698019, 'colsample_bytree': 0.7598785099640686, 'learning_rate': 0.0881744100052964, 'n_estimators': 219}. Best is trial 10 with value: 3.366271206418129.\n",
      "[I 2023-12-26 16:01:39,270] Trial 11 finished with value: 3.4696410609883803 and parameters: {'booster': 'gbtree', 'lambda': 1.0690705252212232e-08, 'alpha': 1.2070660524894436e-08, 'max_depth': 3, 'subsample': 0.9759730320176591, 'colsample_bytree': 0.7541887006644162, 'learning_rate': 0.09721966993689589, 'n_estimators': 216}. Best is trial 10 with value: 3.366271206418129.\n",
      "[I 2023-12-26 16:01:39,705] Trial 12 finished with value: 3.9269131887816395 and parameters: {'booster': 'gbtree', 'lambda': 1.0800734409439694e-08, 'alpha': 1.2084903458776835e-08, 'max_depth': 5, 'subsample': 0.9614226401782306, 'colsample_bytree': 0.9969603313327517, 'learning_rate': 0.09861713308712067, 'n_estimators': 211}. Best is trial 10 with value: 3.366271206418129.\n",
      "[I 2023-12-26 16:01:40,426] Trial 13 finished with value: 2.9526984907169593 and parameters: {'booster': 'gbtree', 'lambda': 2.0388192922657925e-07, 'alpha': 1.706259095923304e-05, 'max_depth': 3, 'subsample': 0.7838038048669277, 'colsample_bytree': 0.7005210494307716, 'learning_rate': 0.04168043620362369, 'n_estimators': 257}. Best is trial 13 with value: 2.9526984907169593.\n",
      "[I 2023-12-26 16:01:41,185] Trial 14 finished with value: 4.987937021541269 and parameters: {'booster': 'gbtree', 'lambda': 3.138683976328395e-07, 'alpha': 8.307756067606911e-05, 'max_depth': 3, 'subsample': 0.8248585674355126, 'colsample_bytree': 0.37310167079970213, 'learning_rate': 0.03785128778994907, 'n_estimators': 272}. Best is trial 13 with value: 2.9526984907169593.\n",
      "[I 2023-12-26 16:01:48,126] Trial 15 finished with value: 2.7734997233244925 and parameters: {'booster': 'dart', 'lambda': 2.1265603072153366e-07, 'alpha': 2.049662341089369e-05, 'max_depth': 3, 'subsample': 0.6453278174799097, 'colsample_bytree': 0.7002281965270426, 'learning_rate': 0.03743309561243859, 'n_estimators': 251}. Best is trial 15 with value: 2.7734997233244925.\n",
      "[I 2023-12-26 16:01:56,554] Trial 16 finished with value: 2.7505788753076232 and parameters: {'booster': 'dart', 'lambda': 4.967309115990981e-07, 'alpha': 1.1565252529595718e-05, 'max_depth': 5, 'subsample': 0.6483339605894612, 'colsample_bytree': 0.6772975694400872, 'learning_rate': 0.032097864674854856, 'n_estimators': 257}. Best is trial 16 with value: 2.7505788753076232.\n",
      "[I 2023-12-26 16:02:04,635] Trial 17 finished with value: 4.791668359438578 and parameters: {'booster': 'dart', 'lambda': 3.810060579187002e-06, 'alpha': 0.0010830021735437265, 'max_depth': 5, 'subsample': 0.5899385665100871, 'colsample_bytree': 0.4488661246770967, 'learning_rate': 0.030104726916605047, 'n_estimators': 253}. Best is trial 16 with value: 2.7505788753076232.\n",
      "[I 2023-12-26 16:02:16,472] Trial 18 finished with value: 6.924716654014369 and parameters: {'booster': 'dart', 'lambda': 3.708291325818698e-05, 'alpha': 8.316324014761232e-06, 'max_depth': 6, 'subsample': 0.6648863476266121, 'colsample_bytree': 0.9121983995781024, 'learning_rate': 0.0032614736785757385, 'n_estimators': 300}. Best is trial 16 with value: 2.7505788753076232.\n",
      "[I 2023-12-26 16:02:25,433] Trial 19 finished with value: 4.2881655913727466 and parameters: {'booster': 'dart', 'lambda': 0.0021995791619433464, 'alpha': 0.00033146037128907306, 'max_depth': 4, 'subsample': 0.4793060394411144, 'colsample_bytree': 0.6478767906180384, 'learning_rate': 0.021948579761225485, 'n_estimators': 270}. Best is trial 16 with value: 2.7505788753076232.\n",
      "[I 2023-12-26 16:02:30,159] Trial 20 finished with value: 4.330399412586264 and parameters: {'booster': 'dart', 'lambda': 1.4417770804261005e-06, 'alpha': 0.061820571614202666, 'max_depth': 4, 'subsample': 0.6858899636444831, 'colsample_bytree': 0.3725700829761251, 'learning_rate': 0.04617152590010817, 'n_estimators': 195}. Best is trial 16 with value: 2.7505788753076232.\n",
      "[I 2023-12-26 16:02:35,203] Trial 21 finished with value: 2.696357644279254 and parameters: {'booster': 'dart', 'lambda': 2.7118943158339287e-07, 'alpha': 2.3146420038413365e-05, 'max_depth': 3, 'subsample': 0.6614830804785787, 'colsample_bytree': 0.6772795512490709, 'learning_rate': 0.05506492278844354, 'n_estimators': 245}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:02:42,039] Trial 22 finished with value: 3.667049855119017 and parameters: {'booster': 'dart', 'lambda': 9.496914144955819e-08, 'alpha': 0.00013670619262902436, 'max_depth': 5, 'subsample': 0.4804584707943666, 'colsample_bytree': 0.6373402075354961, 'learning_rate': 0.05601486345957135, 'n_estimators': 240}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:02:46,198] Trial 23 finished with value: 2.9647076998780304 and parameters: {'booster': 'dart', 'lambda': 1.3581766251256578e-06, 'alpha': 1.8890524613926323e-05, 'max_depth': 4, 'subsample': 0.6861073677079281, 'colsample_bytree': 0.7996825054691741, 'learning_rate': 0.025938787993020306, 'n_estimators': 186}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:02:53,628] Trial 24 finished with value: 2.7723874350878748 and parameters: {'booster': 'dart', 'lambda': 7.860840998498387e-08, 'alpha': 2.865949079049753e-07, 'max_depth': 3, 'subsample': 0.8763824591583242, 'colsample_bytree': 0.7233950469660446, 'learning_rate': 0.06343056874655129, 'n_estimators': 277}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:02:55,878] Trial 25 finished with value: 2.7984710019364205 and parameters: {'booster': 'dart', 'lambda': 6.24223377296446e-08, 'alpha': 4.661870943416507e-07, 'max_depth': 6, 'subsample': 0.8333445164552968, 'colsample_bytree': 0.8735239240183852, 'learning_rate': 0.06558312819074054, 'n_estimators': 281}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:04,715] Trial 26 finished with value: 3.3859370706778145 and parameters: {'booster': 'dart', 'lambda': 5.860683640512304e-05, 'alpha': 6.33258257372777e-08, 'max_depth': 4, 'subsample': 0.895034925199935, 'colsample_bytree': 0.628542476293521, 'learning_rate': 0.06772499713276264, 'n_estimators': 282}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:11,666] Trial 27 finished with value: 7.40810069036266 and parameters: {'booster': 'dart', 'lambda': 1.3870532788131924e-06, 'alpha': 5.231290570363208e-06, 'max_depth': 7, 'subsample': 0.4699739481646493, 'colsample_bytree': 0.4716851154530688, 'learning_rate': 0.007975730001042815, 'n_estimators': 236}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:15,830] Trial 28 finished with value: 2.926496167993981 and parameters: {'booster': 'dart', 'lambda': 1.553145755664016e-05, 'alpha': 6.887693483196176e-08, 'max_depth': 3, 'subsample': 0.8984250893884368, 'colsample_bytree': 0.7486672915784176, 'learning_rate': 0.02967338164276378, 'n_estimators': 195}. Best is trial 21 with value: 2.696357644279254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:03:16,180] Trial 29 finished with value: 8.907405308414267 and parameters: {'booster': 'gblinear', 'lambda': 0.00029500569882879256, 'alpha': 7.644478820751583e-07, 'max_depth': 4, 'subsample': 0.7345817321786307, 'colsample_bytree': 0.9175815944587455, 'learning_rate': 0.019375573524630103, 'n_estimators': 240}. Best is trial 21 with value: 2.696357644279254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:03:16,554] Trial 30 finished with value: 8.912701704817819 and parameters: {'booster': 'gblinear', 'lambda': 4.018728685909619e-08, 'alpha': 1.09463738543686e-07, 'max_depth': 5, 'subsample': 0.6024446370326497, 'colsample_bytree': 0.8296336443830068, 'learning_rate': 0.015843621490257215, 'n_estimators': 268}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:23,514] Trial 31 finished with value: 2.758396007965689 and parameters: {'booster': 'dart', 'lambda': 2.0286566733027214e-07, 'alpha': 1.573187716185152e-05, 'max_depth': 3, 'subsample': 0.640299284217978, 'colsample_bytree': 0.7123043845716917, 'learning_rate': 0.03873900728383063, 'n_estimators': 255}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:29,423] Trial 32 finished with value: 3.391086950242247 and parameters: {'booster': 'dart', 'lambda': 9.693905867399395e-07, 'alpha': 4.268656857130895e-06, 'max_depth': 3, 'subsample': 0.5079250832416703, 'colsample_bytree': 0.6039388273146725, 'learning_rate': 0.07304431031662457, 'n_estimators': 284}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:35,598] Trial 33 finished with value: 4.152518165155088 and parameters: {'booster': 'dart', 'lambda': 1.226231978702997e-07, 'alpha': 0.0001411756048559324, 'max_depth': 4, 'subsample': 0.7148322691926883, 'colsample_bytree': 0.5168974759716936, 'learning_rate': 0.049328976385313125, 'n_estimators': 233}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:42,546] Trial 34 finished with value: 2.809203158791207 and parameters: {'booster': 'dart', 'lambda': 5.077120651100082e-07, 'alpha': 2.3676178310146096e-07, 'max_depth': 3, 'subsample': 0.6270092525167726, 'colsample_bytree': 0.7207488499569661, 'learning_rate': 0.03369727662164174, 'n_estimators': 254}. Best is trial 21 with value: 2.696357644279254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:03:42,868] Trial 35 finished with value: 8.949967781659131 and parameters: {'booster': 'gblinear', 'lambda': 5.5238468211630105e-06, 'alpha': 6.99536729164675e-05, 'max_depth': 4, 'subsample': 0.5358222998684226, 'colsample_bytree': 0.5817559557433668, 'learning_rate': 0.011583444597516989, 'n_estimators': 205}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:45,055] Trial 36 finished with value: 3.6587916231917466 and parameters: {'booster': 'dart', 'lambda': 4.840025184433371e-07, 'alpha': 2.2263000053035708e-05, 'max_depth': 3, 'subsample': 0.4035476873236987, 'colsample_bytree': 0.782363073757826, 'learning_rate': 0.020265593508072763, 'n_estimators': 135}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:49,494] Trial 37 finished with value: 2.778391464491413 and parameters: {'booster': 'dart', 'lambda': 2.5471940377741464e-06, 'alpha': 1.6626549273158858e-06, 'max_depth': 5, 'subsample': 0.8792295570806835, 'colsample_bytree': 0.8561531202287447, 'learning_rate': 0.04663577813747167, 'n_estimators': 290}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:03:57,308] Trial 38 finished with value: 3.6518464318421335 and parameters: {'booster': 'dart', 'lambda': 3.277973337476607e-08, 'alpha': 0.00035850088365309074, 'max_depth': 4, 'subsample': 0.2967656002200798, 'colsample_bytree': 0.10240116514955322, 'learning_rate': 0.07253403718787586, 'n_estimators': 264}. Best is trial 21 with value: 2.696357644279254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:03:57,648] Trial 39 finished with value: 9.06116608293089 and parameters: {'booster': 'gblinear', 'lambda': 1.2754502198454099e-05, 'alpha': 0.0012623135916078553, 'max_depth': 10, 'subsample': 0.542217645738937, 'colsample_bytree': 0.5273083749209497, 'learning_rate': 0.0030839677571575822, 'n_estimators': 225}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:04:00,980] Trial 40 finished with value: 6.391006829232386 and parameters: {'booster': 'dart', 'lambda': 0.016700696572263665, 'alpha': 0.9752758280442572, 'max_depth': 8, 'subsample': 0.7401490356644511, 'colsample_bytree': 0.6663202824879513, 'learning_rate': 0.026224055761101508, 'n_estimators': 155}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:04:07,893] Trial 41 finished with value: 2.7565991882809766 and parameters: {'booster': 'dart', 'lambda': 1.92928723999216e-07, 'alpha': 2.4409293105638864e-05, 'max_depth': 3, 'subsample': 0.6706947748239668, 'colsample_bytree': 0.6997239561131928, 'learning_rate': 0.036686372147615325, 'n_estimators': 251}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:04:13,087] Trial 42 finished with value: 2.704897245832774 and parameters: {'booster': 'dart', 'lambda': 1.0545595802991335e-07, 'alpha': 4.335577788016753e-05, 'max_depth': 3, 'subsample': 0.6236866472087669, 'colsample_bytree': 0.7201409742821778, 'learning_rate': 0.050699406067411544, 'n_estimators': 243}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:04:19,687] Trial 43 finished with value: 5.244461209218795 and parameters: {'booster': 'dart', 'lambda': 6.140726371321243e-07, 'alpha': 3.43046311475468e-05, 'max_depth': 3, 'subsample': 0.6378932319220878, 'colsample_bytree': 0.6001724763521068, 'learning_rate': 0.013906178405162676, 'n_estimators': 245}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:04:22,515] Trial 44 finished with value: 2.728210296984677 and parameters: {'booster': 'dart', 'lambda': 2.6118609548393907e-08, 'alpha': 9.29108710637641e-06, 'max_depth': 4, 'subsample': 0.10130501061347807, 'colsample_bytree': 0.6960129574874557, 'learning_rate': 0.05187105158864895, 'n_estimators': 225}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:04:27,984] Trial 45 finished with value: 3.6647445314170017 and parameters: {'booster': 'dart', 'lambda': 2.503191944231215e-08, 'alpha': 2.6721599586466116e-06, 'max_depth': 4, 'subsample': 0.1678173682329781, 'colsample_bytree': 0.5455540776174475, 'learning_rate': 0.05240665078635112, 'n_estimators': 223}. Best is trial 21 with value: 2.696357644279254.\n",
      "[I 2023-12-26 16:04:29,750] Trial 46 finished with value: 2.677759704764031 and parameters: {'booster': 'dart', 'lambda': 1.598837919488034e-08, 'alpha': 8.502542039761367e-06, 'max_depth': 4, 'subsample': 0.12525903991049836, 'colsample_bytree': 0.6688506752040848, 'learning_rate': 0.07666625705408789, 'n_estimators': 229}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:04:33,067] Trial 47 finished with value: 3.6788038847544424 and parameters: {'booster': 'dart', 'lambda': 2.0497682898419813e-08, 'alpha': 8.948960514588784e-06, 'max_depth': 5, 'subsample': 0.11132379557065887, 'colsample_bytree': 0.661251571891767, 'learning_rate': 0.07872178225422614, 'n_estimators': 205}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:04:34,464] Trial 48 finished with value: 2.787570280549733 and parameters: {'booster': 'dart', 'lambda': 1.823421113702298e-08, 'alpha': 5.712401928603152e-05, 'max_depth': 6, 'subsample': 0.23804226447769633, 'colsample_bytree': 0.7788786522546599, 'learning_rate': 0.07947801312803239, 'n_estimators': 228}. Best is trial 46 with value: 2.677759704764031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:04:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:04:34,793] Trial 49 finished with value: 8.865785140381556 and parameters: {'booster': 'gblinear', 'lambda': 5.451894715687929e-08, 'alpha': 9.029739451621136e-07, 'max_depth': 5, 'subsample': 0.10945185149036214, 'colsample_bytree': 0.8200828343237969, 'learning_rate': 0.09957180453361512, 'n_estimators': 210}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:04:38,369] Trial 50 finished with value: 3.4383696404004205 and parameters: {'booster': 'dart', 'lambda': 0.7972579443245569, 'alpha': 9.027162618891873e-06, 'max_depth': 4, 'subsample': 0.21216560732169432, 'colsample_bytree': 0.4188747504269781, 'learning_rate': 0.05619816588071975, 'n_estimators': 176}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:04:45,639] Trial 51 finished with value: 2.76217751744131 and parameters: {'booster': 'dart', 'lambda': 2.2369574877231514e-07, 'alpha': 0.00019733699250361268, 'max_depth': 3, 'subsample': 0.34551038393881345, 'colsample_bytree': 0.6785082623536159, 'learning_rate': 0.0339808984789072, 'n_estimators': 262}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:04:51,444] Trial 52 finished with value: 2.787804401612173 and parameters: {'booster': 'dart', 'lambda': 1.2734608771797975e-07, 'alpha': 3.946672089048648e-05, 'max_depth': 3, 'subsample': 0.5692565738131792, 'colsample_bytree': 0.7392911735435858, 'learning_rate': 0.041984373053073405, 'n_estimators': 231}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:04:57,938] Trial 53 finished with value: 3.4776529054336898 and parameters: {'booster': 'dart', 'lambda': 1.7320833450541956e-08, 'alpha': 6.835626433903411e-06, 'max_depth': 4, 'subsample': 0.1369178589521428, 'colsample_bytree': 0.6182250565554682, 'learning_rate': 0.058209379660023625, 'n_estimators': 246}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:04:58,753] Trial 54 finished with value: 3.101342992418399 and parameters: {'booster': 'gbtree', 'lambda': 1.0261137679962073e-08, 'alpha': 2.754186559771727e-06, 'max_depth': 4, 'subsample': 0.6918015505300141, 'colsample_bytree': 0.6846968712457563, 'learning_rate': 0.028944876483688306, 'n_estimators': 247}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:05:03,856] Trial 55 finished with value: 2.7218110679872507 and parameters: {'booster': 'dart', 'lambda': 3.634329016915156e-07, 'alpha': 4.08666876172752e-05, 'max_depth': 3, 'subsample': 0.7878614464523938, 'colsample_bytree': 0.7587567665981145, 'learning_rate': 0.04602732637112893, 'n_estimators': 216}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:05:09,033] Trial 56 finished with value: 4.212203109678068 and parameters: {'booster': 'dart', 'lambda': 5.849171965717995e-08, 'alpha': 0.00326821312928751, 'max_depth': 4, 'subsample': 0.7855096057397319, 'colsample_bytree': 0.5689985743619665, 'learning_rate': 0.04457058297256509, 'n_estimators': 214}. Best is trial 46 with value: 2.677759704764031.\n",
      "[I 2023-12-26 16:05:11,871] Trial 57 finished with value: 2.670055751120119 and parameters: {'booster': 'dart', 'lambda': 3.4617654186082624e-07, 'alpha': 1.2363438030927512e-05, 'max_depth': 3, 'subsample': 0.41542253395565726, 'colsample_bytree': 0.7634514965436203, 'learning_rate': 0.08529022198670358, 'n_estimators': 199}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:13,556] Trial 58 finished with value: 2.6780831347263025 and parameters: {'booster': 'dart', 'lambda': 3.2221600244266036e-07, 'alpha': 9.168449448743473e-05, 'max_depth': 3, 'subsample': 0.20011797592693678, 'colsample_bytree': 0.7663570138638491, 'learning_rate': 0.08861104732055447, 'n_estimators': 193}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:13,967] Trial 59 finished with value: 2.707712544592004 and parameters: {'booster': 'gbtree', 'lambda': 3.1650257004470003e-06, 'alpha': 0.00024995518963209464, 'max_depth': 3, 'subsample': 0.2757499986752097, 'colsample_bytree': 0.9125382401103914, 'learning_rate': 0.0911652387776986, 'n_estimators': 192}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:14,270] Trial 60 finished with value: 2.8035614366509596 and parameters: {'booster': 'gbtree', 'lambda': 2.5500021040630884e-06, 'alpha': 0.000774011904548103, 'max_depth': 3, 'subsample': 0.2733853944562807, 'colsample_bytree': 0.9912074887817922, 'learning_rate': 0.08813382802048127, 'n_estimators': 155}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:14,733] Trial 61 finished with value: 2.83214198893608 and parameters: {'booster': 'gbtree', 'lambda': 3.4309713428821014e-07, 'alpha': 0.000275626209915363, 'max_depth': 9, 'subsample': 0.20121681685104192, 'colsample_bytree': 0.9035381752976255, 'learning_rate': 0.0840081839019497, 'n_estimators': 186}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:15,272] Trial 62 finished with value: 2.7059980809987954 and parameters: {'booster': 'gbtree', 'lambda': 1.1516168213265954e-06, 'alpha': 8.974785961052674e-05, 'max_depth': 3, 'subsample': 0.4165105437960604, 'colsample_bytree': 0.9520991180609548, 'learning_rate': 0.06280580203014255, 'n_estimators': 177}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:15,808] Trial 63 finished with value: 2.7067940491621627 and parameters: {'booster': 'gbtree', 'lambda': 2.495177437990731e-06, 'alpha': 9.30208913181651e-05, 'max_depth': 3, 'subsample': 0.416627608326926, 'colsample_bytree': 0.9716936066254073, 'learning_rate': 0.06261846299004449, 'n_estimators': 169}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:16,245] Trial 64 finished with value: 2.7474204801097852 and parameters: {'booster': 'gbtree', 'lambda': 7.928308218551162e-07, 'alpha': 9.48413333014309e-05, 'max_depth': 3, 'subsample': 0.4216349776762265, 'colsample_bytree': 0.950599756661263, 'learning_rate': 0.06375312847975072, 'n_estimators': 138}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:16,788] Trial 65 finished with value: 2.6752935807318448 and parameters: {'booster': 'gbtree', 'lambda': 1.0944437831056261e-07, 'alpha': 0.0022821982826754963, 'max_depth': 3, 'subsample': 0.4354524335003172, 'colsample_bytree': 0.9522814238665481, 'learning_rate': 0.06949123519406321, 'n_estimators': 167}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:17,227] Trial 66 finished with value: 2.937541705320959 and parameters: {'booster': 'gbtree', 'lambda': 7.706020180934225e-08, 'alpha': 0.042615353398112045, 'max_depth': 3, 'subsample': 0.3512457542652543, 'colsample_bytree': 0.8565321877650841, 'learning_rate': 0.07510299331749369, 'n_estimators': 148}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:17,602] Trial 67 finished with value: 10.154666806943885 and parameters: {'booster': 'gbtree', 'lambda': 1.2170643325619017e-07, 'alpha': 0.0025694143217417894, 'max_depth': 3, 'subsample': 0.44522456545845285, 'colsample_bytree': 0.9376061239231156, 'learning_rate': 0.001950077382788632, 'n_estimators': 114}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:18,089] Trial 68 finished with value: 2.6830503413221503 and parameters: {'booster': 'gbtree', 'lambda': 9.444614299191089e-07, 'alpha': 0.0004715361595846234, 'max_depth': 3, 'subsample': 0.3262747840482283, 'colsample_bytree': 0.8086590939984922, 'learning_rate': 0.09981487618209976, 'n_estimators': 178}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:18,574] Trial 69 finished with value: 2.6763783280449367 and parameters: {'booster': 'gbtree', 'lambda': 4.0092196371575416e-08, 'alpha': 0.010611292815084434, 'max_depth': 3, 'subsample': 0.3805040990982938, 'colsample_bytree': 0.8079306691888989, 'learning_rate': 0.09829102944121201, 'n_estimators': 167}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:18,928] Trial 70 finished with value: 2.7112015524574606 and parameters: {'booster': 'gbtree', 'lambda': 0.0013983352711964196, 'alpha': 0.010882873359518343, 'max_depth': 4, 'subsample': 0.30645261668835644, 'colsample_bytree': 0.8111710861848539, 'learning_rate': 0.0993514657178172, 'n_estimators': 166}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:19,439] Trial 71 finished with value: 2.771166132031238 and parameters: {'booster': 'gbtree', 'lambda': 3.905103528611385e-08, 'alpha': 0.007703988874354114, 'max_depth': 3, 'subsample': 0.3681826014147387, 'colsample_bytree': 0.7954402581334534, 'learning_rate': 0.08660420450381495, 'n_estimators': 180}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:19,925] Trial 72 finished with value: 2.7088119134143605 and parameters: {'booster': 'gbtree', 'lambda': 1.0765603948982452e-07, 'alpha': 0.00197237134077842, 'max_depth': 3, 'subsample': 0.2432875336583596, 'colsample_bytree': 0.856840032869543, 'learning_rate': 0.07166824708573259, 'n_estimators': 162}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:20,440] Trial 73 finished with value: 2.6772217459929046 and parameters: {'booster': 'gbtree', 'lambda': 2.3390602597746288e-07, 'alpha': 0.027557317814316, 'max_depth': 3, 'subsample': 0.32008688040113353, 'colsample_bytree': 0.7333728732348557, 'learning_rate': 0.08173530378268061, 'n_estimators': 196}. Best is trial 57 with value: 2.670055751120119.\n",
      "[I 2023-12-26 16:05:21,004] Trial 74 finished with value: 2.6607604529909348 and parameters: {'booster': 'gbtree', 'lambda': 2.3011469569867896e-07, 'alpha': 0.03389753335041493, 'max_depth': 3, 'subsample': 0.3344246919144769, 'colsample_bytree': 0.8868534937970141, 'learning_rate': 0.08144698824475491, 'n_estimators': 201}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:21,525] Trial 75 finished with value: 2.6668608277852406 and parameters: {'booster': 'gbtree', 'lambda': 1.6369817745574107e-07, 'alpha': 0.16923332963991308, 'max_depth': 3, 'subsample': 0.32004887301772217, 'colsample_bytree': 0.8832950394127623, 'learning_rate': 0.08342009336551369, 'n_estimators': 200}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:22,011] Trial 76 finished with value: 2.7965299331964966 and parameters: {'booster': 'gbtree', 'lambda': 1.817653408092043e-07, 'alpha': 0.13862910650213206, 'max_depth': 4, 'subsample': 0.38505997398785313, 'colsample_bytree': 0.881743508769669, 'learning_rate': 0.081129849592033, 'n_estimators': 201}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:22,540] Trial 77 finished with value: 2.6994241747178442 and parameters: {'booster': 'gbtree', 'lambda': 4.6210397630186596e-08, 'alpha': 0.02945321691103176, 'max_depth': 3, 'subsample': 0.2566110151718891, 'colsample_bytree': 0.841123230502997, 'learning_rate': 0.06976034230853992, 'n_estimators': 188}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:23,064] Trial 78 finished with value: 2.6756884609040332 and parameters: {'booster': 'gbtree', 'lambda': 3.513491022290404e-07, 'alpha': 0.1269480906544309, 'max_depth': 3, 'subsample': 0.4515429952520035, 'colsample_bytree': 0.885795968410598, 'learning_rate': 0.08952921314823499, 'n_estimators': 201}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:23,625] Trial 79 finished with value: 2.729451244066567 and parameters: {'booster': 'gbtree', 'lambda': 0.00017559285457696117, 'alpha': 0.1406528001611432, 'max_depth': 4, 'subsample': 0.45454822373909437, 'colsample_bytree': 0.8792053879017729, 'learning_rate': 0.07537831255132744, 'n_estimators': 205}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:24,561] Trial 80 finished with value: 6.232926122035882 and parameters: {'booster': 'gbtree', 'lambda': 7.162318696895603e-08, 'alpha': 0.21317009604250212, 'max_depth': 7, 'subsample': 0.5027592263633391, 'colsample_bytree': 0.8911833518302572, 'learning_rate': 0.006075379061008055, 'n_estimators': 199}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:24,784] Trial 81 finished with value: 2.9694138633279494 and parameters: {'booster': 'gbtree', 'lambda': 3.8458073687240374e-07, 'alpha': 0.019974959155886842, 'max_depth': 3, 'subsample': 0.3278912342530215, 'colsample_bytree': 0.7752288639728164, 'learning_rate': 0.08707987365422233, 'n_estimators': 52}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:25,277] Trial 82 finished with value: 2.770573372563951 and parameters: {'booster': 'gbtree', 'lambda': 1.5429663835272877e-07, 'alpha': 0.07864490634732185, 'max_depth': 3, 'subsample': 0.3679355120945023, 'colsample_bytree': 0.8357697210151298, 'learning_rate': 0.08925555056499154, 'n_estimators': 194}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:25,868] Trial 83 finished with value: 2.7000971444692787 and parameters: {'booster': 'gbtree', 'lambda': 6.277023219934541e-07, 'alpha': 0.44875592971378264, 'max_depth': 3, 'subsample': 0.3904801045734951, 'colsample_bytree': 0.7389145016798713, 'learning_rate': 0.05935750610311564, 'n_estimators': 184}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:26,406] Trial 84 finished with value: 2.6895751319641934 and parameters: {'booster': 'gbtree', 'lambda': 2.7602788055638514e-07, 'alpha': 0.005734898779257838, 'max_depth': 3, 'subsample': 0.4414489313880811, 'colsample_bytree': 0.9333619630504569, 'learning_rate': 0.06644293580984606, 'n_estimators': 169}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:26,865] Trial 85 finished with value: 2.6936550057301782 and parameters: {'booster': 'gbtree', 'lambda': 1.8458577445463598e-06, 'alpha': 0.07409759780461042, 'max_depth': 4, 'subsample': 0.18976737013218622, 'colsample_bytree': 0.9757766159636498, 'learning_rate': 0.07766814293005801, 'n_estimators': 220}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:27,337] Trial 86 finished with value: 2.6697741465017915 and parameters: {'booster': 'gbtree', 'lambda': 1.6532903253132556e-08, 'alpha': 0.020421935133084254, 'max_depth': 3, 'subsample': 0.32135178575634565, 'colsample_bytree': 0.7730930342665298, 'learning_rate': 0.09112154960191252, 'n_estimators': 211}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:27,992] Trial 87 finished with value: 2.7739714381224623 and parameters: {'booster': 'gbtree', 'lambda': 3.491329384269962e-08, 'alpha': 0.017568551484584267, 'max_depth': 3, 'subsample': 0.49708878913491494, 'colsample_bytree': 0.8523200859124663, 'learning_rate': 0.06707871271800887, 'n_estimators': 207}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:28,632] Trial 88 finished with value: 2.746143796288804 and parameters: {'booster': 'gbtree', 'lambda': 1.2016148668812557e-08, 'alpha': 0.03297428092969672, 'max_depth': 4, 'subsample': 0.3136745764529056, 'colsample_bytree': 0.9252021445428084, 'learning_rate': 0.05481423083554302, 'n_estimators': 200}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:29,274] Trial 89 finished with value: 4.485150838616775 and parameters: {'booster': 'gbtree', 'lambda': 1.726379731357177e-08, 'alpha': 0.32419008046435543, 'max_depth': 3, 'subsample': 0.3405831598702333, 'colsample_bytree': 0.8941889667738704, 'learning_rate': 0.00943208124404248, 'n_estimators': 213}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:29,748] Trial 90 finished with value: 2.6942366461054377 and parameters: {'booster': 'gbtree', 'lambda': 2.865851060810721e-08, 'alpha': 0.009981742158910713, 'max_depth': 3, 'subsample': 0.2938318399750197, 'colsample_bytree': 0.7988822058743125, 'learning_rate': 0.08066226316052737, 'n_estimators': 146}. Best is trial 74 with value: 2.6607604529909348.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:05:30,040] Trial 91 finished with value: 8.866900125616763 and parameters: {'booster': 'gblinear', 'lambda': 6.92560019916835e-08, 'alpha': 0.04813369898245213, 'max_depth': 3, 'subsample': 0.3600646327921855, 'colsample_bytree': 0.7662724749417189, 'learning_rate': 0.09631340219088935, 'n_estimators': 189}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:30,488] Trial 92 finished with value: 3.2686679401136423 and parameters: {'booster': 'gbtree', 'lambda': 2.81959727318014e-07, 'alpha': 0.11604651654274052, 'max_depth': 3, 'subsample': 0.1466151758182886, 'colsample_bytree': 0.26802963473465213, 'learning_rate': 0.08803855375443081, 'n_estimators': 197}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:30,998] Trial 93 finished with value: 2.6889562694510643 and parameters: {'booster': 'gbtree', 'lambda': 1.399746802236564e-07, 'alpha': 0.02449447241225048, 'max_depth': 3, 'subsample': 0.39507838659965056, 'colsample_bytree': 0.830767802349226, 'learning_rate': 0.07372697877802137, 'n_estimators': 183}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:31,409] Trial 94 finished with value: 2.6705347775378727 and parameters: {'booster': 'gbtree', 'lambda': 0.07661043013466182, 'alpha': 0.21750537029450798, 'max_depth': 3, 'subsample': 0.16344604632417956, 'colsample_bytree': 0.7397777169955664, 'learning_rate': 0.09008318610041526, 'n_estimators': 172}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:31,745] Trial 95 finished with value: 2.7542524415009644 and parameters: {'booster': 'gbtree', 'lambda': 0.007316744610432945, 'alpha': 0.7072232108604044, 'max_depth': 4, 'subsample': 0.161913233255683, 'colsample_bytree': 0.7379845791126197, 'learning_rate': 0.09954426618616637, 'n_estimators': 174}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:32,185] Trial 96 finished with value: 3.321890396494844 and parameters: {'booster': 'gbtree', 'lambda': 0.2915044770621997, 'alpha': 0.10330708422466223, 'max_depth': 3, 'subsample': 0.22097243072648318, 'colsample_bytree': 0.6524016449915634, 'learning_rate': 0.07944933559110208, 'n_estimators': 158}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:32,804] Trial 97 finished with value: 2.762152552883647 and parameters: {'booster': 'gbtree', 'lambda': 6.131283294771499e-05, 'alpha': 0.2426446708318367, 'max_depth': 4, 'subsample': 0.47017944364494246, 'colsample_bytree': 0.867746687752263, 'learning_rate': 0.060164428362400185, 'n_estimators': 173}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:33,280] Trial 98 finished with value: 2.7143984134991963 and parameters: {'booster': 'gbtree', 'lambda': 0.10140104529306987, 'alpha': 0.012041288443146314, 'max_depth': 3, 'subsample': 0.25809201227913336, 'colsample_bytree': 0.7928317700136212, 'learning_rate': 0.06704308771688534, 'n_estimators': 163}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:33,736] Trial 99 finished with value: 2.884709872099907 and parameters: {'booster': 'gbtree', 'lambda': 1.5229846060325702e-08, 'alpha': 0.00483621985191667, 'max_depth': 8, 'subsample': 0.12846113800802608, 'colsample_bytree': 0.7059577842685902, 'learning_rate': 0.0730541363122449, 'n_estimators': 220}. Best is trial 74 with value: 2.6607604529909348.\n",
      "[I 2023-12-26 16:05:33,740] A new study created in memory with name: no-name-c07d0112-4294-422a-aceb-cde9008e0ec4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 2.6607604529909348\n",
      "  Params: \n",
      "    booster: gbtree\n",
      "    lambda: 2.3011469569867896e-07\n",
      "    alpha: 0.03389753335041493\n",
      "    max_depth: 3\n",
      "    subsample: 0.3344246919144769\n",
      "    colsample_bytree: 0.8868534937970141\n",
      "    learning_rate: 0.08144698824475491\n",
      "    n_estimators: 201\n",
      "[16:05:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:05:34,020] Trial 0 finished with value: 11.903265721569323 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 11.903265721569323.\n",
      "[I 2023-12-26 16:05:34,181] Trial 1 finished with value: 12.773026482569028 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 0 with value: 11.903265721569323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:05:34,414] Trial 2 finished with value: 26.574704217083376 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 0 with value: 11.903265721569323.\n",
      "[I 2023-12-26 16:05:34,985] Trial 3 finished with value: 10.766695824191997 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 3 with value: 10.766695824191997.\n",
      "[I 2023-12-26 16:05:35,119] Trial 4 finished with value: 12.610677104932531 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 3 with value: 10.766695824191997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:05:35,476] Trial 5 finished with value: 54.652120563733526 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 3 with value: 10.766695824191997.\n",
      "[I 2023-12-26 16:05:46,261] Trial 6 finished with value: 43.734638631115224 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 3 with value: 10.766695824191997.\n",
      "[I 2023-12-26 16:05:46,539] Trial 7 finished with value: 43.13449777472509 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 3 with value: 10.766695824191997.\n",
      "[I 2023-12-26 16:05:47,021] Trial 8 finished with value: 11.004445899022768 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 3 with value: 10.766695824191997.\n",
      "[I 2023-12-26 16:05:47,919] Trial 9 finished with value: 58.657703350101976 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 3 with value: 10.766695824191997.\n",
      "[I 2023-12-26 16:05:48,435] Trial 10 finished with value: 9.913626368971176 and parameters: {'booster': 'gbtree', 'lambda': 0.0059279800152147654, 'alpha': 0.5705541732383875, 'max_depth': 10, 'subsample': 0.5522780959073166, 'colsample_bytree': 0.3529613975730607, 'learning_rate': 0.08308860966122086, 'n_estimators': 219}. Best is trial 10 with value: 9.913626368971176.\n",
      "[I 2023-12-26 16:05:48,941] Trial 11 finished with value: 9.912130457211846 and parameters: {'booster': 'gbtree', 'lambda': 0.008076893525758038, 'alpha': 0.9221284856141014, 'max_depth': 10, 'subsample': 0.579782907504362, 'colsample_bytree': 0.32615275723193415, 'learning_rate': 0.09491482732018462, 'n_estimators': 216}. Best is trial 11 with value: 9.912130457211846.\n",
      "[I 2023-12-26 16:05:49,387] Trial 12 finished with value: 9.911513127714532 and parameters: {'booster': 'gbtree', 'lambda': 0.004407941333768624, 'alpha': 0.5445286910752476, 'max_depth': 10, 'subsample': 0.6244867691348617, 'colsample_bytree': 0.3895904598402382, 'learning_rate': 0.09868736446193495, 'n_estimators': 223}. Best is trial 12 with value: 9.911513127714532.\n",
      "[I 2023-12-26 16:05:49,877] Trial 13 finished with value: 10.08033797521025 and parameters: {'booster': 'gbtree', 'lambda': 0.010490870996049373, 'alpha': 0.03652557953537677, 'max_depth': 10, 'subsample': 0.970692835118854, 'colsample_bytree': 0.3739464770277602, 'learning_rate': 0.04168043620362369, 'n_estimators': 230}. Best is trial 12 with value: 9.911513127714532.\n",
      "[I 2023-12-26 16:05:50,287] Trial 14 finished with value: 9.910209781176423 and parameters: {'booster': 'gbtree', 'lambda': 0.0020288569587832823, 'alpha': 0.9173628225364595, 'max_depth': 8, 'subsample': 0.7418278297919652, 'colsample_bytree': 0.4281072733591316, 'learning_rate': 0.09779253077589893, 'n_estimators': 270}. Best is trial 14 with value: 9.910209781176423.\n",
      "[I 2023-12-26 16:05:53,436] Trial 15 finished with value: 10.05906373603159 and parameters: {'booster': 'dart', 'lambda': 6.549025555744352e-05, 'alpha': 0.0665192775729531, 'max_depth': 8, 'subsample': 0.7270773181681627, 'colsample_bytree': 0.44781954501826293, 'learning_rate': 0.03743309561243859, 'n_estimators': 293}. Best is trial 14 with value: 9.910209781176423.\n",
      "[I 2023-12-26 16:05:54,507] Trial 16 finished with value: 23.859822776480897 and parameters: {'booster': 'gbtree', 'lambda': 0.0013286875567105482, 'alpha': 0.0006847640945620193, 'max_depth': 7, 'subsample': 0.8761783572696831, 'colsample_bytree': 0.7269059189562143, 'learning_rate': 0.004362597510446986, 'n_estimators': 262}. Best is trial 14 with value: 9.910209781176423.\n",
      "[I 2023-12-26 16:05:55,364] Trial 17 finished with value: 9.985503733735104 and parameters: {'booster': 'gbtree', 'lambda': 3.816228135091541e-05, 'alpha': 1.7859199196976743e-08, 'max_depth': 9, 'subsample': 0.6914307738948051, 'colsample_bytree': 0.25642348045456276, 'learning_rate': 0.02912129935577816, 'n_estimators': 259}. Best is trial 14 with value: 9.910209781176423.\n",
      "[I 2023-12-26 16:05:56,904] Trial 18 finished with value: 10.043281094625117 and parameters: {'booster': 'dart', 'lambda': 0.0014143960253942662, 'alpha': 0.09332138105742517, 'max_depth': 6, 'subsample': 0.6501395101807405, 'colsample_bytree': 0.4334024280671642, 'learning_rate': 0.058472692223367165, 'n_estimators': 191}. Best is trial 14 with value: 9.910209781176423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:05:57,274] Trial 19 finished with value: 13.31196668232957 and parameters: {'booster': 'gblinear', 'lambda': 0.03800476734847853, 'alpha': 0.002681795771531562, 'max_depth': 3, 'subsample': 0.4677888500034741, 'colsample_bytree': 0.6904394509793828, 'learning_rate': 0.0025359593118897852, 'n_estimators': 262}. Best is trial 14 with value: 9.910209781176423.\n",
      "[I 2023-12-26 16:05:57,765] Trial 20 finished with value: 9.89247178935569 and parameters: {'booster': 'gbtree', 'lambda': 0.7851436318325843, 'alpha': 4.001717339375267e-05, 'max_depth': 9, 'subsample': 0.8564072683039088, 'colsample_bytree': 0.504295404820454, 'learning_rate': 0.09935686244301652, 'n_estimators': 196}. Best is trial 20 with value: 9.89247178935569.\n",
      "[I 2023-12-26 16:05:58,221] Trial 21 finished with value: 9.891421574980157 and parameters: {'booster': 'gbtree', 'lambda': 0.8221940198535354, 'alpha': 3.5737169725694145e-05, 'max_depth': 9, 'subsample': 0.8985966181589764, 'colsample_bytree': 0.4897948716280453, 'learning_rate': 0.09964651093167143, 'n_estimators': 186}. Best is trial 21 with value: 9.891421574980157.\n",
      "[I 2023-12-26 16:05:58,904] Trial 22 finished with value: 9.889452378085759 and parameters: {'booster': 'gbtree', 'lambda': 0.8898840517215323, 'alpha': 3.7255474796091035e-05, 'max_depth': 8, 'subsample': 0.8567833373290206, 'colsample_bytree': 0.5232514357702767, 'learning_rate': 0.05601486345957135, 'n_estimators': 192}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:05:59,498] Trial 23 finished with value: 9.907496795654298 and parameters: {'booster': 'gbtree', 'lambda': 0.7385803100388464, 'alpha': 3.545140149579003e-05, 'max_depth': 9, 'subsample': 0.9757766746374883, 'colsample_bytree': 0.6297614877054181, 'learning_rate': 0.056445888097281294, 'n_estimators': 190}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:00,038] Trial 24 finished with value: 11.030776052257242 and parameters: {'booster': 'gbtree', 'lambda': 0.8945139444813976, 'alpha': 7.410685855917019e-06, 'max_depth': 7, 'subsample': 0.8651935040119304, 'colsample_bytree': 0.7549637983040894, 'learning_rate': 0.060132995548464005, 'n_estimators': 146}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:00,639] Trial 25 finished with value: 9.979911549886067 and parameters: {'booster': 'gbtree', 'lambda': 0.05097072487687184, 'alpha': 0.00013519997484208855, 'max_depth': 9, 'subsample': 0.8806333919779348, 'colsample_bytree': 0.5091455975845924, 'learning_rate': 0.041307294921224945, 'n_estimators': 187}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:01,426] Trial 26 finished with value: 10.019923309604872 and parameters: {'booster': 'gbtree', 'lambda': 0.12106576579296376, 'alpha': 1.1924140626203036e-05, 'max_depth': 8, 'subsample': 0.8219699944450997, 'colsample_bytree': 0.628542476293521, 'learning_rate': 0.02356084915690228, 'n_estimators': 209}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:01,983] Trial 27 finished with value: 9.899745710538403 and parameters: {'booster': 'gbtree', 'lambda': 0.7405415433412412, 'alpha': 0.0003593348015525318, 'max_depth': 9, 'subsample': 0.9995424826762094, 'colsample_bytree': 0.5046052877727524, 'learning_rate': 0.06436968078709909, 'n_estimators': 153}. Best is trial 22 with value: 9.889452378085759.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:02,324] Trial 28 finished with value: 11.32559183129437 and parameters: {'booster': 'gblinear', 'lambda': 0.02933885180272743, 'alpha': 9.257721772046891e-05, 'max_depth': 7, 'subsample': 0.9068632443541855, 'colsample_bytree': 0.9918798974081384, 'learning_rate': 0.04134987384559678, 'n_estimators': 243}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:07,277] Trial 29 finished with value: 10.02044031082223 and parameters: {'booster': 'dart', 'lambda': 0.20156610183818344, 'alpha': 3.032223605869875e-07, 'max_depth': 8, 'subsample': 0.9374285520179745, 'colsample_bytree': 0.10815990606295728, 'learning_rate': 0.02613359512205734, 'n_estimators': 203}. Best is trial 22 with value: 9.889452378085759.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:07,547] Trial 30 finished with value: 11.262609253626437 and parameters: {'booster': 'gblinear', 'lambda': 0.0002522690425494734, 'alpha': 1.396639767693015e-05, 'max_depth': 6, 'subsample': 0.8093067277908155, 'colsample_bytree': 0.6146413246759503, 'learning_rate': 0.07650226175047914, 'n_estimators': 178}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:08,109] Trial 31 finished with value: 9.896725988518702 and parameters: {'booster': 'gbtree', 'lambda': 0.8199602374919274, 'alpha': 0.0006397211225874211, 'max_depth': 9, 'subsample': 0.9942396035484525, 'colsample_bytree': 0.5114643561899024, 'learning_rate': 0.06765061039808697, 'n_estimators': 154}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:08,509] Trial 32 finished with value: 9.980097292547356 and parameters: {'booster': 'gbtree', 'lambda': 0.08800019956674517, 'alpha': 0.00014584007574333424, 'max_depth': 9, 'subsample': 0.9240284627185242, 'colsample_bytree': 0.5103260014479063, 'learning_rate': 0.07208250193313148, 'n_estimators': 134}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:09,106] Trial 33 finished with value: 11.035363071389394 and parameters: {'booster': 'gbtree', 'lambda': 0.9464308799553866, 'alpha': 0.0014398107189186418, 'max_depth': 9, 'subsample': 0.8401804335917329, 'colsample_bytree': 0.5625399752687648, 'learning_rate': 0.018452195955175554, 'n_estimators': 175}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:09,516] Trial 34 finished with value: 10.074681176311893 and parameters: {'booster': 'gbtree', 'lambda': 0.3636949223079954, 'alpha': 3.075237827982537e-05, 'max_depth': 8, 'subsample': 0.9460073418823413, 'colsample_bytree': 0.46342531308240803, 'learning_rate': 0.04757094648401425, 'n_estimators': 111}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:10,317] Trial 35 finished with value: 12.196787013223725 and parameters: {'booster': 'gbtree', 'lambda': 5.469133083457234e-08, 'alpha': 0.0002919493381822186, 'max_depth': 10, 'subsample': 0.7792069999996273, 'colsample_bytree': 0.5441714203409199, 'learning_rate': 0.010297211753388732, 'n_estimators': 200}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:10,551] Trial 36 finished with value: 11.708943772686126 and parameters: {'booster': 'gblinear', 'lambda': 0.2689178559057207, 'alpha': 6.709554209058715e-07, 'max_depth': 9, 'subsample': 0.6966561272673066, 'colsample_bytree': 0.5899302089490588, 'learning_rate': 0.031061788500513953, 'n_estimators': 148}. Best is trial 22 with value: 9.889452378085759.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:10,931] Trial 37 finished with value: 10.165008439712873 and parameters: {'booster': 'gbtree', 'lambda': 0.3184019586678731, 'alpha': 4.6593008057327105e-06, 'max_depth': 9, 'subsample': 0.4714127099608567, 'colsample_bytree': 0.27747603183816894, 'learning_rate': 0.07625689671047382, 'n_estimators': 165}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:11,498] Trial 38 finished with value: 15.886755847669628 and parameters: {'booster': 'gbtree', 'lambda': 0.022400981163441695, 'alpha': 4.8007437667510665e-08, 'max_depth': 8, 'subsample': 0.8961302783899612, 'colsample_bytree': 0.7906737092340654, 'learning_rate': 0.016475512394919394, 'n_estimators': 114}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:12,176] Trial 39 finished with value: 11.256782273941388 and parameters: {'booster': 'gbtree', 'lambda': 1.5708586699377717e-06, 'alpha': 5.898466439974366e-05, 'max_depth': 10, 'subsample': 0.852875769154457, 'colsample_bytree': 0.6671408055978241, 'learning_rate': 0.050179399221893885, 'n_estimators': 235}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:12,751] Trial 40 finished with value: 27.193895123277077 and parameters: {'booster': 'gbtree', 'lambda': 0.06381358729059483, 'alpha': 1.9103589401063014e-05, 'max_depth': 7, 'subsample': 0.9947208753063215, 'colsample_bytree': 0.877286612103322, 'learning_rate': 0.007214421196500502, 'n_estimators': 136}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:13,291] Trial 41 finished with value: 9.892471494631137 and parameters: {'booster': 'gbtree', 'lambda': 0.9236599208508823, 'alpha': 0.0005140720005560808, 'max_depth': 9, 'subsample': 0.9981752287034686, 'colsample_bytree': 0.5266206177605465, 'learning_rate': 0.06735585558557003, 'n_estimators': 154}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:13,626] Trial 42 finished with value: 9.994395669736818 and parameters: {'booster': 'gbtree', 'lambda': 0.15516771541368948, 'alpha': 0.007618889589200436, 'max_depth': 9, 'subsample': 0.9408164377324919, 'colsample_bytree': 0.5394839104892873, 'learning_rate': 0.07900438466162836, 'n_estimators': 158}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:14,259] Trial 43 finished with value: 9.95149495582058 and parameters: {'booster': 'gbtree', 'lambda': 0.4318106550830933, 'alpha': 0.000970957715368863, 'max_depth': 8, 'subsample': 0.9258833304337288, 'colsample_bytree': 0.426352077373651, 'learning_rate': 0.03489767423185249, 'n_estimators': 178}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:14,513] Trial 44 finished with value: 11.064400252947523 and parameters: {'booster': 'gbtree', 'lambda': 0.9828066728608933, 'alpha': 0.0002516367292622719, 'max_depth': 10, 'subsample': 0.10130501061347807, 'colsample_bytree': 0.39535451656929255, 'learning_rate': 0.09588290462020121, 'n_estimators': 166}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:15,983] Trial 45 finished with value: 10.093946053840254 and parameters: {'booster': 'dart', 'lambda': 0.017204998367862975, 'alpha': 2.4582055785121645e-06, 'max_depth': 9, 'subsample': 0.7784006338731861, 'colsample_bytree': 0.32822076577551484, 'learning_rate': 0.05224494791418934, 'n_estimators': 121}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:16,465] Trial 46 finished with value: 9.951411160682433 and parameters: {'booster': 'gbtree', 'lambda': 0.09280797604333438, 'alpha': 0.0019421893475152139, 'max_depth': 10, 'subsample': 0.8303712329152722, 'colsample_bytree': 0.5904810572045024, 'learning_rate': 0.0685919355276057, 'n_estimators': 198}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:16,808] Trial 47 finished with value: 9.939059980557934 and parameters: {'booster': 'gbtree', 'lambda': 0.35135307695717166, 'alpha': 4.279206176572075e-05, 'max_depth': 5, 'subsample': 0.9524594106758834, 'colsample_bytree': 0.46619676093056167, 'learning_rate': 0.08497959588702528, 'n_estimators': 93}. Best is trial 22 with value: 9.889452378085759.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:17,119] Trial 48 finished with value: 11.31871143846207 and parameters: {'booster': 'gblinear', 'lambda': 0.18220091340354566, 'alpha': 8.564704329178537e-05, 'max_depth': 8, 'subsample': 0.32227714397070545, 'colsample_bytree': 0.5279756248386479, 'learning_rate': 0.047924475530207865, 'n_estimators': 213}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:17,758] Trial 49 finished with value: 10.477214234234536 and parameters: {'booster': 'gbtree', 'lambda': 0.45439510248996384, 'alpha': 0.007486412347598646, 'max_depth': 8, 'subsample': 0.8970265727418039, 'colsample_bytree': 0.4814915155659652, 'learning_rate': 0.019788148780448964, 'n_estimators': 183}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:18,085] Trial 50 finished with value: 10.068052255290828 and parameters: {'booster': 'gbtree', 'lambda': 0.003405511560108222, 'alpha': 0.0005938125018234316, 'max_depth': 9, 'subsample': 0.9588678736958492, 'colsample_bytree': 0.39717585228174856, 'learning_rate': 0.06984930152807693, 'n_estimators': 142}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:18,459] Trial 51 finished with value: 9.915131600436554 and parameters: {'booster': 'gbtree', 'lambda': 0.5381469276064968, 'alpha': 0.00036498091465275386, 'max_depth': 9, 'subsample': 0.9906002925230477, 'colsample_bytree': 0.4991334387638075, 'learning_rate': 0.09907459713078048, 'n_estimators': 155}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:19,028] Trial 52 finished with value: 9.891740284401532 and parameters: {'booster': 'gbtree', 'lambda': 0.9858083485680537, 'alpha': 0.00013673344868858633, 'max_depth': 10, 'subsample': 0.9975055066025074, 'colsample_bytree': 0.5554375383507397, 'learning_rate': 0.06820306084126486, 'n_estimators': 171}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:19,579] Trial 53 finished with value: 9.935394005623037 and parameters: {'booster': 'gbtree', 'lambda': 0.15892196432762887, 'alpha': 0.0001814099804587258, 'max_depth': 10, 'subsample': 0.8710880431824543, 'colsample_bytree': 0.5723752864673666, 'learning_rate': 0.06241757964868395, 'n_estimators': 171}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:19,933] Trial 54 finished with value: 9.989128779581149 and parameters: {'booster': 'gbtree', 'lambda': 0.06568842370671474, 'alpha': 5.725750395832414e-06, 'max_depth': 10, 'subsample': 0.9082017997037113, 'colsample_bytree': 0.6638754127740996, 'learning_rate': 0.084155725580187, 'n_estimators': 195}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:20,485] Trial 55 finished with value: 10.072800846186947 and parameters: {'booster': 'gbtree', 'lambda': 1.650660445290908e-05, 'alpha': 0.0030865535920838144, 'max_depth': 10, 'subsample': 0.9668511161827453, 'colsample_bytree': 0.6098349602536797, 'learning_rate': 0.03454193361750788, 'n_estimators': 159}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:24,941] Trial 56 finished with value: 42.532764055783346 and parameters: {'booster': 'dart', 'lambda': 0.9599552519117159, 'alpha': 2.426152016669646e-05, 'max_depth': 10, 'subsample': 0.7931095981111588, 'colsample_bytree': 0.5470823376936655, 'learning_rate': 0.0020525460238584935, 'n_estimators': 206}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:25,524] Trial 57 finished with value: 9.967415978418638 and parameters: {'booster': 'gbtree', 'lambda': 0.01157480503221599, 'alpha': 6.1720610965613e-05, 'max_depth': 9, 'subsample': 0.7409511493530495, 'colsample_bytree': 0.4238528952010889, 'learning_rate': 0.04533504159293876, 'n_estimators': 184}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:26,163] Trial 58 finished with value: 11.005290037529653 and parameters: {'booster': 'gbtree', 'lambda': 0.24225136014780932, 'alpha': 0.0006623073534556747, 'max_depth': 9, 'subsample': 0.9987169743225789, 'colsample_bytree': 0.7112032238872328, 'learning_rate': 0.055933092202676074, 'n_estimators': 128}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:26,679] Trial 59 finished with value: 9.898838498886319 and parameters: {'booster': 'gbtree', 'lambda': 0.5139822116829225, 'alpha': 8.416847019494518e-06, 'max_depth': 8, 'subsample': 0.8554341068827284, 'colsample_bytree': 0.6526774111523742, 'learning_rate': 0.08627373711041647, 'n_estimators': 222}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:27,226] Trial 60 finished with value: 13.561528757173722 and parameters: {'booster': 'gbtree', 'lambda': 1.85779239619619e-07, 'alpha': 1.577071823464249e-06, 'max_depth': 3, 'subsample': 0.6351292298226542, 'colsample_bytree': 0.3644724433749571, 'learning_rate': 0.012421470688422778, 'n_estimators': 169}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:27,705] Trial 61 finished with value: 9.903952803241609 and parameters: {'booster': 'gbtree', 'lambda': 0.44772565070319276, 'alpha': 7.087154554531417e-06, 'max_depth': 8, 'subsample': 0.8559808650397034, 'colsample_bytree': 0.5868686063793839, 'learning_rate': 0.08542303371207079, 'n_estimators': 222}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:28,084] Trial 62 finished with value: 9.986506023668264 and parameters: {'booster': 'gbtree', 'lambda': 0.12016794299196461, 'alpha': 0.00010838549620278088, 'max_depth': 7, 'subsample': 0.9223180623269761, 'colsample_bytree': 0.6424955911530172, 'learning_rate': 0.06502219344147907, 'n_estimators': 248}. Best is trial 22 with value: 9.889452378085759.\n",
      "[I 2023-12-26 16:06:28,619] Trial 63 finished with value: 9.886979154821944 and parameters: {'booster': 'gbtree', 'lambda': 0.6433022818397975, 'alpha': 1.3566890433052513e-05, 'max_depth': 8, 'subsample': 0.877264335525518, 'colsample_bytree': 0.48273661759047193, 'learning_rate': 0.08334938648511478, 'n_estimators': 234}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:29,027] Trial 64 finished with value: 10.034745251381233 and parameters: {'booster': 'gbtree', 'lambda': 0.041796407753415095, 'alpha': 2.485956521376625e-05, 'max_depth': 9, 'subsample': 0.9680876729451963, 'colsample_bytree': 0.4518682297438969, 'learning_rate': 0.05680774070711654, 'n_estimators': 277}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:31,002] Trial 65 finished with value: 9.937301777182103 and parameters: {'booster': 'dart', 'lambda': 0.6847105592488826, 'alpha': 1.4348328994814295e-05, 'max_depth': 9, 'subsample': 0.8834148697449473, 'colsample_bytree': 0.5165270085867488, 'learning_rate': 0.07185233688187033, 'n_estimators': 231}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:31,237] Trial 66 finished with value: 11.261777098494578 and parameters: {'booster': 'gblinear', 'lambda': 0.2211828657505016, 'alpha': 4.9379581077508745e-05, 'max_depth': 7, 'subsample': 0.8176554936673834, 'colsample_bytree': 0.4798464109939526, 'learning_rate': 0.09997783925063797, 'n_estimators': 142}. Best is trial 63 with value: 9.886979154821944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:31,912] Trial 67 finished with value: 9.917181620140598 and parameters: {'booster': 'gbtree', 'lambda': 0.9684046109180968, 'alpha': 3.5735619422814718e-06, 'max_depth': 8, 'subsample': 0.914746350015419, 'colsample_bytree': 0.4140744921086884, 'learning_rate': 0.04068270528867342, 'n_estimators': 191}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:32,153] Trial 68 finished with value: 50.046796875000005 and parameters: {'booster': 'gbtree', 'lambda': 0.09025662290509877, 'alpha': 8.745639035345538e-07, 'max_depth': 10, 'subsample': 0.5053512456497335, 'colsample_bytree': 0.5598698252731483, 'learning_rate': 0.004649696449953221, 'n_estimators': 55}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:32,836] Trial 69 finished with value: 9.895224509739984 and parameters: {'booster': 'gbtree', 'lambda': 0.3322098683045884, 'alpha': 0.00020004563606066707, 'max_depth': 9, 'subsample': 0.7113669684248648, 'colsample_bytree': 0.4575948253655034, 'learning_rate': 0.06490118612947102, 'n_estimators': 211}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:33,240] Trial 70 finished with value: 10.016516849047516 and parameters: {'booster': 'gbtree', 'lambda': 0.274613631225982, 'alpha': 0.000189422989429171, 'max_depth': 4, 'subsample': 0.6047933337849838, 'colsample_bytree': 0.3450180839904333, 'learning_rate': 0.08824699607148274, 'n_estimators': 212}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:33,937] Trial 71 finished with value: 9.891556186763118 and parameters: {'booster': 'gbtree', 'lambda': 0.5229660224681776, 'alpha': 0.0004074926479950599, 'max_depth': 9, 'subsample': 0.6823695876823564, 'colsample_bytree': 0.45212486175239097, 'learning_rate': 0.06254635733343976, 'n_estimators': 241}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:34,664] Trial 72 finished with value: 9.895087757546063 and parameters: {'booster': 'gbtree', 'lambda': 0.4715743491575856, 'alpha': 0.0003545241920891773, 'max_depth': 9, 'subsample': 0.6761319835700014, 'colsample_bytree': 0.4460701178401238, 'learning_rate': 0.054086386235018644, 'n_estimators': 243}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:35,420] Trial 73 finished with value: 9.892431297824807 and parameters: {'booster': 'gbtree', 'lambda': 0.510043894057802, 'alpha': 0.0003839874812537289, 'max_depth': 9, 'subsample': 0.6496282776610995, 'colsample_bytree': 0.4899982930518414, 'learning_rate': 0.05638064331467558, 'n_estimators': 245}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:36,037] Trial 74 finished with value: 9.902632946554384 and parameters: {'booster': 'gbtree', 'lambda': 0.1219689321964681, 'alpha': 0.0011905862521986782, 'max_depth': 8, 'subsample': 0.524373957271756, 'colsample_bytree': 0.49294757541184625, 'learning_rate': 0.07676302565327327, 'n_estimators': 281}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:36,738] Trial 75 finished with value: 9.961317480775321 and parameters: {'booster': 'gbtree', 'lambda': 0.0005469982622186678, 'alpha': 9.72113956199021e-05, 'max_depth': 9, 'subsample': 0.6675034429045595, 'colsample_bytree': 0.531739207792754, 'learning_rate': 0.04497999574402137, 'n_estimators': 238}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:37,402] Trial 76 finished with value: 9.979945525426299 and parameters: {'booster': 'gbtree', 'lambda': 1.0678849317969725e-08, 'alpha': 0.0004584460777906684, 'max_depth': 10, 'subsample': 0.7430274050829865, 'colsample_bytree': 0.4816937467339524, 'learning_rate': 0.036980963259584165, 'n_estimators': 245}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:38,161] Trial 77 finished with value: 9.922472102892453 and parameters: {'booster': 'gbtree', 'lambda': 0.5545777360808906, 'alpha': 3.7448744910341436e-05, 'max_depth': 8, 'subsample': 0.4116638415318271, 'colsample_bytree': 0.29373502619925257, 'learning_rate': 0.05867166301434647, 'n_estimators': 266}. Best is trial 63 with value: 9.886979154821944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:38,547] Trial 78 finished with value: 11.4312112775132 and parameters: {'booster': 'gblinear', 'lambda': 0.20699150626532026, 'alpha': 7.195236037922332e-05, 'max_depth': 9, 'subsample': 0.7761412249795734, 'colsample_bytree': 0.6134557518694482, 'learning_rate': 0.029698382875375386, 'n_estimators': 254}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:38,878] Trial 79 finished with value: 10.011671290288778 and parameters: {'booster': 'gbtree', 'lambda': 2.116362059446141e-06, 'alpha': 1.0501826710189992e-05, 'max_depth': 6, 'subsample': 0.8080754109609409, 'colsample_bytree': 0.3845853038903751, 'learning_rate': 0.07777734799165914, 'n_estimators': 231}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:42,944] Trial 80 finished with value: 21.446549447116244 and parameters: {'booster': 'dart', 'lambda': 0.061395537823895674, 'alpha': 1.8159379515088206e-05, 'max_depth': 10, 'subsample': 0.5915323265551535, 'colsample_bytree': 0.5681819302817245, 'learning_rate': 0.006626151210908311, 'n_estimators': 178}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:43,786] Trial 81 finished with value: 9.89316366814043 and parameters: {'booster': 'gbtree', 'lambda': 0.6257273674391476, 'alpha': 0.00036948494467982265, 'max_depth': 9, 'subsample': 0.6815981619243205, 'colsample_bytree': 0.4413909693122365, 'learning_rate': 0.05141098327593479, 'n_estimators': 254}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:44,532] Trial 82 finished with value: 9.9393280405541 and parameters: {'booster': 'gbtree', 'lambda': 0.6319589182344056, 'alpha': 0.0009751948110162442, 'max_depth': 9, 'subsample': 0.5604140521896958, 'colsample_bytree': 0.4160815372685997, 'learning_rate': 0.048215200230796285, 'n_estimators': 250}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:45,204] Trial 83 finished with value: 9.893574603355095 and parameters: {'booster': 'gbtree', 'lambda': 0.34783981833131644, 'alpha': 0.0020486201307131674, 'max_depth': 9, 'subsample': 0.7207170658721818, 'colsample_bytree': 0.5275285348787254, 'learning_rate': 0.06242452365220292, 'n_estimators': 240}. Best is trial 63 with value: 9.886979154821944.\n",
      "[I 2023-12-26 16:06:45,866] Trial 84 finished with value: 9.880617247281009 and parameters: {'booster': 'gbtree', 'lambda': 0.6495591253446091, 'alpha': 0.00012933765904683272, 'max_depth': 9, 'subsample': 0.617456719057605, 'colsample_bytree': 0.4413077425023056, 'learning_rate': 0.08890636252030748, 'n_estimators': 272}. Best is trial 84 with value: 9.880617247281009.\n",
      "[I 2023-12-26 16:06:46,338] Trial 85 finished with value: 9.91357905557711 and parameters: {'booster': 'gbtree', 'lambda': 0.15430650666429757, 'alpha': 0.0001362973561406584, 'max_depth': 8, 'subsample': 0.6441956426342466, 'colsample_bytree': 0.4678730311733775, 'learning_rate': 0.09240797102805552, 'n_estimators': 296}. Best is trial 84 with value: 9.880617247281009.\n",
      "[I 2023-12-26 16:06:46,978] Trial 86 finished with value: 9.895735094601706 and parameters: {'booster': 'gbtree', 'lambda': 0.2573720064023062, 'alpha': 3.934472772050049e-05, 'max_depth': 9, 'subsample': 0.6179316950383031, 'colsample_bytree': 0.4912230206435628, 'learning_rate': 0.07246510080213704, 'n_estimators': 259}. Best is trial 84 with value: 9.880617247281009.\n",
      "[I 2023-12-26 16:06:47,613] Trial 87 finished with value: 9.881235750799311 and parameters: {'booster': 'gbtree', 'lambda': 0.8892676141507752, 'alpha': 0.00013108552364810263, 'max_depth': 10, 'subsample': 0.836785861651475, 'colsample_bytree': 0.5117932373742804, 'learning_rate': 0.07848598704012734, 'n_estimators': 282}. Best is trial 84 with value: 9.880617247281009.\n",
      "[I 2023-12-26 16:06:48,318] Trial 88 finished with value: 9.878081051203758 and parameters: {'booster': 'gbtree', 'lambda': 0.963761515817317, 'alpha': 0.0002325915040754197, 'max_depth': 10, 'subsample': 0.7602569096629045, 'colsample_bytree': 0.40276183987453607, 'learning_rate': 0.08049851657031563, 'n_estimators': 281}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:48,688] Trial 89 finished with value: 9.986617215648634 and parameters: {'booster': 'gbtree', 'lambda': 0.029057137574600614, 'alpha': 0.00013800020248029674, 'max_depth': 10, 'subsample': 0.8365415919250185, 'colsample_bytree': 0.23559515132347894, 'learning_rate': 0.08324894480371954, 'n_estimators': 286}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:49,176] Trial 90 finished with value: 9.941997228474378 and parameters: {'booster': 'gbtree', 'lambda': 0.0911437465030323, 'alpha': 7.055196789725342e-05, 'max_depth': 10, 'subsample': 0.7601757621845802, 'colsample_bytree': 0.37036867735595236, 'learning_rate': 0.07724017440586738, 'n_estimators': 271}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:49,986] Trial 91 finished with value: 9.88013589519344 and parameters: {'booster': 'gbtree', 'lambda': 0.9548334438342646, 'alpha': 0.00022676858925151926, 'max_depth': 10, 'subsample': 0.6579123484315025, 'colsample_bytree': 0.5079262468457608, 'learning_rate': 0.06877620026058046, 'n_estimators': 285}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:50,351] Trial 92 finished with value: 10.076240506803607 and parameters: {'booster': 'gbtree', 'lambda': 0.5639052948731172, 'alpha': 0.00025004311674683543, 'max_depth': 10, 'subsample': 0.6592479797827442, 'colsample_bytree': 0.4683734173067693, 'learning_rate': 0.09194974142998634, 'n_estimators': 288}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:51,051] Trial 93 finished with value: 9.896749108022751 and parameters: {'booster': 'gbtree', 'lambda': 0.3479422475081756, 'alpha': 0.0008223341259744932, 'max_depth': 10, 'subsample': 0.7008937790011771, 'colsample_bytree': 0.5521146843572353, 'learning_rate': 0.060360533804813876, 'n_estimators': 273}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:51,582] Trial 94 finished with value: 9.945099200941112 and parameters: {'booster': 'gbtree', 'lambda': 0.00011739261736873254, 'alpha': 0.00010840584157718422, 'max_depth': 10, 'subsample': 0.5829938284726355, 'colsample_bytree': 0.4015140247147671, 'learning_rate': 0.07092749931852255, 'n_estimators': 291}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:52,428] Trial 95 finished with value: 28.980041866912146 and parameters: {'booster': 'gbtree', 'lambda': 0.7407274629629905, 'alpha': 0.0002254546207485487, 'max_depth': 10, 'subsample': 0.7990443851739086, 'colsample_bytree': 0.4339579257592238, 'learning_rate': 0.002983190829508485, 'n_estimators': 283}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:53,379] Trial 96 finished with value: 9.883732033646814 and parameters: {'booster': 'gbtree', 'lambda': 0.9897876568926463, 'alpha': 2.2251835218039232e-05, 'max_depth': 10, 'subsample': 0.6314085404619877, 'colsample_bytree': 0.5103405338231191, 'learning_rate': 0.054050589777592126, 'n_estimators': 299}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:54,131] Trial 97 finished with value: 9.992201245451627 and parameters: {'booster': 'gbtree', 'lambda': 0.9125425514681298, 'alpha': 2.0607063773224834e-05, 'max_depth': 10, 'subsample': 0.6179852937559236, 'colsample_bytree': 0.5872371718531666, 'learning_rate': 0.04270090744056939, 'n_estimators': 296}. Best is trial 88 with value: 9.878081051203758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:54,463] Trial 98 finished with value: 11.261452334329963 and parameters: {'booster': 'gblinear', 'lambda': 0.21063597786109164, 'alpha': 2.980362037508211e-05, 'max_depth': 10, 'subsample': 0.540886744634193, 'colsample_bytree': 0.5116220827045959, 'learning_rate': 0.07925253439504658, 'n_estimators': 277}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:54,943] Trial 99 finished with value: 9.915183433637228 and parameters: {'booster': 'gbtree', 'lambda': 0.38981387943463613, 'alpha': 5.4510933735433264e-05, 'max_depth': 10, 'subsample': 0.8797589291345643, 'colsample_bytree': 0.34527742384214527, 'learning_rate': 0.09033250367462965, 'n_estimators': 300}. Best is trial 88 with value: 9.878081051203758.\n",
      "[I 2023-12-26 16:06:54,948] A new study created in memory with name: no-name-873e0c24-bb56-45c4-8ac6-3cf1699cde15\n",
      "[I 2023-12-26 16:06:55,036] Trial 0 finished with value: 0.5790497788991015 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 0.5790497788991015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 9.878081051203758\n",
      "  Params: \n",
      "    booster: gbtree\n",
      "    lambda: 0.963761515817317\n",
      "    alpha: 0.0002325915040754197\n",
      "    max_depth: 10\n",
      "    subsample: 0.7602569096629045\n",
      "    colsample_bytree: 0.40276183987453607\n",
      "    learning_rate: 0.08049851657031563\n",
      "    n_estimators: 281\n",
      "[16:06:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:06:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:55,205] Trial 1 finished with value: 0.5788602802415962 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 1 with value: 0.5788602802415962.\n",
      "[I 2023-12-26 16:06:55,434] Trial 2 finished with value: 0.9170069021721409 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 1 with value: 0.5788602802415962.\n",
      "[I 2023-12-26 16:06:55,950] Trial 3 finished with value: 0.5776136064529419 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 3 with value: 0.5776136064529419.\n",
      "[I 2023-12-26 16:06:56,057] Trial 4 finished with value: 0.5788101757606959 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 3 with value: 0.5776136064529419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:06:56,498] Trial 5 finished with value: 1.600742332488979 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 3 with value: 0.5776136064529419.\n",
      "[I 2023-12-26 16:07:07,939] Trial 6 finished with value: 1.3610794403455029 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 3 with value: 0.5776136064529419.\n",
      "[I 2023-12-26 16:07:08,240] Trial 7 finished with value: 1.402769464357803 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 3 with value: 0.5776136064529419.\n",
      "[I 2023-12-26 16:07:08,527] Trial 8 finished with value: 0.9680849843809051 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 3 with value: 0.5776136064529419.\n",
      "[I 2023-12-26 16:07:09,438] Trial 9 finished with value: 1.7303312615934574 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 3 with value: 0.5776136064529419.\n",
      "[I 2023-12-26 16:07:09,703] Trial 10 finished with value: 0.7158789197712728 and parameters: {'booster': 'gbtree', 'lambda': 0.0059279800152147654, 'alpha': 0.5705541732383875, 'max_depth': 10, 'subsample': 0.5522780959073166, 'colsample_bytree': 0.3529613975730607, 'learning_rate': 0.08308860966122086, 'n_estimators': 219}. Best is trial 3 with value: 0.5776136064529419.\n",
      "[I 2023-12-26 16:07:09,797] Trial 11 finished with value: 0.5775709403922025 and parameters: {'booster': 'gblinear', 'lambda': 0.9247812499675219, 'alpha': 1.5237350586506784e-08, 'max_depth': 8, 'subsample': 0.41147748400786865, 'colsample_bytree': 0.3656073171323335, 'learning_rate': 0.03323015456178867, 'n_estimators': 131}. Best is trial 11 with value: 0.5775709403922025.\n",
      "[I 2023-12-26 16:07:09,884] Trial 12 finished with value: 0.5773543171033467 and parameters: {'booster': 'gblinear', 'lambda': 0.9818799640719645, 'alpha': 1.3387521758026677e-08, 'max_depth': 8, 'subsample': 0.431368851070941, 'colsample_bytree': 0.12008942149895044, 'learning_rate': 0.034940433308196246, 'n_estimators': 173}. Best is trial 12 with value: 0.5773543171033467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:10,205] Trial 13 finished with value: 0.5332086181640624 and parameters: {'booster': 'gblinear', 'lambda': 0.9114058934450224, 'alpha': 1.0611306752443995e-08, 'max_depth': 7, 'subsample': 0.970692835118854, 'colsample_bytree': 0.10462195935248514, 'learning_rate': 0.039796520336972854, 'n_estimators': 213}. Best is trial 13 with value: 0.5332086181640624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:10,507] Trial 14 finished with value: 0.5324088389252963 and parameters: {'booster': 'gblinear', 'lambda': 0.00453406651653231, 'alpha': 2.4364501196875037e-08, 'max_depth': 6, 'subsample': 0.9782995903702544, 'colsample_bytree': 0.10600311424052594, 'learning_rate': 0.041852090254436494, 'n_estimators': 215}. Best is trial 14 with value: 0.5324088389252963.\n",
      "[I 2023-12-26 16:07:10,756] Trial 15 finished with value: 0.5299326815235017 and parameters: {'booster': 'gblinear', 'lambda': 0.005814859673715511, 'alpha': 2.6133088365938805e-05, 'max_depth': 6, 'subsample': 0.9470267674505083, 'colsample_bytree': 0.2705590193694293, 'learning_rate': 0.09854805779801452, 'n_estimators': 224}. Best is trial 15 with value: 0.5299326815235017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:11,010] Trial 16 finished with value: 0.5299633023074773 and parameters: {'booster': 'gblinear', 'lambda': 0.006251045921765777, 'alpha': 5.243708849734769e-05, 'max_depth': 6, 'subsample': 0.9993353430356903, 'colsample_bytree': 0.27321317288923497, 'learning_rate': 0.09013052090532665, 'n_estimators': 271}. Best is trial 15 with value: 0.5299326815235017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:11,300] Trial 17 finished with value: 0.5300085036395348 and parameters: {'booster': 'gblinear', 'lambda': 0.003693917992641761, 'alpha': 2.608456155578103e-05, 'max_depth': 3, 'subsample': 0.8452654483163553, 'colsample_bytree': 0.4073950854419431, 'learning_rate': 0.07825674747336935, 'n_estimators': 288}. Best is trial 15 with value: 0.5299326815235017.\n",
      "[I 2023-12-26 16:07:11,524] Trial 18 finished with value: 0.7851104612655292 and parameters: {'booster': 'dart', 'lambda': 3.7081759816773904e-05, 'alpha': 0.0004132034078025042, 'max_depth': 5, 'subsample': 0.6785626875314997, 'colsample_bytree': 0.24764998237950664, 'learning_rate': 0.09983872115915766, 'n_estimators': 262}. Best is trial 15 with value: 0.5299326815235017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:11,904] Trial 19 finished with value: 0.580248098025039 and parameters: {'booster': 'gblinear', 'lambda': 0.023277808719766032, 'alpha': 1.1370872395746361e-05, 'max_depth': 5, 'subsample': 0.8936450089130051, 'colsample_bytree': 0.7102474224231614, 'learning_rate': 0.0026224881090256167, 'n_estimators': 254}. Best is trial 15 with value: 0.5299326815235017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:12,266] Trial 20 finished with value: 0.5301781838125289 and parameters: {'booster': 'gblinear', 'lambda': 0.0006255906957117708, 'alpha': 0.00035448419774849197, 'max_depth': 6, 'subsample': 0.655349986282793, 'colsample_bytree': 0.2833500634451222, 'learning_rate': 0.05137269141190012, 'n_estimators': 253}. Best is trial 15 with value: 0.5299326815235017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:12,560] Trial 21 finished with value: 0.5300124165347723 and parameters: {'booster': 'gblinear', 'lambda': 0.0032788844848872047, 'alpha': 3.5737169725694145e-05, 'max_depth': 3, 'subsample': 0.8806321046612567, 'colsample_bytree': 0.3904453743654843, 'learning_rate': 0.07755505237797092, 'n_estimators': 297}. Best is trial 15 with value: 0.5299326815235017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:12,934] Trial 22 finished with value: 0.5300685111790487 and parameters: {'booster': 'gblinear', 'lambda': 0.03369471235070952, 'alpha': 1.0368371494031285e-05, 'max_depth': 3, 'subsample': 0.871225799468764, 'colsample_bytree': 0.46038456160794705, 'learning_rate': 0.061200909410443705, 'n_estimators': 274}. Best is trial 15 with value: 0.5299326815235017.\n",
      "[I 2023-12-26 16:07:13,184] Trial 23 finished with value: 0.529927429129544 and parameters: {'booster': 'gblinear', 'lambda': 0.00010907223409670967, 'alpha': 9.364271326200203e-05, 'max_depth': 4, 'subsample': 0.7916441810921575, 'colsample_bytree': 0.4359099519658952, 'learning_rate': 0.09985898127218559, 'n_estimators': 237}. Best is trial 23 with value: 0.529927429129544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:13,291] Trial 24 finished with value: 0.5788611103519458 and parameters: {'booster': 'gblinear', 'lambda': 4.5219999759955366e-05, 'alpha': 0.004026980785091886, 'max_depth': 4, 'subsample': 0.9733418244116243, 'colsample_bytree': 0.3031125972894836, 'learning_rate': 0.026242659949301333, 'n_estimators': 241}. Best is trial 23 with value: 0.529927429129544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:13,604] Trial 25 finished with value: 0.9086988757407828 and parameters: {'booster': 'dart', 'lambda': 0.00034868345111101895, 'alpha': 0.0001390376359286973, 'max_depth': 5, 'subsample': 0.7360062397043341, 'colsample_bytree': 0.21993842786456885, 'learning_rate': 0.05847167764786659, 'n_estimators': 193}. Best is trial 23 with value: 0.529927429129544.\n",
      "[I 2023-12-26 16:07:13,857] Trial 26 finished with value: 0.5299267589447162 and parameters: {'booster': 'gblinear', 'lambda': 8.909417027577913e-07, 'alpha': 0.0016029184591505078, 'max_depth': 7, 'subsample': 0.9216316406266692, 'colsample_bytree': 0.485285682557434, 'learning_rate': 0.09647360456010387, 'n_estimators': 270}. Best is trial 26 with value: 0.5299267589447162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:14,180] Trial 27 finished with value: 0.578742784648181 and parameters: {'booster': 'gblinear', 'lambda': 8.214186701501071e-07, 'alpha': 0.05404882510724897, 'max_depth': 7, 'subsample': 0.8262721104291469, 'colsample_bytree': 0.46216005800585885, 'learning_rate': 0.0036730563834552416, 'n_estimators': 196}. Best is trial 26 with value: 0.5299267589447162.\n",
      "[I 2023-12-26 16:07:14,299] Trial 28 finished with value: 0.5789622558524076 and parameters: {'booster': 'gblinear', 'lambda': 1.0048399620447198e-08, 'alpha': 0.001826637884996049, 'max_depth': 7, 'subsample': 0.917477330362823, 'colsample_bytree': 0.9918798974081384, 'learning_rate': 0.02274557709237894, 'n_estimators': 237}. Best is trial 26 with value: 0.5299267589447162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:14,654] Trial 29 finished with value: 0.530428278500631 and parameters: {'booster': 'gblinear', 'lambda': 2.889022713151846e-07, 'alpha': 0.00017738871130805665, 'max_depth': 4, 'subsample': 0.647534685377915, 'colsample_bytree': 0.5144212517757517, 'learning_rate': 0.04988643061375633, 'n_estimators': 236}. Best is trial 26 with value: 0.5299267589447162.\n",
      "[I 2023-12-26 16:07:17,277] Trial 30 finished with value: 0.9588052508384669 and parameters: {'booster': 'dart', 'lambda': 7.798262297867746e-06, 'alpha': 0.10071683589960731, 'max_depth': 5, 'subsample': 0.7291832075480641, 'colsample_bytree': 0.6391356169862469, 'learning_rate': 0.009590200347595956, 'n_estimators': 200}. Best is trial 26 with value: 0.5299267589447162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:17,534] Trial 31 finished with value: 0.5299409264516614 and parameters: {'booster': 'gblinear', 'lambda': 0.0010555199443798144, 'alpha': 0.0008773859378614747, 'max_depth': 6, 'subsample': 0.9406575639956914, 'colsample_bytree': 0.3466140689817051, 'learning_rate': 0.09601270068802957, 'n_estimators': 273}. Best is trial 26 with value: 0.5299267589447162.\n",
      "[I 2023-12-26 16:07:17,786] Trial 32 finished with value: 0.529918682324832 and parameters: {'booster': 'gblinear', 'lambda': 0.0012490342098710474, 'alpha': 0.0016511341324435694, 'max_depth': 6, 'subsample': 0.9203054411503461, 'colsample_bytree': 0.33965526237816973, 'learning_rate': 0.09749705967304115, 'n_estimators': 270}. Best is trial 32 with value: 0.529918682324832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:18,112] Trial 33 finished with value: 0.5299756671086839 and parameters: {'booster': 'gblinear', 'lambda': 0.00012827032253559365, 'alpha': 0.006763739170179078, 'max_depth': 4, 'subsample': 0.8059508799557478, 'colsample_bytree': 0.41898139932421447, 'learning_rate': 0.06720151251817881, 'n_estimators': 249}. Best is trial 32 with value: 0.529918682324832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:18,354] Trial 34 finished with value: 0.5296765634458359 and parameters: {'booster': 'gblinear', 'lambda': 2.1127508171642428e-06, 'alpha': 0.026766893481202855, 'max_depth': 7, 'subsample': 0.9219172852775852, 'colsample_bytree': 0.5360578896336218, 'learning_rate': 0.09893402402266628, 'n_estimators': 225}. Best is trial 34 with value: 0.5296765634458359.\n",
      "[I 2023-12-26 16:07:18,481] Trial 35 finished with value: 0.5780372146710958 and parameters: {'booster': 'gblinear', 'lambda': 1.2190965444740819e-06, 'alpha': 0.05944787722290443, 'max_depth': 9, 'subsample': 0.9076077772703993, 'colsample_bytree': 0.6387373355972723, 'learning_rate': 0.018681588505855426, 'n_estimators': 285}. Best is trial 34 with value: 0.5296765634458359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:18,870] Trial 36 finished with value: 0.5302581490991323 and parameters: {'booster': 'gblinear', 'lambda': 1.7561644895954908e-07, 'alpha': 0.011629745583694244, 'max_depth': 7, 'subsample': 0.785524106655394, 'colsample_bytree': 0.556086632286917, 'learning_rate': 0.046218277964653894, 'n_estimators': 263}. Best is trial 34 with value: 0.5296765634458359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:19,161] Trial 37 finished with value: 0.5299951326030575 and parameters: {'booster': 'gblinear', 'lambda': 2.541289153559193e-06, 'alpha': 0.0016487076148814163, 'max_depth': 9, 'subsample': 0.8344766812025612, 'colsample_bytree': 0.7617069403554453, 'learning_rate': 0.07634517234262583, 'n_estimators': 229}. Best is trial 34 with value: 0.5296765634458359.\n",
      "[I 2023-12-26 16:07:19,593] Trial 38 finished with value: 0.8273310157044294 and parameters: {'booster': 'gbtree', 'lambda': 3.1889220361751984e-05, 'alpha': 0.02713263569279502, 'max_depth': 8, 'subsample': 0.6960798662054524, 'colsample_bytree': 0.5043777631476177, 'learning_rate': 0.027156259270513128, 'n_estimators': 187}. Best is trial 34 with value: 0.5296765634458359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:19,939] Trial 39 finished with value: 0.5290791703141443 and parameters: {'booster': 'gblinear', 'lambda': 2.628372988577902e-06, 'alpha': 0.12851530584176235, 'max_depth': 7, 'subsample': 0.49214556069796767, 'colsample_bytree': 0.6164175635097008, 'learning_rate': 0.06826470028661803, 'n_estimators': 286}. Best is trial 39 with value: 0.5290791703141443.\n",
      "[I 2023-12-26 16:07:20,083] Trial 40 finished with value: 0.5768157413778784 and parameters: {'booster': 'gblinear', 'lambda': 1.571525146308311e-07, 'alpha': 0.134389652559349, 'max_depth': 7, 'subsample': 0.4963792090996138, 'colsample_bytree': 0.7270053264994758, 'learning_rate': 0.014524153296189236, 'n_estimators': 279}. Best is trial 39 with value: 0.5290791703141443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:20,417] Trial 41 finished with value: 0.530026588527035 and parameters: {'booster': 'gblinear', 'lambda': 2.7879733874797755e-06, 'alpha': 0.0020888301901350803, 'max_depth': 7, 'subsample': 0.473163658321626, 'colsample_bytree': 0.6045354307333912, 'learning_rate': 0.06747268390321283, 'n_estimators': 297}. Best is trial 39 with value: 0.5290791703141443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:20,792] Trial 42 finished with value: 0.5290123750956636 and parameters: {'booster': 'gblinear', 'lambda': 1.1336307646382024e-05, 'alpha': 0.26965394433276835, 'max_depth': 8, 'subsample': 0.5971950668163767, 'colsample_bytree': 0.5306405404329179, 'learning_rate': 0.056664539961187026, 'n_estimators': 259}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:21,051] Trial 43 finished with value: 0.6163884684375432 and parameters: {'booster': 'gbtree', 'lambda': 1.770869740227748e-05, 'alpha': 0.23781698462850231, 'max_depth': 8, 'subsample': 0.26716228120428703, 'colsample_bytree': 0.6001724763521068, 'learning_rate': 0.052758478556115714, 'n_estimators': 262}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:21,253] Trial 44 finished with value: 0.5327007413019329 and parameters: {'booster': 'gblinear', 'lambda': 6.802711382698076e-08, 'alpha': 0.9436075927419246, 'max_depth': 8, 'subsample': 0.10130501061347807, 'colsample_bytree': 0.5525176927630607, 'learning_rate': 0.06804499901992746, 'n_estimators': 286}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:22,027] Trial 45 finished with value: 0.6642408572157767 and parameters: {'booster': 'dart', 'lambda': 2.0878201838274e-06, 'alpha': 0.2699701380674673, 'max_depth': 7, 'subsample': 0.32338301307619893, 'colsample_bytree': 0.5193600881458307, 'learning_rate': 0.04168996418228538, 'n_estimators': 248}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:22,257] Trial 46 finished with value: 0.5784714816803257 and parameters: {'booster': 'gblinear', 'lambda': 5.248251967187026e-06, 'alpha': 0.02646239171823683, 'max_depth': 9, 'subsample': 0.4969364226830344, 'colsample_bytree': 0.6042577401928038, 'learning_rate': 0.006554127338772597, 'n_estimators': 266}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:22,361] Trial 47 finished with value: 0.5782751903359749 and parameters: {'booster': 'gblinear', 'lambda': 6.330346770600387e-07, 'alpha': 0.014436353135087485, 'max_depth': 8, 'subsample': 0.5670038362608568, 'colsample_bytree': 0.8695239605611689, 'learning_rate': 0.03406715374803559, 'n_estimators': 210}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:22,543] Trial 48 finished with value: 0.8319796394104283 and parameters: {'booster': 'gbtree', 'lambda': 1.4786084277520964e-05, 'alpha': 0.255723630943991, 'max_depth': 6, 'subsample': 0.6021780464420273, 'colsample_bytree': 0.6651282031370787, 'learning_rate': 0.079461620069406, 'n_estimators': 148}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:22,972] Trial 49 finished with value: 0.529751372881676 and parameters: {'booster': 'gblinear', 'lambda': 3.75245712805344e-07, 'alpha': 0.03519699213436323, 'max_depth': 7, 'subsample': 0.6081789172385578, 'colsample_bytree': 0.3396206493203128, 'learning_rate': 0.056684821836931014, 'n_estimators': 281}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:23,086] Trial 50 finished with value: 0.5780516872667286 and parameters: {'booster': 'gblinear', 'lambda': 3.559789518086775e-07, 'alpha': 0.034390875851807015, 'max_depth': 9, 'subsample': 0.5979981544143712, 'colsample_bytree': 0.32249193428207085, 'learning_rate': 0.0314819980404359, 'n_estimators': 286}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:23,464] Trial 51 finished with value: 0.5293310638758689 and parameters: {'booster': 'gblinear', 'lambda': 1.3905530673197757e-06, 'alpha': 0.08825298442457576, 'max_depth': 7, 'subsample': 0.34551038393881345, 'colsample_bytree': 0.369537203825564, 'learning_rate': 0.05892378594081482, 'n_estimators': 300}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:23,834] Trial 52 finished with value: 0.5292376484283028 and parameters: {'booster': 'gblinear', 'lambda': 4.033277519657269e-06, 'alpha': 0.10398788533917512, 'max_depth': 8, 'subsample': 0.31551776712289137, 'colsample_bytree': 0.1659836379307859, 'learning_rate': 0.062255230725242215, 'n_estimators': 296}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:24,260] Trial 53 finished with value: 0.5314123670151245 and parameters: {'booster': 'gblinear', 'lambda': 4.97298427785552e-06, 'alpha': 0.4561435264990823, 'max_depth': 8, 'subsample': 0.1918212896659917, 'colsample_bytree': 0.16053680099453557, 'learning_rate': 0.04093941570553124, 'n_estimators': 299}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:24,672] Trial 54 finished with value: 0.5293278403260391 and parameters: {'booster': 'gblinear', 'lambda': 6.993617290683443e-08, 'alpha': 0.09081121685642653, 'max_depth': 8, 'subsample': 0.33986423749719136, 'colsample_bytree': 0.22312779880458103, 'learning_rate': 0.05574690806391925, 'n_estimators': 290}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:25,103] Trial 55 finished with value: 0.5292172410172414 and parameters: {'booster': 'gblinear', 'lambda': 5.068111687277953e-08, 'alpha': 0.13569035516849665, 'max_depth': 9, 'subsample': 0.3466010819058367, 'colsample_bytree': 0.20278853757622567, 'learning_rate': 0.045633624497093996, 'n_estimators': 300}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:25,510] Trial 56 finished with value: 0.5293049328512253 and parameters: {'booster': 'gblinear', 'lambda': 3.5955350320925497e-08, 'alpha': 0.11285918156166819, 'max_depth': 10, 'subsample': 0.34215553337049326, 'colsample_bytree': 0.19860148055952162, 'learning_rate': 0.04698800596895281, 'n_estimators': 291}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:26,548] Trial 57 finished with value: 0.7799283976533098 and parameters: {'booster': 'dart', 'lambda': 2.4843452485170173e-08, 'alpha': 0.17390831401885695, 'max_depth': 10, 'subsample': 0.40617403300773053, 'colsample_bytree': 0.19168895309726963, 'learning_rate': 0.021853137800512918, 'n_estimators': 292}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:26,771] Trial 58 finished with value: 0.5371791209042344 and parameters: {'booster': 'gblinear', 'lambda': 6.412484359370375e-08, 'alpha': 0.9722044946065105, 'max_depth': 10, 'subsample': 0.31679488191833444, 'colsample_bytree': 0.14105576510192636, 'learning_rate': 0.03645970916795709, 'n_estimators': 115}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:27,176] Trial 59 finished with value: 0.5779895962318874 and parameters: {'booster': 'gbtree', 'lambda': 1.4328316839047801e-08, 'alpha': 0.3898209707004666, 'max_depth': 9, 'subsample': 0.24281263220360277, 'colsample_bytree': 0.22997124231409685, 'learning_rate': 0.027585518524709186, 'n_estimators': 291}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:27,587] Trial 60 finished with value: 0.5294234952534715 and parameters: {'booster': 'gblinear', 'lambda': 5.430356527101888e-08, 'alpha': 0.09398697384952454, 'max_depth': 9, 'subsample': 0.4476093864033707, 'colsample_bytree': 0.19371663299785563, 'learning_rate': 0.0482245960376903, 'n_estimators': 278}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:27,955] Trial 61 finished with value: 0.5294531964602535 and parameters: {'booster': 'gblinear', 'lambda': 1.5322812979284777e-07, 'alpha': 0.06700776705197187, 'max_depth': 8, 'subsample': 0.34898339239271026, 'colsample_bytree': 0.25711405346775484, 'learning_rate': 0.06364901820435923, 'n_estimators': 300}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:28,361] Trial 62 finished with value: 0.5292757722340762 and parameters: {'booster': 'gblinear', 'lambda': 2.924179118926749e-08, 'alpha': 0.13495066837322803, 'max_depth': 10, 'subsample': 0.3703927364276731, 'colsample_bytree': 0.20911788228721934, 'learning_rate': 0.04537174644579202, 'n_estimators': 290}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:28,734] Trial 63 finished with value: 0.5325445783519309 and parameters: {'booster': 'gblinear', 'lambda': 2.2311338383093238e-08, 'alpha': 0.5166937698081129, 'max_depth': 10, 'subsample': 0.39198452331753986, 'colsample_bytree': 0.1287517861289578, 'learning_rate': 0.045068948822176526, 'n_estimators': 289}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:29,103] Trial 64 finished with value: 0.5337822529170066 and parameters: {'booster': 'gblinear', 'lambda': 3.901591376918676e-08, 'alpha': 0.17499017286095706, 'max_depth': 10, 'subsample': 0.5301584347626405, 'colsample_bytree': 0.21478705857640207, 'learning_rate': 0.030244324388245567, 'n_estimators': 259}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:29,198] Trial 65 finished with value: 0.578360795103796 and parameters: {'booster': 'gblinear', 'lambda': 1.0639881744203257e-07, 'alpha': 2.3360215033761126e-07, 'max_depth': 9, 'subsample': 0.29783052005061544, 'colsample_bytree': 0.17707328685330748, 'learning_rate': 0.03714385065707414, 'n_estimators': 280}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:29,499] Trial 66 finished with value: 0.5298757337544062 and parameters: {'booster': 'gblinear', 'lambda': 1.7619070170738542e-08, 'alpha': 0.013765876103281671, 'max_depth': 10, 'subsample': 0.36046607862928576, 'colsample_bytree': 0.13928178633239885, 'learning_rate': 0.07778843463673041, 'n_estimators': 292}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:29,901] Trial 67 finished with value: 0.5909192016462212 and parameters: {'booster': 'gblinear', 'lambda': 1.0438101350733631e-07, 'alpha': 0.007395399625014991, 'max_depth': 10, 'subsample': 0.43216180480397065, 'colsample_bytree': 0.28825099939314475, 'learning_rate': 0.001950077382788632, 'n_estimators': 274}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:30,035] Trial 68 finished with value: 0.5591208690922009 and parameters: {'booster': 'gblinear', 'lambda': 3.6365642609241445e-08, 'alpha': 8.745639035345538e-07, 'max_depth': 9, 'subsample': 0.2731320934666792, 'colsample_bytree': 0.2267657512935608, 'learning_rate': 0.05243292368112803, 'n_estimators': 55}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:31,034] Trial 69 finished with value: 0.7469545257472555 and parameters: {'booster': 'dart', 'lambda': 1.0277337765221451e-08, 'alpha': 7.412934391589477e-08, 'max_depth': 8, 'subsample': 0.2342149190985915, 'colsample_bytree': 0.16394472647476643, 'learning_rate': 0.019351854104975343, 'n_estimators': 253}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:31,212] Trial 70 finished with value: 0.5768978183563442 and parameters: {'booster': 'gblinear', 'lambda': 1.4883244837588473e-05, 'alpha': 0.13514265560431973, 'max_depth': 10, 'subsample': 0.18923199741232952, 'colsample_bytree': 0.24990768580287948, 'learning_rate': 0.010045871325042886, 'n_estimators': 281}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:31,602] Trial 71 finished with value: 0.5294329456869324 and parameters: {'booster': 'gblinear', 'lambda': 1.1002854913898358e-06, 'alpha': 0.0746243941993013, 'max_depth': 9, 'subsample': 0.34345462686350003, 'colsample_bytree': 0.3825132122687182, 'learning_rate': 0.05736765853461472, 'n_estimators': 300}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:31,942] Trial 72 finished with value: 0.5296290809161043 and parameters: {'booster': 'gblinear', 'lambda': 3.7627829381767694e-06, 'alpha': 0.04258642106771823, 'max_depth': 8, 'subsample': 0.36794272526639044, 'colsample_bytree': 0.11167581813347113, 'learning_rate': 0.07289967052902761, 'n_estimators': 294}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:32,319] Trial 73 finished with value: 0.5295515884329739 and parameters: {'booster': 'gblinear', 'lambda': 2.3390602597746288e-07, 'alpha': 0.27284013950660185, 'max_depth': 8, 'subsample': 0.29903218920814745, 'colsample_bytree': 0.30968105074962976, 'learning_rate': 0.044270722323309315, 'n_estimators': 268}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:32,718] Trial 74 finished with value: 0.529256378983798 and parameters: {'booster': 'gblinear', 'lambda': 1.5244358475020524e-06, 'alpha': 0.10223781838505382, 'max_depth': 8, 'subsample': 0.3951991780961167, 'colsample_bytree': 0.21159543342134268, 'learning_rate': 0.06015491551726381, 'n_estimators': 287}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:32,913] Trial 75 finished with value: 0.5334367607935379 and parameters: {'booster': 'gblinear', 'lambda': 4.757948324293249e-07, 'alpha': 0.6656281436643084, 'max_depth': 8, 'subsample': 0.4613226177100468, 'colsample_bytree': 0.19943741364790396, 'learning_rate': 0.08342009336551369, 'n_estimators': 284}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:33,294] Trial 76 finished with value: 0.5297635070156289 and parameters: {'booster': 'gblinear', 'lambda': 9.493434331513579e-06, 'alpha': 0.341703884520671, 'max_depth': 9, 'subsample': 0.39883707904440335, 'colsample_bytree': 0.15922503913287256, 'learning_rate': 0.053539466794425686, 'n_estimators': 273}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:33,737] Trial 77 finished with value: 0.5296661973979375 and parameters: {'booster': 'gblinear', 'lambda': 6.871745922250129e-05, 'alpha': 0.13499377903349524, 'max_depth': 9, 'subsample': 0.37277791137246197, 'colsample_bytree': 0.10010790132492403, 'learning_rate': 0.039801986546035076, 'n_estimators': 291}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:34,081] Trial 78 finished with value: 0.5298474431582237 and parameters: {'booster': 'gblinear', 'lambda': 8.533826844915187e-08, 'alpha': 0.02171722922190143, 'max_depth': 8, 'subsample': 0.5275153901703334, 'colsample_bytree': 0.9797857039663993, 'learning_rate': 0.06530033869282328, 'n_estimators': 279}. Best is trial 42 with value: 0.5290123750956636.\n",
      "[I 2023-12-26 16:07:34,260] Trial 79 finished with value: 0.855981120932592 and parameters: {'booster': 'gbtree', 'lambda': 3.4456148573526546e-08, 'alpha': 0.051924034910306775, 'max_depth': 10, 'subsample': 0.48999382633175914, 'colsample_bytree': 0.27001371731193236, 'learning_rate': 0.08339138753008611, 'n_estimators': 243}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:34,582] Trial 80 finished with value: 0.5333240539080476 and parameters: {'booster': 'gblinear', 'lambda': 5.931122123913961e-07, 'alpha': 0.611865209922939, 'max_depth': 8, 'subsample': 0.4329630018453601, 'colsample_bytree': 0.23696895882212285, 'learning_rate': 0.048516596162215736, 'n_estimators': 256}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:34,973] Trial 81 finished with value: 0.5292775281270344 and parameters: {'booster': 'gblinear', 'lambda': 1.823390282544471e-06, 'alpha': 0.09566289490135613, 'max_depth': 7, 'subsample': 0.33256353878423056, 'colsample_bytree': 0.19403654617655358, 'learning_rate': 0.06173420842991171, 'n_estimators': 295}. Best is trial 42 with value: 0.5290123750956636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:35,325] Trial 82 finished with value: 0.528927000995096 and parameters: {'booster': 'gblinear', 'lambda': 1.748961129475529e-06, 'alpha': 0.17232870198653064, 'max_depth': 8, 'subsample': 0.3226434175039233, 'colsample_bytree': 0.2036039534808901, 'learning_rate': 0.07089900532340361, 'n_estimators': 289}. Best is trial 82 with value: 0.528927000995096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:35,615] Trial 83 finished with value: 0.5288610425713944 and parameters: {'booster': 'gblinear', 'lambda': 2.209176941383196e-05, 'alpha': 0.1764301947200935, 'max_depth': 7, 'subsample': 0.3120496300761024, 'colsample_bytree': 0.2063516911168148, 'learning_rate': 0.08714689981047405, 'n_estimators': 267}. Best is trial 83 with value: 0.5288610425713944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:35,912] Trial 84 finished with value: 0.5287847417021451 and parameters: {'booster': 'gblinear', 'lambda': 2.6975155583421707e-05, 'alpha': 0.22073645118608545, 'max_depth': 7, 'subsample': 0.2965346561058327, 'colsample_bytree': 0.1483679364296826, 'learning_rate': 0.08844781306421212, 'n_estimators': 267}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:36,205] Trial 85 finished with value: 0.5288023445704212 and parameters: {'booster': 'gblinear', 'lambda': 2.4420499205225175e-05, 'alpha': 0.19334273346820902, 'max_depth': 7, 'subsample': 0.2578343405515914, 'colsample_bytree': 0.1460617837667009, 'learning_rate': 0.08744841481083136, 'n_estimators': 264}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:36,495] Trial 86 finished with value: 0.5288264413946839 and parameters: {'booster': 'gblinear', 'lambda': 2.7464930797719598e-05, 'alpha': 0.18476337520832473, 'max_depth': 7, 'subsample': 0.3004429205981863, 'colsample_bytree': 0.14438167445823002, 'learning_rate': 0.08785199568608298, 'n_estimators': 265}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:36,783] Trial 87 finished with value: 0.5287853347656389 and parameters: {'booster': 'gblinear', 'lambda': 0.0001802568349530087, 'alpha': 0.19982559053580712, 'max_depth': 6, 'subsample': 0.21124114408568484, 'colsample_bytree': 0.14536889088048172, 'learning_rate': 0.08962995979136353, 'n_estimators': 264}. Best is trial 84 with value: 0.5287847417021451.\n",
      "[I 2023-12-26 16:07:37,027] Trial 88 finished with value: 0.5960713566819282 and parameters: {'booster': 'dart', 'lambda': 2.570049446063325e-05, 'alpha': 0.2118724404163581, 'max_depth': 6, 'subsample': 0.1576529165000074, 'colsample_bytree': 0.140683434456317, 'learning_rate': 0.08981646542794781, 'n_estimators': 249}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:37,271] Trial 89 finished with value: 0.5305472046490675 and parameters: {'booster': 'gblinear', 'lambda': 5.2380015391446117e-05, 'alpha': 0.39562527973221623, 'max_depth': 6, 'subsample': 0.21078643332529975, 'colsample_bytree': 0.12402750550047963, 'learning_rate': 0.09021284847565002, 'n_estimators': 264}. Best is trial 84 with value: 0.5287847417021451.\n",
      "[I 2023-12-26 16:07:37,495] Trial 90 finished with value: 0.5334693821162394 and parameters: {'booster': 'gblinear', 'lambda': 0.00019402148053168202, 'alpha': 0.6024538421085456, 'max_depth': 7, 'subsample': 0.2517497972961694, 'colsample_bytree': 0.5813518372488146, 'learning_rate': 0.07353557578142406, 'n_estimators': 231}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:37,857] Trial 91 finished with value: 0.5288719548700064 and parameters: {'booster': 'gblinear', 'lambda': 8.244531055553931e-05, 'alpha': 0.20250212773144494, 'max_depth': 7, 'subsample': 0.29403977363356965, 'colsample_bytree': 0.16897088529032955, 'learning_rate': 0.07029488053749954, 'n_estimators': 268}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:38,140] Trial 92 finished with value: 0.5288009027803324 and parameters: {'booster': 'gblinear', 'lambda': 8.437893477202687e-05, 'alpha': 0.23217573302234198, 'max_depth': 7, 'subsample': 0.2900710552599707, 'colsample_bytree': 0.1464642467346646, 'learning_rate': 0.08839969283162154, 'n_estimators': 259}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:38,419] Trial 93 finished with value: 0.5292999340736703 and parameters: {'booster': 'gblinear', 'lambda': 7.872583342568921e-05, 'alpha': 0.3019315635890366, 'max_depth': 7, 'subsample': 0.21745211896350314, 'colsample_bytree': 0.1556960625763304, 'learning_rate': 0.08545311895019905, 'n_estimators': 246}. Best is trial 84 with value: 0.5287847417021451.\n",
      "[I 2023-12-26 16:07:38,617] Trial 94 finished with value: 0.5327967419036448 and parameters: {'booster': 'gblinear', 'lambda': 0.00034637173547739475, 'alpha': 0.8971570356434279, 'max_depth': 7, 'subsample': 0.2887872575172013, 'colsample_bytree': 0.17637238397404806, 'learning_rate': 0.07252262231997794, 'n_estimators': 257}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:38,903] Trial 95 finished with value: 0.528792224953708 and parameters: {'booster': 'gblinear', 'lambda': 0.00016757121347239824, 'alpha': 0.1986487750190777, 'max_depth': 6, 'subsample': 0.11181310063367769, 'colsample_bytree': 0.11855458435117856, 'learning_rate': 0.0898482255075468, 'n_estimators': 267}. Best is trial 84 with value: 0.5287847417021451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:39,185] Trial 96 finished with value: 0.5287867529969238 and parameters: {'booster': 'gblinear', 'lambda': 0.00017832316674230516, 'alpha': 0.2049568503575544, 'max_depth': 6, 'subsample': 0.1604699904060733, 'colsample_bytree': 0.12328481317572149, 'learning_rate': 0.08915609370149899, 'n_estimators': 264}. Best is trial 84 with value: 0.5287847417021451.\n",
      "[I 2023-12-26 16:07:39,447] Trial 97 finished with value: 0.5287548818544711 and parameters: {'booster': 'gblinear', 'lambda': 0.00017195035835053832, 'alpha': 0.19518072122405722, 'max_depth': 6, 'subsample': 0.10434163673348415, 'colsample_bytree': 0.11927426838696067, 'learning_rate': 0.09998666347581237, 'n_estimators': 269}. Best is trial 97 with value: 0.5287548818544711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:39,676] Trial 98 finished with value: 0.6254369597674505 and parameters: {'booster': 'gbtree', 'lambda': 0.0001495672161389956, 'alpha': 0.062355692734117056, 'max_depth': 6, 'subsample': 0.10702716692439326, 'colsample_bytree': 0.12808401153170818, 'learning_rate': 0.0897717637198688, 'n_estimators': 265}. Best is trial 97 with value: 0.5287548818544711.\n",
      "[I 2023-12-26 16:07:39,929] Trial 99 finished with value: 0.5297490348554638 and parameters: {'booster': 'gblinear', 'lambda': 0.0007499407568802109, 'alpha': 0.01966722789879205, 'max_depth': 6, 'subsample': 0.12752220185493834, 'colsample_bytree': 0.10485025280585161, 'learning_rate': 0.09870702817066086, 'n_estimators': 240}. Best is trial 97 with value: 0.5287548818544711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:39,933] A new study created in memory with name: no-name-a96f443e-200d-4e46-a35a-b10f3b473397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.5287548818544711\n",
      "  Params: \n",
      "    booster: gblinear\n",
      "    lambda: 0.00017195035835053832\n",
      "    alpha: 0.19518072122405722\n",
      "    max_depth: 6\n",
      "    subsample: 0.10434163673348415\n",
      "    colsample_bytree: 0.11927426838696067\n",
      "    learning_rate: 0.09998666347581237\n",
      "    n_estimators: 269\n",
      "[16:07:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:40,218] Trial 0 finished with value: 6.248936859353819 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 6.248936859353819.\n",
      "[I 2023-12-26 16:07:40,379] Trial 1 finished with value: 6.547871577255041 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 0 with value: 6.248936859353819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:40,610] Trial 2 finished with value: 7.841805602309693 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 0 with value: 6.248936859353819.\n",
      "[I 2023-12-26 16:07:41,233] Trial 3 finished with value: 5.814613506992985 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 3 with value: 5.814613506992985.\n",
      "[I 2023-12-26 16:07:41,376] Trial 4 finished with value: 6.466860530867207 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 3 with value: 5.814613506992985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:07:41,833] Trial 5 finished with value: 12.08417250836429 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 3 with value: 5.814613506992985.\n",
      "[I 2023-12-26 16:07:53,328] Trial 6 finished with value: 9.821137136239875 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 3 with value: 5.814613506992985.\n",
      "[I 2023-12-26 16:07:53,625] Trial 7 finished with value: 10.742623093842806 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 3 with value: 5.814613506992985.\n",
      "[I 2023-12-26 16:07:53,971] Trial 8 finished with value: 5.48921551196303 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 8 with value: 5.48921551196303.\n",
      "[I 2023-12-26 16:07:54,895] Trial 9 finished with value: 12.935293997528566 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 8 with value: 5.48921551196303.\n",
      "[I 2023-12-26 16:07:55,199] Trial 10 finished with value: 5.431544470169555 and parameters: {'booster': 'gbtree', 'lambda': 1.116805293160088e-08, 'alpha': 1.1491548505141235e-08, 'max_depth': 3, 'subsample': 0.9786917711698019, 'colsample_bytree': 0.7598785099640686, 'learning_rate': 0.0881744100052964, 'n_estimators': 219}. Best is trial 10 with value: 5.431544470169555.\n",
      "[I 2023-12-26 16:07:55,504] Trial 11 finished with value: 5.474078922337919 and parameters: {'booster': 'gbtree', 'lambda': 1.0690705252212232e-08, 'alpha': 1.2070660524894436e-08, 'max_depth': 3, 'subsample': 0.9759730320176591, 'colsample_bytree': 0.7541887006644162, 'learning_rate': 0.09721966993689589, 'n_estimators': 216}. Best is trial 10 with value: 5.431544470169555.\n",
      "[I 2023-12-26 16:07:55,821] Trial 12 finished with value: 5.4800722935959625 and parameters: {'booster': 'gbtree', 'lambda': 1.0794475723127262e-08, 'alpha': 1.0798959522730386e-08, 'max_depth': 3, 'subsample': 0.984878669527521, 'colsample_bytree': 0.9982459127273846, 'learning_rate': 0.09870905101087721, 'n_estimators': 223}. Best is trial 10 with value: 5.431544470169555.\n",
      "[I 2023-12-26 16:07:56,337] Trial 13 finished with value: 5.278240353550323 and parameters: {'booster': 'gbtree', 'lambda': 2.156064753383517e-07, 'alpha': 1.1135493946509653e-08, 'max_depth': 3, 'subsample': 0.9906983098391822, 'colsample_bytree': 0.783611812201323, 'learning_rate': 0.04168043620362369, 'n_estimators': 225}. Best is trial 13 with value: 5.278240353550323.\n",
      "[I 2023-12-26 16:07:56,964] Trial 14 finished with value: 5.5713393034181635 and parameters: {'booster': 'gbtree', 'lambda': 3.138683976328395e-07, 'alpha': 6.833425663452977e-08, 'max_depth': 5, 'subsample': 0.8279214979271702, 'colsample_bytree': 0.9579003217897237, 'learning_rate': 0.03785128778994907, 'n_estimators': 270}. Best is trial 13 with value: 5.278240353550323.\n",
      "[I 2023-12-26 16:08:00,494] Trial 15 finished with value: 5.10564755748592 and parameters: {'booster': 'dart', 'lambda': 2.1265603072153366e-07, 'alpha': 2.097263173033571e-05, 'max_depth': 3, 'subsample': 0.6641735636136654, 'colsample_bytree': 0.7002281965270426, 'learning_rate': 0.03743309561243859, 'n_estimators': 196}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:01,454] Trial 16 finished with value: 7.2404848941959745 and parameters: {'booster': 'dart', 'lambda': 5.059652430289812e-07, 'alpha': 6.242247533375862e-05, 'max_depth': 5, 'subsample': 0.6483339605894612, 'colsample_bytree': 0.4301913779352223, 'learning_rate': 0.032097864674854856, 'n_estimators': 195}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:05,728] Trial 17 finished with value: 9.696498799492128 and parameters: {'booster': 'dart', 'lambda': 3.046135392550891e-05, 'alpha': 1.2538268629747142e-05, 'max_depth': 4, 'subsample': 0.6629822885855469, 'colsample_bytree': 0.65571194872476, 'learning_rate': 0.0032832100606028777, 'n_estimators': 190}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:06,678] Trial 18 finished with value: 7.352034794888431 and parameters: {'booster': 'dart', 'lambda': 0.0038731263135072095, 'alpha': 0.0006123755591883913, 'max_depth': 6, 'subsample': 0.8836598647532031, 'colsample_bytree': 0.38830576173212505, 'learning_rate': 0.04855674339657926, 'n_estimators': 253}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:13,717] Trial 19 finished with value: 5.117968633099561 and parameters: {'booster': 'dart', 'lambda': 1.4285006698659757e-07, 'alpha': 0.18702083588029045, 'max_depth': 3, 'subsample': 0.46266404530198013, 'colsample_bytree': 0.6904394509793828, 'learning_rate': 0.02359322297421984, 'n_estimators': 254}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:21,304] Trial 20 finished with value: 5.193870994738575 and parameters: {'booster': 'dart', 'lambda': 2.364374859884813e-06, 'alpha': 0.7479580089872513, 'max_depth': 4, 'subsample': 0.4870988059399894, 'colsample_bytree': 0.6679588016756784, 'learning_rate': 0.023100658482678612, 'n_estimators': 259}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:29,025] Trial 21 finished with value: 5.208653588975183 and parameters: {'booster': 'dart', 'lambda': 1.8831351715481286e-06, 'alpha': 0.4345866663710578, 'max_depth': 4, 'subsample': 0.48880087760996466, 'colsample_bytree': 0.6686237771438925, 'learning_rate': 0.021165344082691755, 'n_estimators': 261}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:31,474] Trial 22 finished with value: 6.23568447971431 and parameters: {'booster': 'dart', 'lambda': 8.561320008082154e-08, 'alpha': 0.0598419570359518, 'max_depth': 3, 'subsample': 0.49164198453808683, 'colsample_bytree': 0.6373402075354961, 'learning_rate': 0.02268118094688553, 'n_estimators': 297}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:38,498] Trial 23 finished with value: 6.177075423476685 and parameters: {'booster': 'dart', 'lambda': 1.7878242504148784e-06, 'alpha': 0.09776556050789428, 'max_depth': 4, 'subsample': 0.5900739388499122, 'colsample_bytree': 0.8761081435369776, 'learning_rate': 0.007429905898738973, 'n_estimators': 247}. Best is trial 15 with value: 5.10564755748592.\n",
      "[I 2023-12-26 16:08:45,394] Trial 24 finished with value: 5.056053821612493 and parameters: {'booster': 'dart', 'lambda': 2.3672346374812343e-06, 'alpha': 0.0006249060366860597, 'max_depth': 3, 'subsample': 0.4448136769359257, 'colsample_bytree': 0.7233950469660446, 'learning_rate': 0.02658914233771496, 'n_estimators': 277}. Best is trial 24 with value: 5.056053821612493.\n",
      "[I 2023-12-26 16:08:49,187] Trial 25 finished with value: 5.2029934558746485 and parameters: {'booster': 'dart', 'lambda': 3.132034651400191e-05, 'alpha': 0.0006419812422017992, 'max_depth': 5, 'subsample': 0.6757251746719827, 'colsample_bytree': 0.7298269955991051, 'learning_rate': 0.03600287313636307, 'n_estimators': 281}. Best is trial 24 with value: 5.056053821612493.\n",
      "[I 2023-12-26 16:08:50,668] Trial 26 finished with value: 5.142291948863687 and parameters: {'booster': 'dart', 'lambda': 6.676398533508016e-08, 'alpha': 0.002135816651222961, 'max_depth': 3, 'subsample': 0.4098066993726535, 'colsample_bytree': 0.8552324642450899, 'learning_rate': 0.06905682718461097, 'n_estimators': 198}. Best is trial 24 with value: 5.056053821612493.\n",
      "[I 2023-12-26 16:08:57,669] Trial 27 finished with value: 6.454471042908272 and parameters: {'booster': 'dart', 'lambda': 1.0209063940067835e-05, 'alpha': 1.2513107806403817e-05, 'max_depth': 6, 'subsample': 0.3161286906299361, 'colsample_bytree': 0.4840210172439978, 'learning_rate': 0.011411957644388952, 'n_estimators': 240}. Best is trial 24 with value: 5.056053821612493.\n",
      "[I 2023-12-26 16:09:03,791] Trial 28 finished with value: 5.067140417504855 and parameters: {'booster': 'dart', 'lambda': 1.0538254804297166e-07, 'alpha': 0.00016192384912868193, 'max_depth': 3, 'subsample': 0.4448925830550883, 'colsample_bytree': 0.9283281801361902, 'learning_rate': 0.03005084559074207, 'n_estimators': 287}. Best is trial 24 with value: 5.056053821612493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:09:04,203] Trial 29 finished with value: 6.2106884778305815 and parameters: {'booster': 'gblinear', 'lambda': 0.00029500569882879256, 'alpha': 0.00017625319014405734, 'max_depth': 4, 'subsample': 0.7249866279731503, 'colsample_bytree': 0.9155842196572824, 'learning_rate': 0.015298782129073756, 'n_estimators': 283}. Best is trial 24 with value: 5.056053821612493.\n",
      "[I 2023-12-26 16:09:04,437] Trial 30 finished with value: 6.100026166294046 and parameters: {'booster': 'gblinear', 'lambda': 1.1415395607156943e-06, 'alpha': 1.0794440544914004e-05, 'max_depth': 5, 'subsample': 0.5432757675490322, 'colsample_bytree': 0.9344972520365185, 'learning_rate': 0.05498125046490799, 'n_estimators': 138}. Best is trial 24 with value: 5.056053821612493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:09:10,329] Trial 31 finished with value: 5.120438695181233 and parameters: {'booster': 'dart', 'lambda': 1.0992426514577182e-07, 'alpha': 0.00022461864402845328, 'max_depth': 3, 'subsample': 0.42499318137329295, 'colsample_bytree': 0.8142006751938536, 'learning_rate': 0.03044053834098923, 'n_estimators': 277}. Best is trial 24 with value: 5.056053821612493.\n",
      "[I 2023-12-26 16:09:12,780] Trial 32 finished with value: 6.141016484069824 and parameters: {'booster': 'dart', 'lambda': 3.938525888363432e-08, 'alpha': 0.006386894127688156, 'max_depth': 3, 'subsample': 0.44601813967197773, 'colsample_bytree': 0.5973193997887652, 'learning_rate': 0.02902636503406586, 'n_estimators': 300}. Best is trial 24 with value: 5.056053821612493.\n",
      "[I 2023-12-26 16:09:21,223] Trial 33 finished with value: 5.0229215549799955 and parameters: {'booster': 'dart', 'lambda': 6.359401106330102e-07, 'alpha': 0.04949979995947364, 'max_depth': 4, 'subsample': 0.31261171433512147, 'colsample_bytree': 0.7015437228746356, 'learning_rate': 0.018577870248999474, 'n_estimators': 269}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:25,587] Trial 34 finished with value: 5.1557218961811495 and parameters: {'booster': 'dart', 'lambda': 5.095954686583202e-07, 'alpha': 0.03205108510610993, 'max_depth': 4, 'subsample': 0.10457343023305932, 'colsample_bytree': 0.7275337213240601, 'learning_rate': 0.018571591726117463, 'n_estimators': 237}. Best is trial 33 with value: 5.0229215549799955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:09:25,972] Trial 35 finished with value: 6.32086048009167 and parameters: {'booster': 'gblinear', 'lambda': 6.773285541535847e-07, 'alpha': 3.5836753114462e-05, 'max_depth': 4, 'subsample': 0.32524002144295755, 'colsample_bytree': 0.8163530237641432, 'learning_rate': 0.009410524160708254, 'n_estimators': 272}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:27,437] Trial 36 finished with value: 6.582030964294851 and parameters: {'booster': 'dart', 'lambda': 4.3996223240792e-06, 'alpha': 0.0012179975794078968, 'max_depth': 3, 'subsample': 0.25873593802146644, 'colsample_bytree': 0.6060723666941759, 'learning_rate': 0.01762318713798193, 'n_estimators': 108}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:29,928] Trial 37 finished with value: 6.649484663345825 and parameters: {'booster': 'dart', 'lambda': 2.8964051309669623e-05, 'alpha': 3.1315590573154006e-07, 'max_depth': 4, 'subsample': 0.349317953057573, 'colsample_bytree': 0.5482626581234267, 'learning_rate': 0.014269364074845295, 'n_estimators': 142}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:35,270] Trial 38 finished with value: 6.337950099645466 and parameters: {'booster': 'dart', 'lambda': 1.2286687940360869e-05, 'alpha': 0.0001273031602437115, 'max_depth': 7, 'subsample': 0.20277199949015492, 'colsample_bytree': 0.10240116514955322, 'learning_rate': 0.009850743801130846, 'n_estimators': 207}. Best is trial 33 with value: 5.0229215549799955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:09:35,672] Trial 39 finished with value: 6.047157778052761 and parameters: {'booster': 'gblinear', 'lambda': 9.305705553074348e-05, 'alpha': 2.5745650136790013e-05, 'max_depth': 10, 'subsample': 0.5319687035327407, 'colsample_bytree': 0.5213683124170361, 'learning_rate': 0.050179399221893885, 'n_estimators': 288}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:39,568] Trial 40 finished with value: 8.612634159582827 and parameters: {'booster': 'dart', 'lambda': 2.05560762461107e-07, 'alpha': 0.003441772310557826, 'max_depth': 5, 'subsample': 0.2714594574780799, 'colsample_bytree': 0.3187584618871723, 'learning_rate': 0.004380145301193661, 'n_estimators': 181}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:41,711] Trial 41 finished with value: 5.201365152869378 and parameters: {'booster': 'dart', 'lambda': 3.7037706580855473e-08, 'alpha': 0.2652533238866641, 'max_depth': 3, 'subsample': 0.6185127228701088, 'colsample_bytree': 0.7057299700905323, 'learning_rate': 0.027154101538213318, 'n_estimators': 263}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:42,558] Trial 42 finished with value: 6.150824835333976 and parameters: {'booster': 'dart', 'lambda': 1.5004850125990487e-07, 'alpha': 0.13235078287114482, 'max_depth': 3, 'subsample': 0.38461826536178345, 'colsample_bytree': 0.6132748512783956, 'learning_rate': 0.04175151473435837, 'n_estimators': 238}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:43,805] Trial 43 finished with value: 5.118359775417798 and parameters: {'booster': 'dart', 'lambda': 1.0204079525992968e-06, 'alpha': 0.012929572913603596, 'max_depth': 3, 'subsample': 0.4622771493599434, 'colsample_bytree': 0.7140003484211616, 'learning_rate': 0.07334538895661143, 'n_estimators': 158}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:49,685] Trial 44 finished with value: 5.198209897268635 and parameters: {'booster': 'dart', 'lambda': 3.4041466010950406e-06, 'alpha': 3.5141294656729588e-06, 'max_depth': 4, 'subsample': 0.5270186068114543, 'colsample_bytree': 0.7901622433382222, 'learning_rate': 0.026021343479927312, 'n_estimators': 288}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:09:56,227] Trial 45 finished with value: 5.301650915377542 and parameters: {'booster': 'dart', 'lambda': 2.503191944231215e-08, 'alpha': 0.24109789654918357, 'max_depth': 3, 'subsample': 0.38954507447038755, 'colsample_bytree': 0.8529505085869188, 'learning_rate': 0.013179018838694117, 'n_estimators': 249}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:10:02,057] Trial 46 finished with value: 5.118478388186242 and parameters: {'booster': 'dart', 'lambda': 3.390733973663297e-07, 'alpha': 0.024340340018769835, 'max_depth': 3, 'subsample': 0.34583855788270507, 'colsample_bytree': 0.761107355467838, 'learning_rate': 0.018212674715182103, 'n_estimators': 233}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:10:05,689] Trial 47 finished with value: 5.254444936907347 and parameters: {'booster': 'dart', 'lambda': 5.682880354567977e-08, 'alpha': 0.00031856182432064763, 'max_depth': 9, 'subsample': 0.5872078853721663, 'colsample_bytree': 0.6963801369468625, 'learning_rate': 0.03406715374803559, 'n_estimators': 268}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:10:06,649] Trial 48 finished with value: 7.178678271790944 and parameters: {'booster': 'dart', 'lambda': 1.7701910339937718e-07, 'alpha': 7.04035015006034e-05, 'max_depth': 4, 'subsample': 0.7059395037814818, 'colsample_bytree': 0.5522846346129324, 'learning_rate': 0.043556478475879096, 'n_estimators': 209}. Best is trial 33 with value: 5.0229215549799955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:10:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:10:07,066] Trial 49 finished with value: 6.041473644705994 and parameters: {'booster': 'gblinear', 'lambda': 2.0493760355164833e-08, 'alpha': 7.100992200043655e-07, 'max_depth': 8, 'subsample': 0.2891473241342643, 'colsample_bytree': 0.9941339819934423, 'learning_rate': 0.06442155647142836, 'n_estimators': 293}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:10:15,032] Trial 50 finished with value: 5.090493159321127 and parameters: {'booster': 'dart', 'lambda': 0.7972579443245569, 'alpha': 2.596654969009547e-06, 'max_depth': 3, 'subsample': 0.22829377044020288, 'colsample_bytree': 0.9020208135165385, 'learning_rate': 0.020304732690944124, 'n_estimators': 276}. Best is trial 33 with value: 5.0229215549799955.\n",
      "[I 2023-12-26 16:10:22,828] Trial 51 finished with value: 5.008827098721021 and parameters: {'booster': 'dart', 'lambda': 0.0027153173248127757, 'alpha': 6.89013356153065e-06, 'max_depth': 3, 'subsample': 0.1579881139597663, 'colsample_bytree': 0.9034407910616159, 'learning_rate': 0.02158973784449041, 'n_estimators': 277}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:10:31,026] Trial 52 finished with value: 5.077798991003864 and parameters: {'booster': 'dart', 'lambda': 0.906875759148379, 'alpha': 1.7176041932697738e-06, 'max_depth': 3, 'subsample': 0.15245244301352098, 'colsample_bytree': 0.9051978718382612, 'learning_rate': 0.020059268205076294, 'n_estimators': 280}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:10:38,933] Trial 53 finished with value: 5.041393352888273 and parameters: {'booster': 'dart', 'lambda': 0.9959705043123284, 'alpha': 2.891044022352541e-06, 'max_depth': 3, 'subsample': 0.15078104679948345, 'colsample_bytree': 0.9020142233935861, 'learning_rate': 0.020586878640569423, 'n_estimators': 276}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:10:39,701] Trial 54 finished with value: 9.189271399962193 and parameters: {'booster': 'gbtree', 'lambda': 0.05574236594626109, 'alpha': 5.725750395832414e-06, 'max_depth': 4, 'subsample': 0.14795518398469634, 'colsample_bytree': 0.9700104949411593, 'learning_rate': 0.0020065057687758928, 'n_estimators': 267}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:10:47,853] Trial 55 finished with value: 5.223454620793312 and parameters: {'booster': 'dart', 'lambda': 0.006141672550780271, 'alpha': 1.1902891176010836e-07, 'max_depth': 3, 'subsample': 0.13632976585388867, 'colsample_bytree': 0.88630173982131, 'learning_rate': 0.011568667065531876, 'n_estimators': 281}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:10:56,866] Trial 56 finished with value: 5.590750124836403 and parameters: {'booster': 'dart', 'lambda': 0.3175521221174107, 'alpha': 8.272446300017924e-07, 'max_depth': 4, 'subsample': 0.1758035119837673, 'colsample_bytree': 0.9457584358730872, 'learning_rate': 0.007626511067636766, 'n_estimators': 289}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:03,849] Trial 57 finished with value: 5.1024283820862095 and parameters: {'booster': 'dart', 'lambda': 0.09391534294650027, 'alpha': 1.4681750391905786e-06, 'max_depth': 3, 'subsample': 0.10888207232940367, 'colsample_bytree': 0.8439594694963422, 'learning_rate': 0.015703385821850338, 'n_estimators': 260}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:08,109] Trial 58 finished with value: 5.0935950732958375 and parameters: {'booster': 'dart', 'lambda': 0.013935409077948616, 'alpha': 4.6175989277716406e-07, 'max_depth': 4, 'subsample': 0.23424682501425342, 'colsample_bytree': 0.9252799771699148, 'learning_rate': 0.024411741228322813, 'n_estimators': 299}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:08,762] Trial 59 finished with value: 5.100930554268893 and parameters: {'booster': 'gbtree', 'lambda': 0.0016424168659786445, 'alpha': 3.556708093878115e-08, 'max_depth': 5, 'subsample': 0.17810618623209903, 'colsample_bytree': 0.9691401644163468, 'learning_rate': 0.029829246841180393, 'n_estimators': 250}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:16,307] Trial 60 finished with value: 5.130542356060847 and parameters: {'booster': 'dart', 'lambda': 0.9900986561510232, 'alpha': 6.0411635609224644e-06, 'max_depth': 3, 'subsample': 0.20624453079515098, 'colsample_bytree': 0.7855609871597159, 'learning_rate': 0.016334448611024906, 'n_estimators': 269}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:24,132] Trial 61 finished with value: 5.040625312488155 and parameters: {'booster': 'dart', 'lambda': 0.8836338270922357, 'alpha': 2.449848260040487e-06, 'max_depth': 3, 'subsample': 0.21580234956320118, 'colsample_bytree': 0.8898372570359461, 'learning_rate': 0.020070575088151733, 'n_estimators': 276}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:24,656] Trial 62 finished with value: 6.699055390324005 and parameters: {'booster': 'dart', 'lambda': 0.2553052581584065, 'alpha': 5.622898963304407e-06, 'max_depth': 3, 'subsample': 0.13575536177708902, 'colsample_bytree': 0.8889719755608175, 'learning_rate': 0.022085326304187428, 'n_estimators': 59}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:32,902] Trial 63 finished with value: 5.012872450123965 and parameters: {'booster': 'dart', 'lambda': 0.11247892551441234, 'alpha': 1.800955170198918e-06, 'max_depth': 3, 'subsample': 0.19685451235451984, 'colsample_bytree': 0.8595717423490198, 'learning_rate': 0.01896948501967975, 'n_estimators': 281}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:41,592] Trial 64 finished with value: 5.141234160206417 and parameters: {'booster': 'dart', 'lambda': 0.10986939531185584, 'alpha': 1.4546847115831655e-07, 'max_depth': 3, 'subsample': 0.2605865043893732, 'colsample_bytree': 0.859049568942442, 'learning_rate': 0.013495227949531039, 'n_estimators': 287}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:48,042] Trial 65 finished with value: 5.080058732416859 and parameters: {'booster': 'dart', 'lambda': 0.024534077679628816, 'alpha': 1.8114618199379708e-05, 'max_depth': 4, 'subsample': 0.29783052005061544, 'colsample_bytree': 0.8388844569087544, 'learning_rate': 0.025689847883435108, 'n_estimators': 273}. Best is trial 51 with value: 5.008827098721021.\n",
      "[I 2023-12-26 16:11:51,355] Trial 66 finished with value: 4.976981649073074 and parameters: {'booster': 'dart', 'lambda': 0.5526694489290025, 'alpha': 0.0010689743722251818, 'max_depth': 3, 'subsample': 0.2000965758833549, 'colsample_bytree': 0.749817514881882, 'learning_rate': 0.03757129395821996, 'n_estimators': 243}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:11:54,565] Trial 67 finished with value: 4.990493800399293 and parameters: {'booster': 'dart', 'lambda': 0.5304981247945598, 'alpha': 0.001173490678462302, 'max_depth': 4, 'subsample': 0.20384534152628525, 'colsample_bytree': 0.7962162041781975, 'learning_rate': 0.03810791005408737, 'n_estimators': 254}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:11:57,002] Trial 68 finished with value: 5.022398654690399 and parameters: {'booster': 'dart', 'lambda': 0.5321121478768613, 'alpha': 0.007202955893194446, 'max_depth': 4, 'subsample': 0.2019208663409156, 'colsample_bytree': 0.8136858708282778, 'learning_rate': 0.037008896364945386, 'n_estimators': 228}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:11:57,487] Trial 69 finished with value: 5.090567538166481 and parameters: {'booster': 'gbtree', 'lambda': 0.5378881411243454, 'alpha': 0.007039318002480739, 'max_depth': 5, 'subsample': 0.1968306846058374, 'colsample_bytree': 0.809131162715912, 'learning_rate': 0.03774856803920531, 'n_estimators': 231}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:11:58,220] Trial 70 finished with value: 5.079482519869172 and parameters: {'booster': 'dart', 'lambda': 0.1890053740840329, 'alpha': 0.0019056088102143074, 'max_depth': 4, 'subsample': 0.23424408728836357, 'colsample_bytree': 0.746479209276408, 'learning_rate': 0.07799467010982118, 'n_estimators': 244}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:00,786] Trial 71 finished with value: 5.11427021512245 and parameters: {'booster': 'dart', 'lambda': 0.4279216238409118, 'alpha': 0.05878799953009438, 'max_depth': 6, 'subsample': 0.17515207997307825, 'colsample_bytree': 0.7717411829307802, 'learning_rate': 0.03392090055801723, 'n_estimators': 255}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:02,689] Trial 72 finished with value: 5.044705346508985 and parameters: {'booster': 'dart', 'lambda': 0.08231904893626715, 'alpha': 0.016042260430858886, 'max_depth': 4, 'subsample': 0.2489422696701191, 'colsample_bytree': 0.8727708347324374, 'learning_rate': 0.04915034297730583, 'n_estimators': 264}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:04,072] Trial 73 finished with value: 5.028824832634077 and parameters: {'booster': 'dart', 'lambda': 0.1800348695679439, 'alpha': 0.004009473239266029, 'max_depth': 4, 'subsample': 0.20011021507977744, 'colsample_bytree': 0.8300989979305922, 'learning_rate': 0.05521579683772242, 'n_estimators': 227}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:04,901] Trial 74 finished with value: 5.061648355106023 and parameters: {'booster': 'dart', 'lambda': 0.04356153213917132, 'alpha': 0.001258645984034097, 'max_depth': 5, 'subsample': 0.1985999470542344, 'colsample_bytree': 0.829186548040535, 'learning_rate': 0.08345809886724363, 'n_estimators': 220}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:06,859] Trial 75 finished with value: 5.039167424516374 and parameters: {'booster': 'dart', 'lambda': 0.16076697388079228, 'alpha': 0.0038538689195412594, 'max_depth': 4, 'subsample': 0.11695842312564561, 'colsample_bytree': 0.7976011580519344, 'learning_rate': 0.04317778366585741, 'n_estimators': 227}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:07,938] Trial 76 finished with value: 5.1082589231134 and parameters: {'booster': 'dart', 'lambda': 0.16977519738825003, 'alpha': 0.0043071118913325405, 'max_depth': 5, 'subsample': 0.1070235785553654, 'colsample_bytree': 0.8065531263916865, 'learning_rate': 0.061082927254561756, 'n_estimators': 212}. Best is trial 66 with value: 4.976981649073074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:12:08,276] Trial 77 finished with value: 6.068586414229163 and parameters: {'booster': 'gblinear', 'lambda': 0.016099103519361523, 'alpha': 0.00044245919464046507, 'max_depth': 4, 'subsample': 0.16774133859500845, 'colsample_bytree': 0.7942706548830928, 'learning_rate': 0.04313943079714362, 'n_estimators': 227}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:10,197] Trial 78 finished with value: 5.005329566934663 and parameters: {'booster': 'dart', 'lambda': 0.47638546983787566, 'alpha': 0.00913532942800336, 'max_depth': 4, 'subsample': 0.12710727736087166, 'colsample_bytree': 0.7430029958322235, 'learning_rate': 0.053891569375851586, 'n_estimators': 242}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:11,224] Trial 79 finished with value: 5.24159029001384 and parameters: {'booster': 'dart', 'lambda': 0.4881367047736875, 'alpha': 0.010758154122155505, 'max_depth': 4, 'subsample': 0.285685399663393, 'colsample_bytree': 0.7482620902814591, 'learning_rate': 0.0925562967459382, 'n_estimators': 253}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:12,407] Trial 80 finished with value: 5.306347262461763 and parameters: {'booster': 'dart', 'lambda': 0.2637331835611395, 'alpha': 0.04557542473609912, 'max_depth': 7, 'subsample': 0.31827438803044267, 'colsample_bytree': 0.679847258206197, 'learning_rate': 0.057534657271072515, 'n_estimators': 242}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:14,157] Trial 81 finished with value: 5.613828380772839 and parameters: {'booster': 'dart', 'lambda': 0.13493923162583896, 'alpha': 0.0011822776715466725, 'max_depth': 4, 'subsample': 0.12590825957017715, 'colsample_bytree': 0.6421151133773733, 'learning_rate': 0.05445033976217777, 'n_estimators': 204}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:16,261] Trial 82 finished with value: 5.068521564096947 and parameters: {'booster': 'dart', 'lambda': 0.05651909307990654, 'alpha': 0.00262359346400712, 'max_depth': 5, 'subsample': 0.12530766451631026, 'colsample_bytree': 0.7329265208164691, 'learning_rate': 0.04658207257192214, 'n_estimators': 220}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:18,578] Trial 83 finished with value: 5.028311584869804 and parameters: {'booster': 'dart', 'lambda': 0.0005163520396614528, 'alpha': 0.005550564545894789, 'max_depth': 4, 'subsample': 0.16321050948987498, 'colsample_bytree': 0.7715656127937984, 'learning_rate': 0.03867463661241784, 'n_estimators': 232}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:20,898] Trial 84 finished with value: 5.040824964842079 and parameters: {'booster': 'dart', 'lambda': 0.0006906706487867348, 'alpha': 0.00902448121063687, 'max_depth': 4, 'subsample': 0.19132268317078832, 'colsample_bytree': 0.7681357612416505, 'learning_rate': 0.03778593533443924, 'n_estimators': 235}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:22,769] Trial 85 finished with value: 5.044806155144678 and parameters: {'booster': 'dart', 'lambda': 0.0009422837014263644, 'alpha': 0.02485200492421474, 'max_depth': 5, 'subsample': 0.1575661463715945, 'colsample_bytree': 0.8275323647955857, 'learning_rate': 0.07122709676267797, 'n_estimators': 243}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:26,399] Trial 86 finished with value: 5.015293722036004 and parameters: {'booster': 'dart', 'lambda': 0.004687563084795513, 'alpha': 0.005725413796122738, 'max_depth': 4, 'subsample': 0.24999916932885657, 'colsample_bytree': 0.8662478486256554, 'learning_rate': 0.03146732088695725, 'n_estimators': 259}. Best is trial 66 with value: 4.976981649073074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:12:26,777] Trial 87 finished with value: 6.1086970587046725 and parameters: {'booster': 'gblinear', 'lambda': 0.0036136714440315166, 'alpha': 0.015971134425308484, 'max_depth': 4, 'subsample': 0.2536963042262233, 'colsample_bytree': 0.8721084774071071, 'learning_rate': 0.028367219239634832, 'n_estimators': 255}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:29,209] Trial 88 finished with value: 5.060989654502695 and parameters: {'booster': 'dart', 'lambda': 0.0002669073282023832, 'alpha': 0.0008749934337369494, 'max_depth': 4, 'subsample': 0.22587513120356395, 'colsample_bytree': 0.7443840693697299, 'learning_rate': 0.03159885738601072, 'n_estimators': 259}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:29,719] Trial 89 finished with value: 5.058475203976566 and parameters: {'booster': 'gbtree', 'lambda': 0.0001251276689412649, 'alpha': 0.008110541729061043, 'max_depth': 4, 'subsample': 0.2748916524398253, 'colsample_bytree': 0.7791670279780132, 'learning_rate': 0.03359563616836077, 'n_estimators': 246}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:32,377] Trial 90 finished with value: 5.078023800467574 and parameters: {'booster': 'dart', 'lambda': 0.002300547865007684, 'alpha': 0.0017343987409545903, 'max_depth': 6, 'subsample': 0.24194335185904114, 'colsample_bytree': 0.8604374322970973, 'learning_rate': 0.03732498457062225, 'n_estimators': 261}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:34,239] Trial 91 finished with value: 5.035253714483949 and parameters: {'booster': 'dart', 'lambda': 0.007176122073631452, 'alpha': 0.005096493105995932, 'max_depth': 4, 'subsample': 0.21566983607428164, 'colsample_bytree': 0.8278999760124476, 'learning_rate': 0.053297913342081726, 'n_estimators': 214}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:36,580] Trial 92 finished with value: 5.016350406852269 and parameters: {'booster': 'dart', 'lambda': 0.58044549190853, 'alpha': 0.003277915346002975, 'max_depth': 4, 'subsample': 0.18446577965233105, 'colsample_bytree': 0.843211137687793, 'learning_rate': 0.04819687909612238, 'n_estimators': 232}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:38,915] Trial 93 finished with value: 5.021588949487416 and parameters: {'booster': 'dart', 'lambda': 0.5373188830076738, 'alpha': 0.0025311035121247413, 'max_depth': 3, 'subsample': 0.17249000309492712, 'colsample_bytree': 0.7693681548499713, 'learning_rate': 0.04646552430370744, 'n_estimators': 238}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:40,227] Trial 94 finished with value: 4.991519122220392 and parameters: {'booster': 'dart', 'lambda': 0.6260138588325176, 'alpha': 0.002561279244024384, 'max_depth': 3, 'subsample': 0.18425418875506686, 'colsample_bytree': 0.7142900645627183, 'learning_rate': 0.06590530989578895, 'n_estimators': 240}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:41,537] Trial 95 finished with value: 5.001800903107804 and parameters: {'booster': 'dart', 'lambda': 0.5313502430320018, 'alpha': 0.0003299673847680121, 'max_depth': 3, 'subsample': 0.18571086670731915, 'colsample_bytree': 0.7188834744033811, 'learning_rate': 0.0638237857665353, 'n_estimators': 239}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:43,210] Trial 96 finished with value: 5.383584605696865 and parameters: {'booster': 'dart', 'lambda': 0.332711204956069, 'alpha': 0.00039517986111222634, 'max_depth': 3, 'subsample': 0.14480791179386726, 'colsample_bytree': 0.6647159263652203, 'learning_rate': 0.06466694159877717, 'n_estimators': 249}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:45,730] Trial 97 finished with value: 5.168560213878057 and parameters: {'booster': 'dart', 'lambda': 0.6514635241257442, 'alpha': 0.002779660889665935, 'max_depth': 3, 'subsample': 0.10066280743197795, 'colsample_bytree': 0.622275301430265, 'learning_rate': 0.04607503276122713, 'n_estimators': 237}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:46,640] Trial 98 finished with value: 5.033333423767787 and parameters: {'booster': 'dart', 'lambda': 0.34352147752535744, 'alpha': 0.0002330020391813402, 'max_depth': 3, 'subsample': 0.18468260530254432, 'colsample_bytree': 0.7182461577558565, 'learning_rate': 0.08096827516584718, 'n_estimators': 83}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:48,765] Trial 99 finished with value: 5.00360759450834 and parameters: {'booster': 'dart', 'lambda': 0.24835524283255037, 'alpha': 0.0007957309326660381, 'max_depth': 3, 'subsample': 0.16653444855930163, 'colsample_bytree': 0.9369861747996158, 'learning_rate': 0.050844768444104974, 'n_estimators': 255}. Best is trial 66 with value: 4.976981649073074.\n",
      "[I 2023-12-26 16:12:48,770] A new study created in memory with name: no-name-61c46292-8d78-486d-96ea-4633b9cd7e2b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 4.976981649073074\n",
      "  Params: \n",
      "    booster: dart\n",
      "    lambda: 0.5526694489290025\n",
      "    alpha: 0.0010689743722251818\n",
      "    max_depth: 3\n",
      "    subsample: 0.2000965758833549\n",
      "    colsample_bytree: 0.749817514881882\n",
      "    learning_rate: 0.03757129395821996\n",
      "    n_estimators: 243\n",
      "[16:12:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:12:49,058] Trial 0 finished with value: 30.753773017778787 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 30.753773017778787.\n",
      "[I 2023-12-26 16:12:49,222] Trial 1 finished with value: 31.355955319339277 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 0 with value: 30.753773017778787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:12:49,448] Trial 2 finished with value: 35.18882899698057 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 0 with value: 30.753773017778787.\n",
      "[I 2023-12-26 16:12:49,845] Trial 3 finished with value: 30.482865316312605 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 3 with value: 30.482865316312605.\n",
      "[I 2023-12-26 16:12:49,981] Trial 4 finished with value: 31.12176230373992 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 3 with value: 30.482865316312605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:12:50,424] Trial 5 finished with value: 46.59098996637074 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 3 with value: 30.482865316312605.\n",
      "[I 2023-12-26 16:13:01,340] Trial 6 finished with value: 40.65978440550364 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 3 with value: 30.482865316312605.\n",
      "[I 2023-12-26 16:13:01,632] Trial 7 finished with value: 43.20148018388443 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 3 with value: 30.482865316312605.\n",
      "[I 2023-12-26 16:13:01,978] Trial 8 finished with value: 30.159971007604035 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:02,875] Trial 9 finished with value: 49.24811052378999 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:03,011] Trial 10 finished with value: 31.27852738994442 and parameters: {'booster': 'gbtree', 'lambda': 1.116805293160088e-08, 'alpha': 1.1491548505141235e-08, 'max_depth': 3, 'subsample': 0.9786917711698019, 'colsample_bytree': 0.7598785099640686, 'learning_rate': 0.0881744100052964, 'n_estimators': 219}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:03,260] Trial 11 finished with value: 34.173384793076885 and parameters: {'booster': 'gbtree', 'lambda': 1.133353977171156e-08, 'alpha': 0.5499098198182308, 'max_depth': 6, 'subsample': 0.6445983663896186, 'colsample_bytree': 0.3630146189517875, 'learning_rate': 0.06167020181123221, 'n_estimators': 174}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:04,095] Trial 12 finished with value: 31.063454439171913 and parameters: {'booster': 'gbtree', 'lambda': 0.004268162793906724, 'alpha': 3.513053644688532e-05, 'max_depth': 10, 'subsample': 0.7514497084607286, 'colsample_bytree': 0.987005007454463, 'learning_rate': 0.03604182605436954, 'n_estimators': 174}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:04,480] Trial 13 finished with value: 32.471839872037975 and parameters: {'booster': 'gbtree', 'lambda': 5.985540948966967e-07, 'alpha': 0.8635835438209288, 'max_depth': 5, 'subsample': 0.4855381281942338, 'colsample_bytree': 0.1026918590516594, 'learning_rate': 0.02982894370402057, 'n_estimators': 220}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:05,060] Trial 14 finished with value: 31.246571244017723 and parameters: {'booster': 'gbtree', 'lambda': 0.9375038170603618, 'alpha': 0.02996617744197145, 'max_depth': 7, 'subsample': 0.9674306376468527, 'colsample_bytree': 0.7387380072583746, 'learning_rate': 0.03661206023497895, 'n_estimators': 143}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:12,173] Trial 15 finished with value: 38.855684757145575 and parameters: {'booster': 'dart', 'lambda': 0.0056211684328409854, 'alpha': 9.018553400578149e-06, 'max_depth': 5, 'subsample': 0.7670378720619528, 'colsample_bytree': 0.41098824826542846, 'learning_rate': 0.0038990513337170715, 'n_estimators': 249}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:12,891] Trial 16 finished with value: 31.27653864229107 and parameters: {'booster': 'gbtree', 'lambda': 3.8760061290523975e-05, 'alpha': 0.0006625168167997717, 'max_depth': 8, 'subsample': 0.4888165358239319, 'colsample_bytree': 0.6781258505255456, 'learning_rate': 0.025815325463280848, 'n_estimators': 192}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:13,065] Trial 17 finished with value: 39.66554325452134 and parameters: {'booster': 'gbtree', 'lambda': 2.1023041575253858e-07, 'alpha': 1.2166914888742715e-08, 'max_depth': 9, 'subsample': 0.8765689950217602, 'colsample_bytree': 0.2828574352253965, 'learning_rate': 0.06315818973085191, 'n_estimators': 147}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:13,367] Trial 18 finished with value: 34.46735947578465 and parameters: {'booster': 'dart', 'lambda': 0.0033623057029686008, 'alpha': 0.0006952334891338025, 'max_depth': 5, 'subsample': 0.6508127143377795, 'colsample_bytree': 0.6646778439534707, 'learning_rate': 0.09937009494687501, 'n_estimators': 192}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:13,556] Trial 19 finished with value: 30.907289742247702 and parameters: {'booster': 'gblinear', 'lambda': 1.2808752172773615e-07, 'alpha': 0.05725092621657002, 'max_depth': 3, 'subsample': 0.35089152305611, 'colsample_bytree': 0.23158271896073607, 'learning_rate': 0.020219450031240763, 'n_estimators': 107}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:13,825] Trial 20 finished with value: 34.030318409819586 and parameters: {'booster': 'gbtree', 'lambda': 4.240597404517817e-05, 'alpha': 8.901889340091406e-06, 'max_depth': 9, 'subsample': 0.6622242667869436, 'colsample_bytree': 0.42161099862322393, 'learning_rate': 0.045685612539356504, 'n_estimators': 265}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:14,165] Trial 21 finished with value: 30.923094050437893 and parameters: {'booster': 'gblinear', 'lambda': 0.0006502603236015741, 'alpha': 2.6033391254529684e-07, 'max_depth': 4, 'subsample': 0.1450784958794869, 'colsample_bytree': 0.9245239379863004, 'learning_rate': 0.009254639139346234, 'n_estimators': 222}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:14,411] Trial 22 finished with value: 30.817900500711243 and parameters: {'booster': 'gblinear', 'lambda': 3.8665331981979555e-06, 'alpha': 8.642886810460843e-08, 'max_depth': 4, 'subsample': 0.11451428773283162, 'colsample_bytree': 0.8893216927518138, 'learning_rate': 0.018790117765881593, 'n_estimators': 157}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:14,722] Trial 23 finished with value: 30.41196305366412 and parameters: {'booster': 'gblinear', 'lambda': 0.00032986254983142534, 'alpha': 2.5654709807324455e-06, 'max_depth': 6, 'subsample': 0.2696631247657278, 'colsample_bytree': 0.8328776178860887, 'learning_rate': 0.05345298981131541, 'n_estimators': 206}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:15,020] Trial 24 finished with value: 30.3959204540514 and parameters: {'booster': 'gblinear', 'lambda': 0.0642844209523738, 'alpha': 3.7798416797520334e-06, 'max_depth': 6, 'subsample': 0.4492877589967841, 'colsample_bytree': 0.660803832799132, 'learning_rate': 0.060132995548464005, 'n_estimators': 196}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:15,324] Trial 25 finished with value: 30.401014990959 and parameters: {'booster': 'gblinear', 'lambda': 0.0281628449624149, 'alpha': 2.9624487345363516e-06, 'max_depth': 6, 'subsample': 0.48851211235345615, 'colsample_bytree': 0.6687435351234414, 'learning_rate': 0.06033898333973051, 'n_estimators': 191}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:15,615] Trial 26 finished with value: 30.36342863527063 and parameters: {'booster': 'gblinear', 'lambda': 0.03284457787100556, 'alpha': 1.0843932168731625e-05, 'max_depth': 7, 'subsample': 0.4681635446318717, 'colsample_bytree': 0.6565354511734879, 'learning_rate': 0.07321871462669284, 'n_estimators': 191}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:15,996] Trial 27 finished with value: 30.31596372909198 and parameters: {'booster': 'gblinear', 'lambda': 0.04453796608573726, 'alpha': 0.00018578876063958196, 'max_depth': 7, 'subsample': 0.538065158798551, 'colsample_bytree': 0.6248682643371153, 'learning_rate': 0.07897255752292695, 'n_estimators': 260}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:16,421] Trial 28 finished with value: 30.302542083600887 and parameters: {'booster': 'gblinear', 'lambda': 0.012536498235793638, 'alpha': 0.00016192384912868193, 'max_depth': 7, 'subsample': 0.616300326464762, 'colsample_bytree': 0.5026428514354739, 'learning_rate': 0.08314222413769018, 'n_estimators': 295}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:16,822] Trial 29 finished with value: 30.408158100424295 and parameters: {'booster': 'gblinear', 'lambda': 0.0015053240130994264, 'alpha': 5.7581910212867314e-05, 'max_depth': 7, 'subsample': 0.5550184123695313, 'colsample_bytree': 0.4574463234347228, 'learning_rate': 0.038512730567320894, 'n_estimators': 291}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:17,198] Trial 30 finished with value: 30.30320230144344 and parameters: {'booster': 'gblinear', 'lambda': 0.006641523621505445, 'alpha': 0.00017315946202476704, 'max_depth': 5, 'subsample': 0.7067889548609451, 'colsample_bytree': 0.5172552243043242, 'learning_rate': 0.09005891929228586, 'n_estimators': 270}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:17,575] Trial 31 finished with value: 30.299306959039004 and parameters: {'booster': 'gblinear', 'lambda': 0.011071019000189922, 'alpha': 0.00021530387723825108, 'max_depth': 5, 'subsample': 0.6803792922374878, 'colsample_bytree': 0.5125346718065175, 'learning_rate': 0.09699932886262601, 'n_estimators': 270}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:17,926] Trial 32 finished with value: 30.305043668006657 and parameters: {'booster': 'gblinear', 'lambda': 0.00755981977524475, 'alpha': 0.0001902214514269906, 'max_depth': 5, 'subsample': 0.6964284359437242, 'colsample_bytree': 0.5113812306694864, 'learning_rate': 0.09696112473928487, 'n_estimators': 244}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:18,317] Trial 33 finished with value: 30.367675324879826 and parameters: {'booster': 'gblinear', 'lambda': 0.011780223966560269, 'alpha': 0.005122173185384054, 'max_depth': 5, 'subsample': 0.8321678739720997, 'colsample_bytree': 0.5182574800741315, 'learning_rate': 0.048492515329007675, 'n_estimators': 281}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:18,707] Trial 34 finished with value: 30.31024569646409 and parameters: {'booster': 'gblinear', 'lambda': 0.0013429086770725051, 'alpha': 0.0018755339868069044, 'max_depth': 4, 'subsample': 0.6074689670263071, 'colsample_bytree': 0.36652331216519246, 'learning_rate': 0.07977889547041928, 'n_estimators': 275}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:19,053] Trial 35 finished with value: 30.304237230553476 and parameters: {'booster': 'gblinear', 'lambda': 0.00011564025786747027, 'alpha': 0.00013057243307885595, 'max_depth': 5, 'subsample': 0.7359839955534507, 'colsample_bytree': 0.5848366076194503, 'learning_rate': 0.09994676000896437, 'n_estimators': 240}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:19,450] Trial 36 finished with value: 31.728204009870417 and parameters: {'booster': 'gblinear', 'lambda': 0.20819674708781816, 'alpha': 2.6666451175304177e-05, 'max_depth': 4, 'subsample': 0.8788370285965723, 'colsample_bytree': 0.590987711501064, 'learning_rate': 0.002497206423265257, 'n_estimators': 282}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:19,821] Trial 37 finished with value: 30.383465697406095 and parameters: {'booster': 'gblinear', 'lambda': 1.7745980694775324e-06, 'alpha': 6.830499334928434e-07, 'max_depth': 3, 'subsample': 0.7240138714932598, 'colsample_bytree': 0.7387235346584577, 'learning_rate': 0.04729727465471528, 'n_estimators': 265}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:22,151] Trial 38 finished with value: 36.68844718480219 and parameters: {'booster': 'dart', 'lambda': 0.0012519919596213976, 'alpha': 0.0002985727509485867, 'max_depth': 6, 'subsample': 0.8115676845089285, 'colsample_bytree': 0.5118225318714098, 'learning_rate': 0.013039275717404316, 'n_estimators': 239}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:22,577] Trial 39 finished with value: 30.314328028709383 and parameters: {'booster': 'gblinear', 'lambda': 4.7122358574827056e-08, 'alpha': 0.0025406230970830834, 'max_depth': 5, 'subsample': 0.8786053835191311, 'colsample_bytree': 0.547103577398348, 'learning_rate': 0.07129715382304784, 'n_estimators': 293}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:22,957] Trial 40 finished with value: 30.491988124760315 and parameters: {'booster': 'gblinear', 'lambda': 0.016700696572263665, 'alpha': 7.075138605483881e-05, 'max_depth': 8, 'subsample': 0.5998311231569748, 'colsample_bytree': 0.3388181468798092, 'learning_rate': 0.03234823452295173, 'n_estimators': 254}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:23,311] Trial 41 finished with value: 30.305731783653506 and parameters: {'booster': 'gblinear', 'lambda': 8.313370996551728e-05, 'alpha': 0.00014398495169590735, 'max_depth': 5, 'subsample': 0.7078477014168175, 'colsample_bytree': 0.5974747448741632, 'learning_rate': 0.09925456372141189, 'n_estimators': 236}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:23,711] Trial 42 finished with value: 30.318087010492476 and parameters: {'booster': 'gblinear', 'lambda': 1.6653850661308603e-05, 'alpha': 0.0004433202819206982, 'max_depth': 4, 'subsample': 0.6709035059424434, 'colsample_bytree': 0.441331623401738, 'learning_rate': 0.07349790447297666, 'n_estimators': 273}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:24,142] Trial 43 finished with value: 30.300824309745337 and parameters: {'booster': 'gblinear', 'lambda': 0.00017296805559399166, 'alpha': 0.0013672606774435144, 'max_depth': 5, 'subsample': 0.7476897459349645, 'colsample_bytree': 0.5504803783813076, 'learning_rate': 0.08431383991436557, 'n_estimators': 300}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:24,584] Trial 44 finished with value: 30.383103621670106 and parameters: {'booster': 'gblinear', 'lambda': 0.00020000463734423375, 'alpha': 0.0014119693174595544, 'max_depth': 6, 'subsample': 0.6090918586218859, 'colsample_bytree': 0.4757483968647366, 'learning_rate': 0.042147983470012536, 'n_estimators': 298}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:24,893] Trial 45 finished with value: 35.83179011027019 and parameters: {'booster': 'dart', 'lambda': 0.12804337742166422, 'alpha': 0.14934449634490377, 'max_depth': 5, 'subsample': 0.8382311879765532, 'colsample_bytree': 0.528166066746189, 'learning_rate': 0.05706740761892419, 'n_estimators': 285}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:25,163] Trial 46 finished with value: 37.32148283640544 and parameters: {'booster': 'gbtree', 'lambda': 0.4972776542149698, 'alpha': 0.008941596984465446, 'max_depth': 7, 'subsample': 0.7798149985434829, 'colsample_bytree': 0.6189176819954909, 'learning_rate': 0.07423829624863075, 'n_estimators': 272}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:25,589] Trial 47 finished with value: 30.30328386280635 and parameters: {'booster': 'gblinear', 'lambda': 0.0026180901241789176, 'alpha': 2.5345942092227582e-05, 'max_depth': 6, 'subsample': 0.6942851939569342, 'colsample_bytree': 0.7647615747840368, 'learning_rate': 0.08066577041897124, 'n_estimators': 300}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:25,921] Trial 48 finished with value: 34.4622499053119 and parameters: {'booster': 'gbtree', 'lambda': 0.0005794454708671352, 'alpha': 1.6069959281482857e-05, 'max_depth': 3, 'subsample': 0.7523283741787252, 'colsample_bytree': 0.40212051433215124, 'learning_rate': 0.02840994383936791, 'n_estimators': 167}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:26,150] Trial 49 finished with value: 31.552763280999176 and parameters: {'booster': 'gblinear', 'lambda': 0.015065400917065902, 'alpha': 5.5547988155279196e-05, 'max_depth': 5, 'subsample': 0.6231036668513282, 'colsample_bytree': 0.5639934232158484, 'learning_rate': 0.005925345806222788, 'n_estimators': 131}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:26,382] Trial 50 finished with value: 31.096583273900702 and parameters: {'booster': 'gbtree', 'lambda': 0.008180299504786276, 'alpha': 0.0010153146919280164, 'max_depth': 4, 'subsample': 0.9443141438949815, 'colsample_bytree': 0.6990370253767175, 'learning_rate': 0.06546175566728361, 'n_estimators': 287}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:26,813] Trial 51 finished with value: 30.303070668259714 and parameters: {'booster': 'gblinear', 'lambda': 0.002962682339952073, 'alpha': 2.6270273592998565e-05, 'max_depth': 6, 'subsample': 0.6968968494462251, 'colsample_bytree': 0.7801312582519933, 'learning_rate': 0.0809589077040079, 'n_estimators': 300}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:27,241] Trial 52 finished with value: 30.300241127885098 and parameters: {'booster': 'gblinear', 'lambda': 0.0031052226684439767, 'alpha': 5.019846261313289e-06, 'max_depth': 6, 'subsample': 0.799727053811888, 'colsample_bytree': 0.8161063022101858, 'learning_rate': 0.08524802618966142, 'n_estimators': 300}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:27,672] Trial 53 finished with value: 30.30138461038947 and parameters: {'booster': 'gblinear', 'lambda': 0.0017385039527115802, 'alpha': 1.248430159943279e-07, 'max_depth': 6, 'subsample': 0.7859220331635924, 'colsample_bytree': 0.7144515667399471, 'learning_rate': 0.08369967900517511, 'n_estimators': 299}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:28,832] Trial 54 finished with value: 31.323257659842433 and parameters: {'booster': 'dart', 'lambda': 0.0006232024486691726, 'alpha': 7.918340726435036e-08, 'max_depth': 8, 'subsample': 0.9064811387159641, 'colsample_bytree': 0.8208388529135735, 'learning_rate': 0.05545533048003808, 'n_estimators': 280}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:29,215] Trial 55 finished with value: 30.415313938785363 and parameters: {'booster': 'gblinear', 'lambda': 0.07555300222502853, 'alpha': 7.194238865834381e-07, 'max_depth': 6, 'subsample': 0.7973238053433588, 'colsample_bytree': 0.7120114793172975, 'learning_rate': 0.042240408869966724, 'n_estimators': 257}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:29,687] Trial 56 finished with value: 30.80364640484117 and parameters: {'booster': 'gbtree', 'lambda': 1.798399196599814e-05, 'alpha': 5.229270244439056e-08, 'max_depth': 7, 'subsample': 0.8350858549186233, 'colsample_bytree': 0.8513448161802931, 'learning_rate': 0.05202428055261635, 'n_estimators': 289}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:30,116] Trial 57 finished with value: 30.301387397382904 and parameters: {'booster': 'gblinear', 'lambda': 0.0019559307951320932, 'alpha': 2.412957641421288e-08, 'max_depth': 6, 'subsample': 0.7695728693406764, 'colsample_bytree': 0.937047152046752, 'learning_rate': 0.08638449328907769, 'n_estimators': 290}. Best is trial 8 with value: 30.159971007604035.\n",
      "[I 2023-12-26 16:13:30,257] Trial 58 finished with value: 31.019863784302316 and parameters: {'booster': 'gblinear', 'lambda': 0.00023462418069023213, 'alpha': 1.715727085983156e-08, 'max_depth': 6, 'subsample': 0.7736693251635245, 'colsample_bytree': 0.9748166241920511, 'learning_rate': 0.02268194270111959, 'n_estimators': 65}. Best is trial 8 with value: 30.159971007604035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:30,657] Trial 59 finished with value: 29.888420004997077 and parameters: {'booster': 'gbtree', 'lambda': 0.002092062670737406, 'alpha': 2.1465967527186582e-07, 'max_depth': 5, 'subsample': 0.921919091895522, 'colsample_bytree': 0.9269792381784294, 'learning_rate': 0.06765644991973838, 'n_estimators': 209}. Best is trial 59 with value: 29.888420004997077.\n",
      "[I 2023-12-26 16:13:30,995] Trial 60 finished with value: 30.16985091239894 and parameters: {'booster': 'gbtree', 'lambda': 0.00010100235341532511, 'alpha': 1.072732370641098e-06, 'max_depth': 5, 'subsample': 0.9171664680389902, 'colsample_bytree': 0.7831117496563343, 'learning_rate': 0.06780594313015038, 'n_estimators': 157}. Best is trial 59 with value: 29.888420004997077.\n",
      "[I 2023-12-26 16:13:31,328] Trial 61 finished with value: 29.855687944595125 and parameters: {'booster': 'gbtree', 'lambda': 4.038604804627531e-05, 'alpha': 1.9278151755008147e-07, 'max_depth': 5, 'subsample': 0.9505822661198629, 'colsample_bytree': 0.7925420643808723, 'learning_rate': 0.06490527669590927, 'n_estimators': 180}. Best is trial 61 with value: 29.855687944595125.\n",
      "[I 2023-12-26 16:13:31,563] Trial 62 finished with value: 30.791520230018932 and parameters: {'booster': 'gbtree', 'lambda': 5.156106154291851e-05, 'alpha': 4.40807557069375e-07, 'max_depth': 4, 'subsample': 0.9401958562920932, 'colsample_bytree': 0.7940968957462023, 'learning_rate': 0.06354029427432921, 'n_estimators': 152}. Best is trial 61 with value: 29.855687944595125.\n",
      "[I 2023-12-26 16:13:32,015] Trial 63 finished with value: 29.77079920294078 and parameters: {'booster': 'gbtree', 'lambda': 1.590242767414875e-06, 'alpha': 1.7144243214063895e-06, 'max_depth': 5, 'subsample': 0.9854705490887194, 'colsample_bytree': 0.887349204431578, 'learning_rate': 0.0328408403842817, 'n_estimators': 181}. Best is trial 63 with value: 29.77079920294078.\n",
      "[I 2023-12-26 16:13:32,315] Trial 64 finished with value: 30.26830855905194 and parameters: {'booster': 'gbtree', 'lambda': 7.75740659512944e-07, 'alpha': 1.2098314342408504e-06, 'max_depth': 4, 'subsample': 0.9917737978517339, 'colsample_bytree': 0.882295804182867, 'learning_rate': 0.033385598283439365, 'n_estimators': 180}. Best is trial 63 with value: 29.77079920294078.\n",
      "[I 2023-12-26 16:13:32,876] Trial 65 finished with value: 29.86939667932519 and parameters: {'booster': 'gbtree', 'lambda': 8.974847195625133e-07, 'alpha': 1.3196377390931711e-06, 'max_depth': 5, 'subsample': 0.9981129619019607, 'colsample_bytree': 0.8829528614000414, 'learning_rate': 0.03253086099017735, 'n_estimators': 180}. Best is trial 63 with value: 29.77079920294078.\n",
      "[I 2023-12-26 16:13:33,237] Trial 66 finished with value: 30.04421270117912 and parameters: {'booster': 'gbtree', 'lambda': 1.224092838098833e-06, 'alpha': 1.701481928506869e-06, 'max_depth': 4, 'subsample': 0.9966073707357215, 'colsample_bytree': 0.8754986201611095, 'learning_rate': 0.03249872681026874, 'n_estimators': 181}. Best is trial 63 with value: 29.77079920294078.\n",
      "[I 2023-12-26 16:13:33,625] Trial 67 finished with value: 30.87874998432316 and parameters: {'booster': 'gbtree', 'lambda': 1.7432583273956254e-07, 'alpha': 2.5694852830539316e-07, 'max_depth': 4, 'subsample': 0.9247034554449894, 'colsample_bytree': 0.9311294135288686, 'learning_rate': 0.024332612410048006, 'n_estimators': 211}. Best is trial 63 with value: 29.77079920294078.\n",
      "[I 2023-12-26 16:13:34,229] Trial 68 finished with value: 29.765877046280252 and parameters: {'booster': 'gbtree', 'lambda': 3.959238789257373e-08, 'alpha': 8.745639035345538e-07, 'max_depth': 5, 'subsample': 0.9674116354627325, 'colsample_bytree': 0.857985519837729, 'learning_rate': 0.0287127174747138, 'n_estimators': 181}. Best is trial 68 with value: 29.765877046280252.\n",
      "[I 2023-12-26 16:13:34,566] Trial 69 finished with value: 32.7482160991512 and parameters: {'booster': 'gbtree', 'lambda': 4.9408532097014355e-08, 'alpha': 2.1762117131212854e-06, 'max_depth': 3, 'subsample': 0.9663161006327106, 'colsample_bytree': 0.8613644209362668, 'learning_rate': 0.01952395462870804, 'n_estimators': 179}. Best is trial 68 with value: 29.765877046280252.\n",
      "[I 2023-12-26 16:13:35,122] Trial 70 finished with value: 30.705787781144927 and parameters: {'booster': 'gbtree', 'lambda': 1.9284120003738434e-08, 'alpha': 5.4840927480193565e-06, 'max_depth': 5, 'subsample': 0.9968715178307181, 'colsample_bytree': 0.9084502847168996, 'learning_rate': 0.0149421929957819, 'n_estimators': 165}. Best is trial 68 with value: 29.765877046280252.\n",
      "[I 2023-12-26 16:13:35,808] Trial 71 finished with value: 29.84563035904 and parameters: {'booster': 'gbtree', 'lambda': 2.6187707997160222e-06, 'alpha': 1.3681643530514842e-06, 'max_depth': 5, 'subsample': 0.9023247075379733, 'colsample_bytree': 0.9623890553687815, 'learning_rate': 0.029079386525647972, 'n_estimators': 200}. Best is trial 68 with value: 29.765877046280252.\n",
      "[I 2023-12-26 16:13:36,260] Trial 72 finished with value: 29.891680231834652 and parameters: {'booster': 'gbtree', 'lambda': 3.326431359191111e-06, 'alpha': 4.89447708774361e-07, 'max_depth': 5, 'subsample': 0.9621708731253014, 'colsample_bytree': 0.9864902041072048, 'learning_rate': 0.03786101031915647, 'n_estimators': 202}. Best is trial 68 with value: 29.765877046280252.\n",
      "[I 2023-12-26 16:13:36,902] Trial 73 finished with value: 29.758580581804388 and parameters: {'booster': 'gbtree', 'lambda': 3.531144621836348e-06, 'alpha': 3.5629013509371597e-07, 'max_depth': 5, 'subsample': 0.9643458582253838, 'colsample_bytree': 0.9658704227680268, 'learning_rate': 0.025906897044279512, 'n_estimators': 200}. Best is trial 73 with value: 29.758580581804388.\n",
      "[I 2023-12-26 16:13:37,273] Trial 74 finished with value: 29.936560981785327 and parameters: {'booster': 'gbtree', 'lambda': 4.265286673690365e-06, 'alpha': 3.948409523404006e-07, 'max_depth': 5, 'subsample': 0.962612683803909, 'colsample_bytree': 0.9672778501490665, 'learning_rate': 0.03806908126067373, 'n_estimators': 204}. Best is trial 73 with value: 29.758580581804388.\n",
      "[I 2023-12-26 16:13:37,953] Trial 75 finished with value: 29.714699368411544 and parameters: {'booster': 'gbtree', 'lambda': 2.8244768564796005e-07, 'alpha': 1.9571232059060417e-07, 'max_depth': 5, 'subsample': 0.8967325679234351, 'colsample_bytree': 0.9964331645616751, 'learning_rate': 0.027488543602505796, 'n_estimators': 199}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:38,670] Trial 76 finished with value: 30.211411802387673 and parameters: {'booster': 'gbtree', 'lambda': 3.536521685515026e-07, 'alpha': 3.9724187829104485e-08, 'max_depth': 5, 'subsample': 0.8944469627797806, 'colsample_bytree': 0.9559376997356731, 'learning_rate': 0.016664520061793406, 'n_estimators': 212}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:39,163] Trial 77 finished with value: 30.549650502662132 and parameters: {'booster': 'gbtree', 'lambda': 3.844846834904642e-07, 'alpha': 1.3877169558853691e-07, 'max_depth': 5, 'subsample': 0.8581377206964045, 'colsample_bytree': 0.9131491425245385, 'learning_rate': 0.026481766088050127, 'n_estimators': 189}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:39,554] Trial 78 finished with value: 30.952051487404464 and parameters: {'booster': 'gbtree', 'lambda': 9.106745458692666e-08, 'alpha': 1.5634003040228367e-07, 'max_depth': 4, 'subsample': 0.936585765885882, 'colsample_bytree': 0.9983209349957294, 'learning_rate': 0.02184420389180469, 'n_estimators': 227}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:40,223] Trial 79 finished with value: 31.678161948913854 and parameters: {'booster': 'gbtree', 'lambda': 7.785169446347826e-06, 'alpha': 3.0646505068102747e-07, 'max_depth': 5, 'subsample': 0.8980452628888795, 'colsample_bytree': 0.9544706122704425, 'learning_rate': 0.009587919302513534, 'n_estimators': 198}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:40,839] Trial 80 finished with value: 30.880758039396106 and parameters: {'booster': 'gbtree', 'lambda': 2.1350529485235867e-06, 'alpha': 2.0459280466268823e-07, 'max_depth': 5, 'subsample': 0.9485397285605972, 'colsample_bytree': 0.9067835317418947, 'learning_rate': 0.011091746173654592, 'n_estimators': 186}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:41,264] Trial 81 finished with value: 29.996699017389727 and parameters: {'booster': 'gbtree', 'lambda': 8.566298460186084e-07, 'alpha': 5.149514061541875e-07, 'max_depth': 5, 'subsample': 0.9714723483959451, 'colsample_bytree': 0.9931133414721466, 'learning_rate': 0.029661893081910445, 'n_estimators': 202}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:41,751] Trial 82 finished with value: 29.915592601201304 and parameters: {'booster': 'gbtree', 'lambda': 3.999515845637059e-06, 'alpha': 8.979887365246212e-07, 'max_depth': 5, 'subsample': 0.9197673576267039, 'colsample_bytree': 0.9378678813922501, 'learning_rate': 0.043075155098491816, 'n_estimators': 212}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:42,166] Trial 83 finished with value: 30.356862139070415 and parameters: {'booster': 'gbtree', 'lambda': 2.235668846804737e-06, 'alpha': 8.269734137727105e-08, 'max_depth': 5, 'subsample': 0.859461675770985, 'colsample_bytree': 0.8513872384455635, 'learning_rate': 0.03488935472863173, 'n_estimators': 169}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:42,822] Trial 84 finished with value: 29.830016010406354 and parameters: {'booster': 'gbtree', 'lambda': 1.733148770999377e-05, 'alpha': 6.214441224865989e-07, 'max_depth': 5, 'subsample': 0.9705637522366338, 'colsample_bytree': 0.8876038852855377, 'learning_rate': 0.017442711236326, 'n_estimators': 197}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:43,376] Trial 85 finished with value: 29.94324450070455 and parameters: {'booster': 'gbtree', 'lambda': 1.5329969455731555e-05, 'alpha': 1.4773911203586407e-06, 'max_depth': 4, 'subsample': 0.9866547164181938, 'colsample_bytree': 0.9080547854394184, 'learning_rate': 0.01637580604358422, 'n_estimators': 219}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:43,970] Trial 86 finished with value: 30.033874812365664 and parameters: {'booster': 'gbtree', 'lambda': 1.4762111826969026e-06, 'alpha': 5.314973446183597e-08, 'max_depth': 5, 'subsample': 0.8838747328379921, 'colsample_bytree': 0.8900795748351464, 'learning_rate': 0.02730976382111885, 'n_estimators': 172}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:44,617] Trial 87 finished with value: 30.212186638819027 and parameters: {'booster': 'gbtree', 'lambda': 1.1105989809737998e-05, 'alpha': 3.535483188917363e-06, 'max_depth': 5, 'subsample': 0.8601427466045516, 'colsample_bytree': 0.9513218185455404, 'learning_rate': 0.020741648932217697, 'n_estimators': 184}. Best is trial 75 with value: 29.714699368411544.\n",
      "[I 2023-12-26 16:13:45,274] Trial 88 finished with value: 29.644350384751412 and parameters: {'booster': 'gbtree', 'lambda': 3.0433251476948645e-05, 'alpha': 6.607357296751633e-07, 'max_depth': 5, 'subsample': 0.9267060968458163, 'colsample_bytree': 0.8421777663255714, 'learning_rate': 0.024692646886133325, 'n_estimators': 195}. Best is trial 88 with value: 29.644350384751412.\n",
      "[I 2023-12-26 16:13:45,660] Trial 89 finished with value: 30.4891048086506 and parameters: {'booster': 'gbtree', 'lambda': 6.3496874327504785e-06, 'alpha': 7.184166867953516e-07, 'max_depth': 4, 'subsample': 0.9563676197713167, 'colsample_bytree': 0.8018047396235669, 'learning_rate': 0.02433086685205216, 'n_estimators': 196}. Best is trial 88 with value: 29.644350384751412.\n",
      "[I 2023-12-26 16:13:46,482] Trial 90 finished with value: 29.99435319856966 and parameters: {'booster': 'gbtree', 'lambda': 2.462199643532768e-07, 'alpha': 5.871280516461645e-06, 'max_depth': 6, 'subsample': 0.9757791835147551, 'colsample_bytree': 0.8292319263460965, 'learning_rate': 0.018543504787517477, 'n_estimators': 230}. Best is trial 88 with value: 29.644350384751412.\n",
      "[I 2023-12-26 16:13:47,077] Trial 91 finished with value: 32.949360058928185 and parameters: {'booster': 'gbtree', 'lambda': 4.6208587466677e-05, 'alpha': 2.5552497081662804e-07, 'max_depth': 5, 'subsample': 0.9257454252422275, 'colsample_bytree': 0.8639414192047394, 'learning_rate': 0.008169678316009128, 'n_estimators': 177}. Best is trial 88 with value: 29.644350384751412.\n",
      "[I 2023-12-26 16:13:47,741] Trial 92 finished with value: 30.593702099943812 and parameters: {'booster': 'gbtree', 'lambda': 3.114702025918237e-05, 'alpha': 3.628210441311311e-07, 'max_depth': 5, 'subsample': 0.9064046933594072, 'colsample_bytree': 0.89418410878173, 'learning_rate': 0.014140904554524387, 'n_estimators': 194}. Best is trial 88 with value: 29.644350384751412.\n",
      "[I 2023-12-26 16:13:48,363] Trial 93 finished with value: 29.479076070916165 and parameters: {'booster': 'gbtree', 'lambda': 2.2917396642170627e-05, 'alpha': 2.4043888510112873e-06, 'max_depth': 5, 'subsample': 0.9455148222259764, 'colsample_bytree': 0.9232209197458731, 'learning_rate': 0.03071755690993936, 'n_estimators': 208}. Best is trial 93 with value: 29.479076070916165.\n",
      "[I 2023-12-26 16:13:49,247] Trial 94 finished with value: 30.760543651842088 and parameters: {'booster': 'gbtree', 'lambda': 5.04177934244679e-07, 'alpha': 2.303904806346103e-06, 'max_depth': 10, 'subsample': 0.9479418712559379, 'colsample_bytree': 0.8347913460825481, 'learning_rate': 0.02879208141733647, 'n_estimators': 161}. Best is trial 93 with value: 29.479076070916165.\n",
      "[I 2023-12-26 16:13:49,945] Trial 95 finished with value: 29.990338147829657 and parameters: {'booster': 'gbtree', 'lambda': 2.059196633470138e-05, 'alpha': 1.3441469369396528e-06, 'max_depth': 5, 'subsample': 0.9998003118804046, 'colsample_bytree': 0.9432734212572208, 'learning_rate': 0.018103755723728472, 'n_estimators': 216}. Best is trial 93 with value: 29.479076070916165.\n",
      "[I 2023-12-26 16:13:50,628] Trial 96 finished with value: 29.860329541768113 and parameters: {'booster': 'gbtree', 'lambda': 2.8742640453482444e-05, 'alpha': 6.342337384512662e-07, 'max_depth': 6, 'subsample': 0.41411642009177696, 'colsample_bytree': 0.9688313518549279, 'learning_rate': 0.030796543316246264, 'n_estimators': 188}. Best is trial 93 with value: 29.479076070916165.\n",
      "[I 2023-12-26 16:13:51,607] Trial 97 finished with value: 31.47103936670034 and parameters: {'booster': 'dart', 'lambda': 2.771545915152154e-05, 'alpha': 6.990912743880782e-07, 'max_depth': 6, 'subsample': 0.2935426664533394, 'colsample_bytree': 0.9742342411516954, 'learning_rate': 0.02465821189212633, 'n_estimators': 188}. Best is trial 93 with value: 29.479076070916165.\n",
      "[I 2023-12-26 16:13:52,278] Trial 98 finished with value: 30.214508559344562 and parameters: {'booster': 'gbtree', 'lambda': 1.1814711873907589e-05, 'alpha': 9.562944488854667e-06, 'max_depth': 6, 'subsample': 0.37768611839530286, 'colsample_bytree': 0.9669247868080939, 'learning_rate': 0.02239148217553434, 'n_estimators': 200}. Best is trial 93 with value: 29.479076070916165.\n",
      "[I 2023-12-26 16:13:52,894] Trial 99 finished with value: 30.2180361527395 and parameters: {'booster': 'gbtree', 'lambda': 9.52230556214095e-06, 'alpha': 1.2239507263624846e-07, 'max_depth': 6, 'subsample': 0.40090504340362304, 'colsample_bytree': 0.9196705903570888, 'learning_rate': 0.03024517753419888, 'n_estimators': 224}. Best is trial 93 with value: 29.479076070916165.\n",
      "[I 2023-12-26 16:13:52,899] A new study created in memory with name: no-name-1c8a693c-bc1d-479b-9825-a49cbe57811b\n",
      "[I 2023-12-26 16:13:52,931] Trial 0 finished with value: 5.296610759817846 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 5.296610759817846.\n",
      "[I 2023-12-26 16:13:52,966] Trial 1 finished with value: 4.9516564213913865 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 1 with value: 4.9516564213913865.\n",
      "[I 2023-12-26 16:13:53,091] Trial 2 finished with value: 4.747276290159792 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 2 with value: 4.747276290159792.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 29.479076070916165\n",
      "  Params: \n",
      "    booster: gbtree\n",
      "    lambda: 2.2917396642170627e-05\n",
      "    alpha: 2.4043888510112873e-06\n",
      "    max_depth: 5\n",
      "    subsample: 0.9455148222259764\n",
      "    colsample_bytree: 0.9232209197458731\n",
      "    learning_rate: 0.03071755690993936\n",
      "    n_estimators: 208\n",
      "[16:13:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:13:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:53,212] Trial 3 finished with value: 4.771451236825011 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 2 with value: 4.747276290159792.\n",
      "[I 2023-12-26 16:13:53,245] Trial 4 finished with value: 5.168968638650903 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 2 with value: 4.747276290159792.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:13:53,702] Trial 5 finished with value: 4.756686918694134 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 2 with value: 4.747276290159792.\n",
      "[I 2023-12-26 16:13:59,763] Trial 6 finished with value: 4.700459746998739 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 6 with value: 4.700459746998739.\n",
      "[I 2023-12-26 16:14:00,065] Trial 7 finished with value: 4.729034862766528 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 6 with value: 4.700459746998739.\n",
      "[I 2023-12-26 16:14:00,129] Trial 8 finished with value: 4.729203392518709 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 6 with value: 4.700459746998739.\n",
      "[I 2023-12-26 16:14:01,057] Trial 9 finished with value: 4.807169074539725 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 6 with value: 4.700459746998739.\n",
      "[I 2023-12-26 16:14:02,821] Trial 10 finished with value: 4.696616608911453 and parameters: {'booster': 'dart', 'lambda': 8.124962944565012e-06, 'alpha': 1.1491548505141235e-08, 'max_depth': 7, 'subsample': 0.5751364799296288, 'colsample_bytree': 0.916898315754266, 'learning_rate': 0.0032425517614221794, 'n_estimators': 295}. Best is trial 10 with value: 4.696616608911453.\n",
      "[I 2023-12-26 16:14:04,842] Trial 11 finished with value: 4.697175491842505 and parameters: {'booster': 'dart', 'lambda': 7.75559510175841e-06, 'alpha': 1.1853705448329331e-08, 'max_depth': 7, 'subsample': 0.5794580507127968, 'colsample_bytree': 0.9916588150293536, 'learning_rate': 0.0030683400070060014, 'n_estimators': 292}. Best is trial 10 with value: 4.696616608911453.\n",
      "[I 2023-12-26 16:14:06,442] Trial 12 finished with value: 4.698636857559692 and parameters: {'booster': 'dart', 'lambda': 1.18257993284632e-05, 'alpha': 1.0798959522730386e-08, 'max_depth': 6, 'subsample': 0.5942610624694253, 'colsample_bytree': 0.9988764065230473, 'learning_rate': 0.0031875671209702075, 'n_estimators': 288}. Best is trial 10 with value: 4.696616608911453.\n",
      "[I 2023-12-26 16:14:08,122] Trial 13 finished with value: 4.694826246244179 and parameters: {'booster': 'dart', 'lambda': 3.3253740789097257e-07, 'alpha': 1.1135591293252908e-08, 'max_depth': 7, 'subsample': 0.970692835118854, 'colsample_bytree': 0.992741706950859, 'learning_rate': 0.0031067386185478444, 'n_estimators': 241}. Best is trial 13 with value: 4.694826246244179.\n",
      "[I 2023-12-26 16:14:09,680] Trial 14 finished with value: 4.704759360474538 and parameters: {'booster': 'dart', 'lambda': 4.372190708647385e-08, 'alpha': 6.833425663452977e-08, 'max_depth': 3, 'subsample': 0.9793057128469835, 'colsample_bytree': 0.790080865387831, 'learning_rate': 0.002386804481418316, 'n_estimators': 236}. Best is trial 13 with value: 4.694826246244179.\n",
      "[I 2023-12-26 16:14:10,575] Trial 15 finished with value: 4.694991556365741 and parameters: {'booster': 'dart', 'lambda': 7.703243715990718e-07, 'alpha': 2.097263173033571e-05, 'max_depth': 8, 'subsample': 0.9107686724474016, 'colsample_bytree': 0.8968574207685822, 'learning_rate': 0.0052075511417194065, 'n_estimators': 241}. Best is trial 13 with value: 4.694826246244179.\n",
      "[I 2023-12-26 16:14:11,228] Trial 16 finished with value: 4.694617805179396 and parameters: {'booster': 'dart', 'lambda': 3.4631663755106965e-07, 'alpha': 6.24222026242346e-05, 'max_depth': 8, 'subsample': 0.9993162304897427, 'colsample_bytree': 0.6979343202316866, 'learning_rate': 0.006071524104769008, 'n_estimators': 230}. Best is trial 16 with value: 4.694617805179396.\n",
      "[I 2023-12-26 16:14:11,393] Trial 17 finished with value: 4.724927497796272 and parameters: {'booster': 'dart', 'lambda': 1.1033236832972273e-08, 'alpha': 0.00031630266873957345, 'max_depth': 10, 'subsample': 0.8439785006031971, 'colsample_bytree': 0.39978712317296744, 'learning_rate': 0.035616379657550025, 'n_estimators': 200}. Best is trial 16 with value: 4.694617805179396.\n",
      "[I 2023-12-26 16:14:11,532] Trial 18 finished with value: 4.69238445144048 and parameters: {'booster': 'dart', 'lambda': 3.7016890522898883e-07, 'alpha': 0.3930425589745921, 'max_depth': 9, 'subsample': 0.9992035592755385, 'colsample_bytree': 0.6883386542597292, 'learning_rate': 0.08459106552440165, 'n_estimators': 261}. Best is trial 18 with value: 4.69238445144048.\n",
      "[I 2023-12-26 16:14:11,667] Trial 19 finished with value: 4.698985912473234 and parameters: {'booster': 'dart', 'lambda': 0.0021995791619433464, 'alpha': 0.5866663448037603, 'max_depth': 9, 'subsample': 0.754715747354047, 'colsample_bytree': 0.6904394509793828, 'learning_rate': 0.07650314720328254, 'n_estimators': 263}. Best is trial 18 with value: 4.69238445144048.\n",
      "[I 2023-12-26 16:14:11,739] Trial 20 finished with value: 5.790498625994817 and parameters: {'booster': 'gblinear', 'lambda': 2.179313868923387e-07, 'alpha': 0.03954192464853706, 'max_depth': 10, 'subsample': 0.7084989779023586, 'colsample_bytree': 0.7064211574644668, 'learning_rate': 0.033052649606942305, 'n_estimators': 196}. Best is trial 18 with value: 4.69238445144048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:14:12,381] Trial 21 finished with value: 4.693148276981154 and parameters: {'booster': 'dart', 'lambda': 1.1168458902066568e-06, 'alpha': 0.001028347584313135, 'max_depth': 8, 'subsample': 0.9966028459647209, 'colsample_bytree': 0.7547835364105744, 'learning_rate': 0.006431873710461328, 'n_estimators': 260}. Best is trial 18 with value: 4.69238445144048.\n",
      "[I 2023-12-26 16:14:12,826] Trial 22 finished with value: 4.690400736120738 and parameters: {'booster': 'dart', 'lambda': 1.6737130361946293e-06, 'alpha': 0.0013994349604265017, 'max_depth': 8, 'subsample': 0.8906943462580239, 'colsample_bytree': 0.7603932624922316, 'learning_rate': 0.008035768028108911, 'n_estimators': 270}. Best is trial 22 with value: 4.690400736120738.\n",
      "[I 2023-12-26 16:14:13,268] Trial 23 finished with value: 4.6943394134599865 and parameters: {'booster': 'dart', 'lambda': 4.7054424540397486e-05, 'alpha': 0.002285610487718376, 'max_depth': 9, 'subsample': 0.8762328092625133, 'colsample_bytree': 0.7557768260187623, 'learning_rate': 0.010265187943312071, 'n_estimators': 267}. Best is trial 22 with value: 4.690400736120738.\n",
      "[I 2023-12-26 16:14:13,686] Trial 24 finished with value: 4.725481432163552 and parameters: {'booster': 'dart', 'lambda': 1.2677224916406679e-06, 'alpha': 0.08116295481341157, 'max_depth': 8, 'subsample': 0.913433643248041, 'colsample_bytree': 0.6198323198848256, 'learning_rate': 0.009093537319511166, 'n_estimators': 265}. Best is trial 22 with value: 4.690400736120738.\n",
      "[I 2023-12-26 16:14:13,848] Trial 25 finished with value: 4.701791961788587 and parameters: {'booster': 'dart', 'lambda': 1.8681220569145662e-06, 'alpha': 0.0007494643083366341, 'max_depth': 9, 'subsample': 0.8333445164552968, 'colsample_bytree': 0.8191975767632667, 'learning_rate': 0.044625994838453024, 'n_estimators': 206}. Best is trial 22 with value: 4.690400736120738.\n",
      "[I 2023-12-26 16:14:14,024] Trial 26 finished with value: 4.736448646260179 and parameters: {'booster': 'dart', 'lambda': 6.796593269728125e-08, 'alpha': 0.09989942810413821, 'max_depth': 6, 'subsample': 0.6672166007452818, 'colsample_bytree': 0.4643683864025715, 'learning_rate': 0.020155222519084887, 'n_estimators': 270}. Best is trial 22 with value: 4.690400736120738.\n",
      "[I 2023-12-26 16:14:14,151] Trial 27 finished with value: 4.681405650574323 and parameters: {'booster': 'dart', 'lambda': 7.68022388812152e-05, 'alpha': 0.006944741395221721, 'max_depth': 8, 'subsample': 0.9525844786717498, 'colsample_bytree': 0.7463370417524927, 'learning_rate': 0.08904839593197302, 'n_estimators': 215}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:14,276] Trial 28 finished with value: 4.730843338485179 and parameters: {'booster': 'dart', 'lambda': 5.910291298550215e-05, 'alpha': 0.005983481908360919, 'max_depth': 10, 'subsample': 0.4728259278115994, 'colsample_bytree': 0.6044090637932833, 'learning_rate': 0.09260873414865031, 'n_estimators': 218}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:14,349] Trial 29 finished with value: 6.259972826021447 and parameters: {'booster': 'gblinear', 'lambda': 0.0017499171181334897, 'alpha': 0.17836299742617692, 'max_depth': 9, 'subsample': 0.9254105099730802, 'colsample_bytree': 0.8802963381900815, 'learning_rate': 0.05966069643321938, 'n_estimators': 216}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:14,424] Trial 30 finished with value: 5.671256073128687 and parameters: {'booster': 'gblinear', 'lambda': 0.00036581283592578814, 'alpha': 0.01874929973867363, 'max_depth': 5, 'subsample': 0.6760810117429294, 'colsample_bytree': 0.6409172992948895, 'learning_rate': 0.026671597072497975, 'n_estimators': 182}. Best is trial 27 with value: 4.681405650574323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:14:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:14:14,555] Trial 31 finished with value: 4.681500411477808 and parameters: {'booster': 'dart', 'lambda': 2.595160309561438e-06, 'alpha': 0.00018144100358243417, 'max_depth': 8, 'subsample': 0.9431309382412109, 'colsample_bytree': 0.7573686227745651, 'learning_rate': 0.09567054688584893, 'n_estimators': 256}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:14,687] Trial 32 finished with value: 4.686331989230631 and parameters: {'booster': 'dart', 'lambda': 2.7879338924546403e-05, 'alpha': 0.00023867977578741133, 'max_depth': 8, 'subsample': 0.9310889469773501, 'colsample_bytree': 0.7458919230097454, 'learning_rate': 0.09487448513721476, 'n_estimators': 240}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:14,829] Trial 33 finished with value: 4.701261809270676 and parameters: {'booster': 'dart', 'lambda': 0.00012827032253559365, 'alpha': 0.00019482966790332936, 'max_depth': 7, 'subsample': 0.8607199130156584, 'colsample_bytree': 0.7559808698392174, 'learning_rate': 0.05819940346779289, 'n_estimators': 249}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:14,955] Trial 34 finished with value: 4.68733620417608 and parameters: {'booster': 'dart', 'lambda': 2.2004719074694914e-05, 'alpha': 1.1634515798936219e-05, 'max_depth': 8, 'subsample': 0.9277915061759858, 'colsample_bytree': 0.8560790057059973, 'learning_rate': 0.09698761897156381, 'n_estimators': 282}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:15,061] Trial 35 finished with value: 4.71409454103583 and parameters: {'booster': 'gbtree', 'lambda': 3.0026136891018713e-05, 'alpha': 1.1742553223167398e-05, 'max_depth': 7, 'subsample': 0.8178947326121684, 'colsample_bytree': 0.8553477753062402, 'learning_rate': 0.09994969578552582, 'n_estimators': 279}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:15,134] Trial 36 finished with value: 6.010627690546045 and parameters: {'booster': 'gblinear', 'lambda': 0.0010983090101697524, 'alpha': 1.8125742601273537e-05, 'max_depth': 8, 'subsample': 0.9460786842151114, 'colsample_bytree': 0.9433615701772337, 'learning_rate': 0.042224125161050056, 'n_estimators': 186}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:15,279] Trial 37 finished with value: 4.700585422740136 and parameters: {'booster': 'dart', 'lambda': 0.0101762621659287, 'alpha': 0.00011748408765187847, 'max_depth': 9, 'subsample': 0.7891333039060568, 'colsample_bytree': 0.8408629486845944, 'learning_rate': 0.07592816390780785, 'n_estimators': 222}. Best is trial 27 with value: 4.681405650574323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:14:15,403] Trial 38 finished with value: 4.804851573107993 and parameters: {'booster': 'gbtree', 'lambda': 0.0001373944002937127, 'alpha': 4.599339616310015e-06, 'max_depth': 7, 'subsample': 0.49045899752784, 'colsample_bytree': 0.10240116514955322, 'learning_rate': 0.04893680692054347, 'n_estimators': 251}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:15,541] Trial 39 finished with value: 4.720656338068993 and parameters: {'booster': 'dart', 'lambda': 2.900124258550888e-06, 'alpha': 0.0002935808858115588, 'max_depth': 6, 'subsample': 0.9408207832405643, 'colsample_bytree': 0.4827661197167026, 'learning_rate': 0.06785556756653902, 'n_estimators': 137}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:15,674] Trial 40 finished with value: 4.726170176823934 and parameters: {'booster': 'dart', 'lambda': 2.1110493988584477e-05, 'alpha': 3.580556088575515e-05, 'max_depth': 8, 'subsample': 0.7298915406853212, 'colsample_bytree': 0.36400624713730834, 'learning_rate': 0.09736919718590385, 'n_estimators': 155}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:15,906] Trial 41 finished with value: 4.6889124207866795 and parameters: {'booster': 'dart', 'lambda': 3.864088557913668e-06, 'alpha': 0.003118142663042854, 'max_depth': 8, 'subsample': 0.9031813312869329, 'colsample_bytree': 0.778628179599279, 'learning_rate': 0.016637524338800416, 'n_estimators': 279}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:16,139] Trial 42 finished with value: 4.692059756851632 and parameters: {'booster': 'dart', 'lambda': 1.9578174831350065e-05, 'alpha': 5.959656954603991e-07, 'max_depth': 8, 'subsample': 0.8752812326265846, 'colsample_bytree': 0.8016225379943088, 'learning_rate': 0.015541417757900307, 'n_estimators': 277}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:16,280] Trial 43 finished with value: 4.7229128604261845 and parameters: {'booster': 'dart', 'lambda': 0.00014355981645088943, 'alpha': 0.005606630483652698, 'max_depth': 9, 'subsample': 0.7833063340282441, 'colsample_bytree': 0.5411345210351585, 'learning_rate': 0.05560233992836942, 'n_estimators': 300}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:16,382] Trial 44 finished with value: 4.772700799193012 and parameters: {'booster': 'gbtree', 'lambda': 4.8614262343252825e-06, 'alpha': 5.610914326764855e-06, 'max_depth': 7, 'subsample': 0.10130501061347807, 'colsample_bytree': 0.9426168866582243, 'learning_rate': 0.0701361692357528, 'n_estimators': 283}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:16,559] Trial 45 finished with value: 4.691589939145738 and parameters: {'booster': 'dart', 'lambda': 3.7964600158204076e-06, 'alpha': 8.997173651687739e-05, 'max_depth': 8, 'subsample': 0.9064345567383641, 'colsample_bytree': 0.8536488714914274, 'learning_rate': 0.034740754942789616, 'n_estimators': 249}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:16,787] Trial 46 finished with value: 4.685754883320908 and parameters: {'booster': 'dart', 'lambda': 5.9442044062446675e-05, 'alpha': 0.012262617925305684, 'max_depth': 8, 'subsample': 0.9485783659171035, 'colsample_bytree': 0.7179933740814359, 'learning_rate': 0.019682584000658705, 'n_estimators': 229}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:16,952] Trial 47 finished with value: 4.726218571205663 and parameters: {'booster': 'dart', 'lambda': 0.0004449012153296561, 'alpha': 0.0080261384140545, 'max_depth': 7, 'subsample': 0.956744081435207, 'colsample_bytree': 0.6411936487326955, 'learning_rate': 0.02678588217120296, 'n_estimators': 211}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:17,027] Trial 48 finished with value: 6.398625618634158 and parameters: {'booster': 'gblinear', 'lambda': 7.005019809850606e-05, 'alpha': 0.02111254636882865, 'max_depth': 8, 'subsample': 0.32227714397070545, 'colsample_bytree': 0.738553513842708, 'learning_rate': 0.0797452121218737, 'n_estimators': 228}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:17,152] Trial 49 finished with value: 4.723637670364554 and parameters: {'booster': 'dart', 'lambda': 1.8371854057599315e-05, 'alpha': 0.0005299760675925678, 'max_depth': 5, 'subsample': 0.8203284401345889, 'colsample_bytree': 0.5690294813321064, 'learning_rate': 0.05286161186519252, 'n_estimators': 235}. Best is trial 27 with value: 4.681405650574323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:14:17,319] Trial 50 finished with value: 4.758316310631086 and parameters: {'booster': 'gbtree', 'lambda': 0.7972579443245569, 'alpha': 1.1957557068311931e-06, 'max_depth': 9, 'subsample': 0.9503124547717825, 'colsample_bytree': 0.730413109787116, 'learning_rate': 0.04045459915846506, 'n_estimators': 247}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:17,657] Trial 51 finished with value: 4.690208748351494 and parameters: {'booster': 'dart', 'lambda': 9.613259344187696e-06, 'alpha': 0.002206192960707368, 'max_depth': 8, 'subsample': 0.867482578379524, 'colsample_bytree': 0.7891018848584765, 'learning_rate': 0.012760505970371948, 'n_estimators': 287}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:17,869] Trial 52 finished with value: 4.684880535876914 and parameters: {'booster': 'dart', 'lambda': 0.00023944350662168223, 'alpha': 0.002225531559276424, 'max_depth': 7, 'subsample': 0.960301783792206, 'colsample_bytree': 0.9202632600529012, 'learning_rate': 0.021543340309094997, 'n_estimators': 256}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:18,074] Trial 53 finished with value: 4.685012970710997 and parameters: {'booster': 'dart', 'lambda': 0.00023133451094395113, 'alpha': 0.011207158366724534, 'max_depth': 7, 'subsample': 0.9627560129395455, 'colsample_bytree': 0.9328954050892804, 'learning_rate': 0.02152749808614893, 'n_estimators': 226}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:18,267] Trial 54 finished with value: 4.689559879986663 and parameters: {'booster': 'dart', 'lambda': 0.0038898117998645058, 'alpha': 0.012395854478696032, 'max_depth': 6, 'subsample': 0.9652747954309253, 'colsample_bytree': 0.9475791950516722, 'learning_rate': 0.02081477535074793, 'n_estimators': 227}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:18,578] Trial 55 finished with value: 4.69136135851847 and parameters: {'booster': 'dart', 'lambda': 0.00022794811145355361, 'alpha': 0.051094188672875004, 'max_depth': 7, 'subsample': 0.9851332157589638, 'colsample_bytree': 0.9033940386090717, 'learning_rate': 0.012093601472772927, 'n_estimators': 199}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:18,740] Trial 56 finished with value: 4.724929347077461 and parameters: {'booster': 'dart', 'lambda': 0.0005089349567377498, 'alpha': 0.0004217570970532784, 'max_depth': 7, 'subsample': 0.8526555293280496, 'colsample_bytree': 0.6654173812297938, 'learning_rate': 0.028227643468790198, 'n_estimators': 240}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:18,949] Trial 57 finished with value: 4.691606084318465 and parameters: {'booster': 'dart', 'lambda': 0.0009196502099708968, 'alpha': 0.0016561527861816566, 'max_depth': 6, 'subsample': 0.9551088323352128, 'colsample_bytree': 0.9612379150709796, 'learning_rate': 0.01827379542847519, 'n_estimators': 258}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:19,161] Trial 58 finished with value: 4.690165636016898 and parameters: {'booster': 'dart', 'lambda': 4.183500374469641e-05, 'alpha': 0.03379746944445163, 'max_depth': 7, 'subsample': 0.8878591272200415, 'colsample_bytree': 0.9164098865460673, 'learning_rate': 0.022643000445759568, 'n_estimators': 208}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:19,468] Trial 59 finished with value: 4.686678589015246 and parameters: {'booster': 'dart', 'lambda': 0.0002498273691971493, 'alpha': 0.0008773865961463147, 'max_depth': 7, 'subsample': 0.9989547606458204, 'colsample_bytree': 0.8247686773750191, 'learning_rate': 0.013090640895820939, 'n_estimators': 235}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:19,603] Trial 60 finished with value: 4.740984145508508 and parameters: {'booster': 'dart', 'lambda': 0.00627206524824377, 'alpha': 0.009916250106412693, 'max_depth': 3, 'subsample': 0.21282727009535152, 'colsample_bytree': 0.5404297132447229, 'learning_rate': 0.03012449241359923, 'n_estimators': 190}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:19,905] Trial 61 finished with value: 4.686804704465823 and parameters: {'booster': 'dart', 'lambda': 0.00021216161057804645, 'alpha': 0.0001636302908982601, 'max_depth': 7, 'subsample': 0.999187867567987, 'colsample_bytree': 0.7180090128732054, 'learning_rate': 0.011992002244877774, 'n_estimators': 233}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:20,136] Trial 62 finished with value: 4.688032853281117 and parameters: {'booster': 'dart', 'lambda': 0.0007403612987194405, 'alpha': 0.0038017747229531973, 'max_depth': 8, 'subsample': 0.9178310361270203, 'colsample_bytree': 0.8290058726882112, 'learning_rate': 0.01718693659977406, 'n_estimators': 221}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:20,256] Trial 63 finished with value: 4.694864719266761 and parameters: {'booster': 'dart', 'lambda': 8.019903338330112e-05, 'alpha': 0.0009750888251790544, 'max_depth': 6, 'subsample': 0.9672215685530595, 'colsample_bytree': 0.8765665903425469, 'learning_rate': 0.0635710073960762, 'n_estimators': 255}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:20,561] Trial 64 finished with value: 4.6888533661703 and parameters: {'booster': 'dart', 'lambda': 0.0002537985936015283, 'alpha': 0.0008768330042566047, 'max_depth': 7, 'subsample': 0.9385649106458899, 'colsample_bytree': 0.8010050443678032, 'learning_rate': 0.013977035980227528, 'n_estimators': 239}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:21,505] Trial 65 finished with value: 4.694262993300885 and parameters: {'booster': 'dart', 'lambda': 0.025486522429413183, 'alpha': 0.00025675720240382583, 'max_depth': 7, 'subsample': 0.9730460137349212, 'colsample_bytree': 0.9752787193298256, 'learning_rate': 0.004607499931943604, 'n_estimators': 243}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:27,223] Trial 66 finished with value: 4.7042149448373 and parameters: {'booster': 'dart', 'lambda': 8.666303670892783e-05, 'alpha': 5.3033027579949153e-05, 'max_depth': 8, 'subsample': 0.8921796834073485, 'colsample_bytree': 0.8974621570355739, 'learning_rate': 0.0015646071245330295, 'n_estimators': 227}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:27,309] Trial 67 finished with value: 5.04737345716398 and parameters: {'booster': 'gblinear', 'lambda': 4.287363452940877e-05, 'alpha': 0.003444679530192613, 'max_depth': 8, 'subsample': 0.8387951344709252, 'colsample_bytree': 0.8203948823862124, 'learning_rate': 0.009482951594214938, 'n_estimators': 168}. Best is trial 27 with value: 4.681405650574323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:14:27,600] Trial 68 finished with value: 4.6929247393455675 and parameters: {'booster': 'dart', 'lambda': 1.5119179833684767e-07, 'alpha': 0.17771178449483854, 'max_depth': 9, 'subsample': 0.9303177328318222, 'colsample_bytree': 0.8800376762401113, 'learning_rate': 0.02205335036234798, 'n_estimators': 55}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:28,056] Trial 69 finished with value: 4.690762731480271 and parameters: {'booster': 'dart', 'lambda': 1.206370051943443e-05, 'alpha': 0.023225595157700705, 'max_depth': 5, 'subsample': 0.9993703439780789, 'colsample_bytree': 0.927199011788822, 'learning_rate': 0.0074981579295926104, 'n_estimators': 216}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:28,223] Trial 70 finished with value: 4.712398601090527 and parameters: {'booster': 'gbtree', 'lambda': 0.0019058337751269123, 'alpha': 0.0012514464444204206, 'max_depth': 7, 'subsample': 0.8095504597934782, 'colsample_bytree': 0.65796034390846, 'learning_rate': 0.08657957244721139, 'n_estimators': 255}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:28,541] Trial 71 finished with value: 4.6870684792026545 and parameters: {'booster': 'dart', 'lambda': 0.00019057074939158547, 'alpha': 0.00013154261008082606, 'max_depth': 7, 'subsample': 0.9986826388349674, 'colsample_bytree': 0.7160510762594825, 'learning_rate': 0.011754914421937112, 'n_estimators': 234}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:28,806] Trial 72 finished with value: 4.694823035786685 and parameters: {'booster': 'dart', 'lambda': 0.00033837519881469385, 'alpha': 0.00018110454291099266, 'max_depth': 6, 'subsample': 0.9183839822973017, 'colsample_bytree': 0.692074503520387, 'learning_rate': 0.013601091168062419, 'n_estimators': 234}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:28,981] Trial 73 finished with value: 4.686386517387547 and parameters: {'booster': 'dart', 'lambda': 0.00011370420332466584, 'alpha': 0.00045920968357678684, 'max_depth': 7, 'subsample': 0.9763450863962558, 'colsample_bytree': 0.7758918792811255, 'learning_rate': 0.025231707458247828, 'n_estimators': 211}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:29,203] Trial 74 finished with value: 4.689869148596237 and parameters: {'booster': 'dart', 'lambda': 3.188276252185014e-05, 'alpha': 0.0006037800472493634, 'max_depth': 7, 'subsample': 0.6267365902231448, 'colsample_bytree': 0.7614122262460555, 'learning_rate': 0.019572246270075533, 'n_estimators': 205}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:29,382] Trial 75 finished with value: 4.728733434431085 and parameters: {'booster': 'dart', 'lambda': 0.00010988235019042248, 'alpha': 0.0019960507370635405, 'max_depth': 8, 'subsample': 0.9701759609175615, 'colsample_bytree': 0.6041334333264676, 'learning_rate': 0.02435756319777772, 'n_estimators': 273}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:29,547] Trial 76 finished with value: 4.6953025852817385 and parameters: {'booster': 'dart', 'lambda': 0.0011131580193367145, 'alpha': 0.008156247528179665, 'max_depth': 6, 'subsample': 0.8881905939628256, 'colsample_bytree': 0.7708403306573695, 'learning_rate': 0.03126311123768107, 'n_estimators': 103}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:29,754] Trial 77 finished with value: 4.69032473154155 and parameters: {'booster': 'dart', 'lambda': 6.457767790516149e-07, 'alpha': 0.0003358229305894897, 'max_depth': 8, 'subsample': 0.4116638415318271, 'colsample_bytree': 0.8165236872075394, 'learning_rate': 0.025152028251405296, 'n_estimators': 216}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:29,922] Trial 78 finished with value: 4.6837527259735205 and parameters: {'booster': 'dart', 'lambda': 0.0006002537525688447, 'alpha': 8.480471274404652e-05, 'max_depth': 7, 'subsample': 0.9445595405034596, 'colsample_bytree': 0.8619232131754544, 'learning_rate': 0.03669489484066233, 'n_estimators': 224}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:30,003] Trial 79 finished with value: 5.905639953195232 and parameters: {'booster': 'gblinear', 'lambda': 0.0005903357276635184, 'alpha': 2.547928000271069e-05, 'max_depth': 8, 'subsample': 0.8659144574806691, 'colsample_bytree': 0.8648740239216561, 'learning_rate': 0.0374925826131899, 'n_estimators': 179}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:30,161] Trial 80 finished with value: 4.725091368335566 and parameters: {'booster': 'dart', 'lambda': 6.171805934720825e-05, 'alpha': 8.777117169357949e-05, 'max_depth': 8, 'subsample': 0.7565474282313958, 'colsample_bytree': 0.23955637361274107, 'learning_rate': 0.05082764987811665, 'n_estimators': 193}. Best is trial 27 with value: 4.681405650574323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:14:30,421] Trial 81 finished with value: 4.6897197584430925 and parameters: {'booster': 'dart', 'lambda': 0.00039450544353637567, 'alpha': 0.00453729859467473, 'max_depth': 7, 'subsample': 0.9384241363895744, 'colsample_bytree': 0.742053887747877, 'learning_rate': 0.015041979286086313, 'n_estimators': 222}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:30,561] Trial 82 finished with value: 4.686230224676872 and parameters: {'booster': 'dart', 'lambda': 0.0001275247805995024, 'alpha': 6.442168043717022e-05, 'max_depth': 7, 'subsample': 0.9084681521461481, 'colsample_bytree': 0.8391852204223347, 'learning_rate': 0.07264678808152095, 'n_estimators': 245}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:30,698] Trial 83 finished with value: 4.687017273643789 and parameters: {'booster': 'dart', 'lambda': 0.00010101371368620661, 'alpha': 6.795446195275846e-05, 'max_depth': 7, 'subsample': 0.9099385505080765, 'colsample_bytree': 0.7879045475337261, 'learning_rate': 0.07566306858991728, 'n_estimators': 245}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:30,854] Trial 84 finished with value: 4.690884372632797 and parameters: {'booster': 'dart', 'lambda': 1.5018921741126727e-05, 'alpha': 3.56207836283909e-05, 'max_depth': 8, 'subsample': 0.951803346961804, 'colsample_bytree': 0.8432420530282996, 'learning_rate': 0.04529001565811443, 'n_estimators': 262}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:30,983] Trial 85 finished with value: 4.682792666570237 and parameters: {'booster': 'dart', 'lambda': 0.0001439898505372957, 'alpha': 0.0004260360628210917, 'max_depth': 7, 'subsample': 0.9782296544324453, 'colsample_bytree': 0.975672256043306, 'learning_rate': 0.08409241915022954, 'n_estimators': 204}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:31,113] Trial 86 finished with value: 4.707216721687143 and parameters: {'booster': 'dart', 'lambda': 7.0063511744452036e-06, 'alpha': 1.1202342665375484e-05, 'max_depth': 6, 'subsample': 0.8995614778294013, 'colsample_bytree': 0.9188797135783916, 'learning_rate': 0.08701159424639271, 'n_estimators': 228}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:31,248] Trial 87 finished with value: 4.742326950537016 and parameters: {'booster': 'gbtree', 'lambda': 0.0028112355716393145, 'alpha': 0.00024945580574833317, 'max_depth': 9, 'subsample': 0.8424424925772492, 'colsample_bytree': 0.8879621833010507, 'learning_rate': 0.0656808231816573, 'n_estimators': 202}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:31,388] Trial 88 finished with value: 4.687559123069728 and parameters: {'booster': 'dart', 'lambda': 2.6681223206212882e-05, 'alpha': 0.014378849628791218, 'max_depth': 8, 'subsample': 0.927870746513972, 'colsample_bytree': 0.9831153476861983, 'learning_rate': 0.07232961480097147, 'n_estimators': 267}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:31,523] Trial 89 finished with value: 4.692566254975045 and parameters: {'booster': 'dart', 'lambda': 0.00015452214921080797, 'alpha': 0.00010286027854409083, 'max_depth': 7, 'subsample': 0.9536948568022043, 'colsample_bytree': 0.9731363194541078, 'learning_rate': 0.05974444632044967, 'n_estimators': 250}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:31,652] Trial 90 finished with value: 4.687144881747084 and parameters: {'booster': 'dart', 'lambda': 0.0013599389482263644, 'alpha': 0.08394549608201472, 'max_depth': 7, 'subsample': 0.8793161108959391, 'colsample_bytree': 0.9486189756442456, 'learning_rate': 0.08362253222978822, 'n_estimators': 243}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:31,789] Trial 91 finished with value: 4.68657882835005 and parameters: {'booster': 'dart', 'lambda': 4.799044455975695e-05, 'alpha': 0.0005119920958841808, 'max_depth': 7, 'subsample': 0.9750868625411359, 'colsample_bytree': 0.9965834499390062, 'learning_rate': 0.09559285151391729, 'n_estimators': 212}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:31,921] Trial 92 finished with value: 4.682836924015115 and parameters: {'booster': 'dart', 'lambda': 0.00013965550001052667, 'alpha': 0.0027694820847771525, 'max_depth': 7, 'subsample': 0.9791229513992653, 'colsample_bytree': 0.9323474866380742, 'learning_rate': 0.08310874695888776, 'n_estimators': 210}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:32,064] Trial 93 finished with value: 4.684480823987151 and parameters: {'booster': 'dart', 'lambda': 0.0006118322502884163, 'alpha': 0.006010652741250066, 'max_depth': 8, 'subsample': 0.9310582230089254, 'colsample_bytree': 0.9327367472007991, 'learning_rate': 0.08858886027066817, 'n_estimators': 224}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:32,202] Trial 94 finished with value: 4.685910544282225 and parameters: {'booster': 'dart', 'lambda': 0.0006897271455890561, 'alpha': 0.00634802282812792, 'max_depth': 7, 'subsample': 0.9092284321356617, 'colsample_bytree': 0.909284344056632, 'learning_rate': 0.07582396212670442, 'n_estimators': 222}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:32,321] Trial 95 finished with value: 4.691942003639865 and parameters: {'booster': 'dart', 'lambda': 0.0006761421946374924, 'alpha': 0.0073703728005250525, 'max_depth': 6, 'subsample': 0.9472555898231806, 'colsample_bytree': 0.9267722914188986, 'learning_rate': 0.08435786437685346, 'n_estimators': 222}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:32,466] Trial 96 finished with value: 4.6919371526426366 and parameters: {'booster': 'dart', 'lambda': 0.004538745004496578, 'alpha': 0.0026691565228220203, 'max_depth': 8, 'subsample': 0.9833924126499182, 'colsample_bytree': 0.9618173261743279, 'learning_rate': 0.06267656986144057, 'n_estimators': 190}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:32,618] Trial 97 finished with value: 4.69204046912498 and parameters: {'booster': 'dart', 'lambda': 0.0004172168126545157, 'alpha': 0.025886014118178462, 'max_depth': 7, 'subsample': 0.8605675315242798, 'colsample_bytree': 0.91433472500382, 'learning_rate': 0.04564983091676835, 'n_estimators': 196}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:32,697] Trial 98 finished with value: 6.433440882774249 and parameters: {'booster': 'gblinear', 'lambda': 0.001508470623444905, 'alpha': 0.04878958734045642, 'max_depth': 8, 'subsample': 0.9337752879127577, 'colsample_bytree': 0.9376114959536663, 'learning_rate': 0.09070843359850016, 'n_estimators': 203}. Best is trial 27 with value: 4.681405650574323.\n",
      "[I 2023-12-26 16:14:32,848] Trial 99 finished with value: 4.688940625526046 and parameters: {'booster': 'dart', 'lambda': 0.0009624443125687995, 'alpha': 0.005340814454886007, 'max_depth': 7, 'subsample': 0.967470918722151, 'colsample_bytree': 0.9000273858206834, 'learning_rate': 0.053803175130613654, 'n_estimators': 211}. Best is trial 27 with value: 4.681405650574323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Best trial:\n",
      "  Value: 4.681405650574323\n",
      "  Params: \n",
      "    booster: dart\n",
      "    lambda: 7.68022388812152e-05\n",
      "    alpha: 0.006944741395221721\n",
      "    max_depth: 8\n",
      "    subsample: 0.9525844786717498\n",
      "    colsample_bytree: 0.7463370417524927\n",
      "    learning_rate: 0.08904839593197302\n",
      "    n_estimators: 215\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "\n",
    "    X, y = base_select_label(data, labels, label)\n",
    "    \n",
    "    X['months'] = X['months'].astype(int)\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_data(X,y, 1095)\n",
    "\n",
    "    study = make_model_opt(X_train,y_train, X_test, y_test)\n",
    "    \n",
    "    globals()[label+\"_model\"] = study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e7ed4ae-85ee-416d-861c-c8be715838c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_88756\\1978695544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1095\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_model\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_88756\\3040474686.py\u001b[0m in \u001b[0;36mmake_model\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mparam_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;31m# n_iter=50,  # 반복 횟수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# cv=5,  # 교차 검증 폴드 수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diquest\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, estimator, search_spaces, optimizer_kwargs, n_iter, scoring, fit_params, n_jobs, n_points, iid, refit, cv, verbose, pre_dispatch, random_state, error_score, return_train_score)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_search_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_spaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[1;31m# Temporary fix for compatibility with sklearn 0.20 and 0.21\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# See scikit-optimize#762\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diquest\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_check_search_space\u001b[1;34m(self, search_space)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msubspace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdicts_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m                     \u001b[0mcheck_dimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             raise TypeError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diquest\\lib\\site-packages\\skopt\\space\\space.py\u001b[0m in \u001b[0;36mcheck_dimension\u001b[1;34m(dimension, transform)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m# for examples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diquest\\lib\\site-packages\\skopt\\space\\space.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, categories, prior, transform, name)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"onehot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diquest\\lib\\site-packages\\skopt\\space\\space.py\u001b[0m in \u001b[0;36mset_transformer\u001b[1;34m(self, transform)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"onehot\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"string\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diquest\\lib\\site-packages\\skopt\\space\\transformers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \"\"\"\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_mapping_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diquest\\lib\\site-packages\\skopt\\space\\transformers.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \"\"\"\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_mapping_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'DataFrame'"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "\n",
    "    X, y = base_select_label(data, labels, label)\n",
    "    \n",
    "    X['months'] = X['months'].astype(int)\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_data(X,y, 1095)\n",
    "\n",
    "    opt = make_model(X_train,y_train, X_test, y_test)\n",
    "    \n",
    "    globals()[label+\"_model\"] = opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91776cb7-9ff9-4764-b583-66715deb3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f758288-cc42-4dc5-9ba8-d6af7c6fabb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Value: 3.081674730723307\n"
     ]
    }
   ],
   "source": [
    "print('  Value: {}'.format(최고기온_model.best_trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853f997-b50d-4206-a934-7cf7d37cf545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6210766-21a6-43ca-899f-60d7232d0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\",\"일사합\", \"일조율\", \"강수량\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\",\"일사합\",\"강수량\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\", \"일조율\", \"강수량\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\",\"일사합\",\"강수량\"]]\n",
    "X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\",\"일조율\", \"강수량\"]]\n",
    "y = data[\"평균기온\"]\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_data(X,y, 1095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec3cfb7c-e81d-4df4-8cec-f39a2e1b2bc1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:24:28,915] A new study created in memory with name: no-name-ec7c2258-800e-4aa8-bc22-ecea31795058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:24:29,207] Trial 0 finished with value: 0.8503493992909449 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07, 'max_depth': 4, 'subsample': 0.15227525095137953, 'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.015930522616241012, 'n_estimators': 227}. Best is trial 0 with value: 0.8503493992909449.\n",
      "[I 2023-12-26 16:24:29,372] Trial 1 finished with value: 3.5696285768751412 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07, 'max_depth': 4, 'subsample': 0.373818018663584, 'colsample_bytree': 0.5722807884690141, 'learning_rate': 0.007309539835912915, 'n_estimators': 123}. Best is trial 0 with value: 0.8503493992909449.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:24:29,775] Trial 2 finished with value: 5.6718128581161364 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05, 'max_depth': 9, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'learning_rate': 0.015304852121831466, 'n_estimators': 61}. Best is trial 0 with value: 0.8503493992909449.\n",
      "[I 2023-12-26 16:24:30,390] Trial 3 finished with value: 2.589454817861557 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921, 'max_depth': 9, 'subsample': 0.3741523922560336, 'colsample_bytree': 0.1879049026057455, 'learning_rate': 0.0233596350262616, 'n_estimators': 160}. Best is trial 0 with value: 0.8503493992909449.\n",
      "[I 2023-12-26 16:24:30,531] Trial 4 finished with value: 2.8972473121260944 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06, 'max_depth': 8, 'subsample': 0.3805399684804699, 'colsample_bytree': 0.5680612190600297, 'learning_rate': 0.0123999678368461, 'n_estimators': 96}. Best is trial 0 with value: 0.8503493992909449.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:24:31,156] Trial 5 finished with value: 12.359822935079604 and parameters: {'booster': 'gbtree', 'lambda': 0.14408501080722544, 'alpha': 0.0006070155694141794, 'max_depth': 10, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'learning_rate': 0.0012315571723666018, 'n_estimators': 131}. Best is trial 0 with value: 0.8503493992909449.\n",
      "[I 2023-12-26 16:24:43,177] Trial 6 finished with value: 9.351700162130948 and parameters: {'booster': 'dart', 'lambda': 7.145401117237584e-06, 'alpha': 1.7679748286442581e-06, 'max_depth': 7, 'subsample': 0.2268318024772864, 'colsample_bytree': 0.8219772826786357, 'learning_rate': 0.0014096175149815868, 'n_estimators': 297}. Best is trial 0 with value: 0.8503493992909449.\n",
      "[I 2023-12-26 16:24:43,490] Trial 7 finished with value: 10.6085519766862 and parameters: {'booster': 'gbtree', 'lambda': 0.03339576740674938, 'alpha': 0.0045170900739091345, 'max_depth': 8, 'subsample': 0.7941433120173511, 'colsample_bytree': 0.16664018656068133, 'learning_rate': 0.005211124595788265, 'n_estimators': 79}. Best is trial 0 with value: 0.8503493992909449.\n",
      "[I 2023-12-26 16:24:44,094] Trial 8 finished with value: 0.36638134347776713 and parameters: {'booster': 'gbtree', 'lambda': 3.224532824812341e-08, 'alpha': 3.075095259104445e-06, 'max_depth': 5, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'learning_rate': 0.059487468132197734, 'n_estimators': 168}. Best is trial 8 with value: 0.36638134347776713.\n",
      "[I 2023-12-26 16:24:45,127] Trial 9 finished with value: 13.049691514876335 and parameters: {'booster': 'dart', 'lambda': 0.0003091844051450647, 'alpha': 0.014714226590398758, 'max_depth': 6, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'learning_rate': 0.0011241862095793063, 'n_estimators': 77}. Best is trial 8 with value: 0.36638134347776713.\n",
      "[I 2023-12-26 16:24:45,743] Trial 10 finished with value: 0.37766396510818784 and parameters: {'booster': 'gbtree', 'lambda': 1.116805293160088e-08, 'alpha': 1.1491548505141235e-08, 'max_depth': 3, 'subsample': 0.9786917711698019, 'colsample_bytree': 0.7598785099640686, 'learning_rate': 0.0881744100052964, 'n_estimators': 219}. Best is trial 8 with value: 0.36638134347776713.\n",
      "[I 2023-12-26 16:24:46,222] Trial 11 finished with value: 0.3800707730963895 and parameters: {'booster': 'gbtree', 'lambda': 1.0690705252212232e-08, 'alpha': 1.2070660524894436e-08, 'max_depth': 3, 'subsample': 0.9759730320176591, 'colsample_bytree': 0.7541887006644162, 'learning_rate': 0.09721966993689589, 'n_estimators': 216}. Best is trial 8 with value: 0.36638134347776713.\n",
      "[I 2023-12-26 16:24:46,832] Trial 12 finished with value: 0.36435631250886075 and parameters: {'booster': 'gbtree', 'lambda': 1.0800734409439694e-08, 'alpha': 1.2084903458776835e-08, 'max_depth': 5, 'subsample': 0.9614226401782306, 'colsample_bytree': 0.9969603313327517, 'learning_rate': 0.09861713308712067, 'n_estimators': 211}. Best is trial 12 with value: 0.36435631250886075.\n",
      "[I 2023-12-26 16:24:47,615] Trial 13 finished with value: 0.3686327056423442 and parameters: {'booster': 'gbtree', 'lambda': 2.0388192922657925e-07, 'alpha': 1.665002867819998e-05, 'max_depth': 5, 'subsample': 0.7753407952093393, 'colsample_bytree': 0.9857920070716526, 'learning_rate': 0.04168043620362369, 'n_estimators': 183}. Best is trial 12 with value: 0.36435631250886075.\n",
      "[I 2023-12-26 16:24:48,641] Trial 14 finished with value: 0.36359367721434477 and parameters: {'booster': 'gbtree', 'lambda': 1.6146407502997316e-07, 'alpha': 9.807167833981538e-06, 'max_depth': 6, 'subsample': 0.7907993258012694, 'colsample_bytree': 0.9688041514589095, 'learning_rate': 0.046643677618952786, 'n_estimators': 270}. Best is trial 14 with value: 0.36359367721434477.\n",
      "[I 2023-12-26 16:24:56,896] Trial 15 finished with value: 0.3653724148502089 and parameters: {'booster': 'dart', 'lambda': 1.1426317436115804e-06, 'alpha': 0.0002953851542568911, 'max_depth': 6, 'subsample': 0.6447283253670815, 'colsample_bytree': 0.9933874717728974, 'learning_rate': 0.03743309561243859, 'n_estimators': 293}. Best is trial 14 with value: 0.36359367721434477.\n",
      "[I 2023-12-26 16:24:58,020] Trial 16 finished with value: 0.36393414461823637 and parameters: {'booster': 'gbtree', 'lambda': 9.686553267831243e-08, 'alpha': 9.716490864088478e-08, 'max_depth': 5, 'subsample': 0.8892047219701569, 'colsample_bytree': 0.9072168122674455, 'learning_rate': 0.032097864674854856, 'n_estimators': 257}. Best is trial 14 with value: 0.36359367721434477.\n",
      "[I 2023-12-26 16:24:59,317] Trial 17 finished with value: 0.4798393334155758 and parameters: {'booster': 'gbtree', 'lambda': 3.046135392550891e-05, 'alpha': 1.8821827511223498e-07, 'max_depth': 7, 'subsample': 0.8369809858650438, 'colsample_bytree': 0.4073950854419431, 'learning_rate': 0.027500151998369658, 'n_estimators': 261}. Best is trial 14 with value: 0.36359367721434477.\n",
      "[I 2023-12-26 16:25:10,681] Trial 18 finished with value: 6.173972739677995 and parameters: {'booster': 'dart', 'lambda': 0.0038731263135072095, 'alpha': 1.4877568870546897e-05, 'max_depth': 6, 'subsample': 0.6577247034810735, 'colsample_bytree': 0.8707703341211004, 'learning_rate': 0.0032614736785757385, 'n_estimators': 257}. Best is trial 14 with value: 0.36359367721434477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:25:11,109] Trial 19 finished with value: 0.503380371345139 and parameters: {'booster': 'gblinear', 'lambda': 1.4285006698659757e-07, 'alpha': 5.148105284588349e-06, 'max_depth': 4, 'subsample': 0.882018584239708, 'colsample_bytree': 0.6844517835626445, 'learning_rate': 0.0453672775647755, 'n_estimators': 254}. Best is trial 14 with value: 0.36359367721434477.\n",
      "[I 2023-12-26 16:25:13,217] Trial 20 finished with value: 0.36152965687045224 and parameters: {'booster': 'gbtree', 'lambda': 1.8724498765264119e-06, 'alpha': 0.00015407322697889175, 'max_depth': 7, 'subsample': 0.6918575073913608, 'colsample_bytree': 0.9044365415168654, 'learning_rate': 0.022742617693521965, 'n_estimators': 277}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:15,256] Trial 21 finished with value: 0.3632023169739878 and parameters: {'booster': 'gbtree', 'lambda': 1.8831351715481286e-06, 'alpha': 0.001028347584313135, 'max_depth': 7, 'subsample': 0.7132875850649778, 'colsample_bytree': 0.8909338943136295, 'learning_rate': 0.023300446422844564, 'n_estimators': 276}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:17,256] Trial 22 finished with value: 0.37808943164964387 and parameters: {'booster': 'gbtree', 'lambda': 1.6737130361946293e-06, 'alpha': 0.0015943926163806308, 'max_depth': 7, 'subsample': 0.7022370285706172, 'colsample_bytree': 0.7950222953483171, 'learning_rate': 0.01933429140643277, 'n_estimators': 277}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:18,791] Trial 23 finished with value: 0.3642725179551944 and parameters: {'booster': 'gbtree', 'lambda': 4.228468168984074e-06, 'alpha': 0.025369443415753423, 'max_depth': 8, 'subsample': 0.5136949867645081, 'colsample_bytree': 0.9234735632471864, 'learning_rate': 0.058928055647461015, 'n_estimators': 241}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:20,851] Trial 24 finished with value: 1.1608037318820006 and parameters: {'booster': 'gbtree', 'lambda': 2.1853013232785177e-05, 'alpha': 0.0001405126238529777, 'max_depth': 7, 'subsample': 0.5810650503281545, 'colsample_bytree': 0.9159966730726792, 'learning_rate': 0.009302867595219939, 'n_estimators': 277}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:22,534] Trial 25 finished with value: 0.3633739721487579 and parameters: {'booster': 'gbtree', 'lambda': 8.72750265932015e-05, 'alpha': 4.779818229786905e-05, 'max_depth': 6, 'subsample': 0.4951832124293183, 'colsample_bytree': 0.68533838555212, 'learning_rate': 0.023540039256161813, 'n_estimators': 281}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:24,104] Trial 26 finished with value: 0.42858424983816606 and parameters: {'booster': 'gbtree', 'lambda': 9.263925182194197e-05, 'alpha': 8.412281078225467e-05, 'max_depth': 8, 'subsample': 0.4330217289561772, 'colsample_bytree': 0.7098680868848608, 'learning_rate': 0.022657084895304772, 'n_estimators': 192}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:26,776] Trial 27 finished with value: 0.9154489720656992 and parameters: {'booster': 'gbtree', 'lambda': 0.0022914913638179945, 'alpha': 0.12512929956640986, 'max_depth': 9, 'subsample': 0.5077761447152429, 'colsample_bytree': 0.6177241026601895, 'learning_rate': 0.010223956000613823, 'n_estimators': 297}. Best is trial 20 with value: 0.36152965687045224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:25:27,169] Trial 28 finished with value: 3.036982743226366 and parameters: {'booster': 'gblinear', 'lambda': 6.664727900514889e-05, 'alpha': 0.001826637884996049, 'max_depth': 7, 'subsample': 0.631692957043795, 'colsample_bytree': 0.8142332248552395, 'learning_rate': 0.00482912317701799, 'n_estimators': 233}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:37,057] Trial 29 finished with value: 0.7021254183658182 and parameters: {'booster': 'dart', 'lambda': 0.0005548390383485422, 'alpha': 0.0007151793965951698, 'max_depth': 6, 'subsample': 0.7082218597428098, 'colsample_bytree': 0.43493977411236623, 'learning_rate': 0.016998633997855176, 'n_estimators': 243}. Best is trial 20 with value: 0.36152965687045224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:25:37,533] Trial 30 finished with value: 0.8238967282410081 and parameters: {'booster': 'gblinear', 'lambda': 2.7714858674907465e-06, 'alpha': 5.029624039624803e-05, 'max_depth': 8, 'subsample': 0.47298807320857056, 'colsample_bytree': 0.849479545159001, 'learning_rate': 0.012923252623290252, 'n_estimators': 289}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:38,439] Trial 31 finished with value: 0.3626221327517675 and parameters: {'booster': 'gbtree', 'lambda': 5.780490018517557e-07, 'alpha': 1.146736468543638e-05, 'max_depth': 6, 'subsample': 0.6129643102609612, 'colsample_bytree': 0.9344738534459147, 'learning_rate': 0.056769415242858834, 'n_estimators': 275}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:39,419] Trial 32 finished with value: 0.36278584618002313 and parameters: {'booster': 'gbtree', 'lambda': 1.4896652073807367e-06, 'alpha': 0.00018653123657930452, 'max_depth': 6, 'subsample': 0.5968164527943995, 'colsample_bytree': 0.8798933095472191, 'learning_rate': 0.05942084493765945, 'n_estimators': 278}. Best is trial 20 with value: 0.36152965687045224.\n",
      "[I 2023-12-26 16:25:40,555] Trial 33 finished with value: 0.3595470589691918 and parameters: {'booster': 'gbtree', 'lambda': 1.4672246596368952e-06, 'alpha': 0.00024193580628132107, 'max_depth': 7, 'subsample': 0.7054937452731973, 'colsample_bytree': 0.8885148411296009, 'learning_rate': 0.06601810339980696, 'n_estimators': 269}. Best is trial 33 with value: 0.3595470589691918.\n",
      "[I 2023-12-26 16:25:41,696] Trial 34 finished with value: 0.3645355072967947 and parameters: {'booster': 'gbtree', 'lambda': 5.98643922695407e-07, 'alpha': 0.0002986878545092895, 'max_depth': 4, 'subsample': 0.592788353504593, 'colsample_bytree': 0.9487829837523766, 'learning_rate': 0.07209216722302397, 'n_estimators': 241}. Best is trial 33 with value: 0.3595470589691918.\n",
      "[I 2023-12-26 16:25:42,466] Trial 35 finished with value: 0.3654240841884591 and parameters: {'booster': 'gbtree', 'lambda': 4.695661093754194e-07, 'alpha': 8.190288996494954e-07, 'max_depth': 5, 'subsample': 0.6681461156830322, 'colsample_bytree': 0.7618736183165676, 'learning_rate': 0.06950329106415563, 'n_estimators': 199}. Best is trial 33 with value: 0.3595470589691918.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:25:42,773] Trial 36 finished with value: 0.5374023837266175 and parameters: {'booster': 'gblinear', 'lambda': 1.368035786279106e-05, 'alpha': 0.00020287613913662337, 'max_depth': 7, 'subsample': 0.4183182824021185, 'colsample_bytree': 0.8423192821510649, 'learning_rate': 0.05424238695226363, 'n_estimators': 153}. Best is trial 33 with value: 0.3595470589691918.\n",
      "[I 2023-12-26 16:25:44,600] Trial 37 finished with value: 0.41028141471621105 and parameters: {'booster': 'gbtree', 'lambda': 6.99704223883171e-07, 'alpha': 2.2702614700284286e-05, 'max_depth': 9, 'subsample': 0.29469981656763466, 'colsample_bytree': 0.6121350621273345, 'learning_rate': 0.03554149987247947, 'n_estimators': 266}. Best is trial 33 with value: 0.3595470589691918.\n",
      "[I 2023-12-26 16:25:45,587] Trial 38 finished with value: 0.8406771105495559 and parameters: {'booster': 'gbtree', 'lambda': 4.531158952268673e-08, 'alpha': 0.0039039432037887485, 'max_depth': 6, 'subsample': 0.6099405644378426, 'colsample_bytree': 0.10240116514955322, 'learning_rate': 0.07151512046212087, 'n_estimators': 229}. Best is trial 33 with value: 0.3595470589691918.\n",
      "[I 2023-12-26 16:25:47,885] Trial 39 finished with value: 0.3581119118212429 and parameters: {'booster': 'gbtree', 'lambda': 6.4514502091526016e-06, 'alpha': 0.010675235211184745, 'max_depth': 8, 'subsample': 0.5473391330530959, 'colsample_bytree': 0.8719674503467574, 'learning_rate': 0.029307178574022204, 'n_estimators': 300}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:25:48,829] Trial 40 finished with value: 1.2667595004783647 and parameters: {'booster': 'gbtree', 'lambda': 7.167310796404915e-06, 'alpha': 0.9764522517882088, 'max_depth': 10, 'subsample': 0.5369502100852863, 'colsample_bytree': 0.31452552710741866, 'learning_rate': 0.031515424735136945, 'n_estimators': 126}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:25:50,210] Trial 41 finished with value: 0.3637545385592741 and parameters: {'booster': 'gbtree', 'lambda': 3.751602438726429e-07, 'alpha': 0.05612126778080248, 'max_depth': 8, 'subsample': 0.562923236627939, 'colsample_bytree': 0.8658443255922834, 'learning_rate': 0.051073293948696585, 'n_estimators': 299}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:25:51,116] Trial 42 finished with value: 0.36213725098327965 and parameters: {'booster': 'gbtree', 'lambda': 4.768818581025436e-06, 'alpha': 0.007890822024620131, 'max_depth': 7, 'subsample': 0.720047689454661, 'colsample_bytree': 0.930629302172141, 'learning_rate': 0.07976884725798118, 'n_estimators': 284}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:25:52,277] Trial 43 finished with value: 0.37173067170735363 and parameters: {'booster': 'gbtree', 'lambda': 3.727084321772638e-06, 'alpha': 0.008249074663959775, 'max_depth': 9, 'subsample': 0.7444074288627225, 'colsample_bytree': 0.9301115771823815, 'learning_rate': 0.07993724998982271, 'n_estimators': 285}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:25:53,813] Trial 44 finished with value: 0.3708113130954303 and parameters: {'booster': 'gbtree', 'lambda': 9.629884298415755e-06, 'alpha': 0.11104488156882814, 'max_depth': 8, 'subsample': 0.10130501061347807, 'colsample_bytree': 0.8186622301638075, 'learning_rate': 0.028720346888565996, 'n_estimators': 248}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:26:04,352] Trial 45 finished with value: 0.36010176505128 and parameters: {'booster': 'dart', 'lambda': 2.432586373672495e-05, 'alpha': 0.2699701380674673, 'max_depth': 7, 'subsample': 0.8483381342812637, 'colsample_bytree': 0.9496195934766299, 'learning_rate': 0.037784307987387314, 'n_estimators': 267}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:26:13,921] Trial 46 finished with value: 0.3595232732981852 and parameters: {'booster': 'dart', 'lambda': 0.000214803510760927, 'alpha': 0.3442237657100567, 'max_depth': 7, 'subsample': 0.8200310247655282, 'colsample_bytree': 0.7808756469838566, 'learning_rate': 0.0407845896802897, 'n_estimators': 265}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:26:23,513] Trial 47 finished with value: 0.3790452430074074 and parameters: {'booster': 'dart', 'lambda': 0.0001864934717029553, 'alpha': 0.546997307512073, 'max_depth': 8, 'subsample': 0.8423754664622694, 'colsample_bytree': 0.7728173286607981, 'learning_rate': 0.04154878036413855, 'n_estimators': 267}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:26:28,066] Trial 48 finished with value: 1.4642509905987133 and parameters: {'booster': 'dart', 'lambda': 3.470429000946844e-05, 'alpha': 0.19068665510886126, 'max_depth': 7, 'subsample': 0.9187536338893296, 'colsample_bytree': 0.7233457370326485, 'learning_rate': 0.01591904297996284, 'n_estimators': 148}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:26:36,766] Trial 49 finished with value: 0.455927414077602 and parameters: {'booster': 'dart', 'lambda': 0.001639959513850393, 'alpha': 0.02609689886146247, 'max_depth': 8, 'subsample': 0.8197356540873131, 'colsample_bytree': 0.9634982723164904, 'learning_rate': 0.019788148780448964, 'n_estimators': 207}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:26:49,619] Trial 50 finished with value: 0.36575644070155006 and parameters: {'booster': 'dart', 'lambda': 0.0207589061609371, 'alpha': 0.22057930482642538, 'max_depth': 9, 'subsample': 0.8738296939150362, 'colsample_bytree': 0.8358086527877843, 'learning_rate': 0.03738685095457775, 'n_estimators': 251}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:26:51,937] Trial 51 finished with value: 0.366047420768433 and parameters: {'booster': 'dart', 'lambda': 0.00023864642889020882, 'alpha': 0.05861336312272525, 'max_depth': 7, 'subsample': 0.7404920814356389, 'colsample_bytree': 0.8967803509756681, 'learning_rate': 0.09651083789661097, 'n_estimators': 109}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:27:00,687] Trial 52 finished with value: 0.3623616940626815 and parameters: {'booster': 'dart', 'lambda': 1.604117710834085e-05, 'alpha': 0.003102298115259264, 'max_depth': 7, 'subsample': 0.7951874182775253, 'colsample_bytree': 0.9651804585031454, 'learning_rate': 0.04667637558639435, 'n_estimators': 289}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:27:13,045] Trial 53 finished with value: 9.115817236225356 and parameters: {'booster': 'dart', 'lambda': 4.4090787804794144e-05, 'alpha': 0.01116545054177728, 'max_depth': 7, 'subsample': 0.9305903238868065, 'colsample_bytree': 0.8031725842573274, 'learning_rate': 0.0016831609954217925, 'n_estimators': 264}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:27:27,806] Trial 54 finished with value: 0.360492945435929 and parameters: {'booster': 'dart', 'lambda': 4.9452706391733485e-06, 'alpha': 0.42250845517861485, 'max_depth': 7, 'subsample': 0.698550053556799, 'colsample_bytree': 0.9941742270602809, 'learning_rate': 0.02715945090956605, 'n_estimators': 290}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:27:44,474] Trial 55 finished with value: 0.36035311411504883 and parameters: {'booster': 'dart', 'lambda': 1.091841754198432e-05, 'alpha': 0.4233925248691701, 'max_depth': 8, 'subsample': 0.6652060587711437, 'colsample_bytree': 0.8698069514778349, 'learning_rate': 0.027201650845712407, 'n_estimators': 300}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:28:01,031] Trial 56 finished with value: 0.365075935800326 and parameters: {'booster': 'dart', 'lambda': 0.000161904964785032, 'alpha': 0.4199988596799743, 'max_depth': 9, 'subsample': 0.6697454364099242, 'colsample_bytree': 0.9869999051616313, 'learning_rate': 0.030883479763066567, 'n_estimators': 294}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:28:18,498] Trial 57 finished with value: 0.3602007689813501 and parameters: {'booster': 'dart', 'lambda': 0.0005548270516767072, 'alpha': 0.39451135880822114, 'max_depth': 8, 'subsample': 0.7691156493755185, 'colsample_bytree': 0.9992074510108689, 'learning_rate': 0.025382818375258746, 'n_estimators': 300}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:28:35,976] Trial 58 finished with value: 0.5775526017576592 and parameters: {'booster': 'dart', 'lambda': 0.0006959432767688564, 'alpha': 0.9059135857516772, 'max_depth': 8, 'subsample': 0.7741351502753023, 'colsample_bytree': 0.8611474222185708, 'learning_rate': 0.011961845060709332, 'n_estimators': 300}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:28:45,005] Trial 59 finished with value: 0.35946926398908713 and parameters: {'booster': 'dart', 'lambda': 0.0004481688040181212, 'alpha': 0.06463429270691189, 'max_depth': 8, 'subsample': 0.811749894973032, 'colsample_bytree': 0.7858667002529133, 'learning_rate': 0.03994563999309482, 'n_estimators': 268}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:28:56,126] Trial 60 finished with value: 0.5434575873858307 and parameters: {'booster': 'dart', 'lambda': 0.00976178682046707, 'alpha': 0.04727423389463114, 'max_depth': 10, 'subsample': 0.8211817378733886, 'colsample_bytree': 0.5181070335249662, 'learning_rate': 0.041399321713781835, 'n_estimators': 259}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:29:08,748] Trial 61 finished with value: 0.37662284441190225 and parameters: {'booster': 'dart', 'lambda': 0.0009877780145499848, 'alpha': 0.21073443736048195, 'max_depth': 8, 'subsample': 0.852206605426187, 'colsample_bytree': 0.7242561451722579, 'learning_rate': 0.03584870101178009, 'n_estimators': 270}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:29:09,995] Trial 62 finished with value: 2.9834035902752727 and parameters: {'booster': 'dart', 'lambda': 6.16078570526859e-05, 'alpha': 0.11398575774525976, 'max_depth': 9, 'subsample': 0.7975682784884528, 'colsample_bytree': 0.7940968957462023, 'learning_rate': 0.02649442682869535, 'n_estimators': 59}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:29:22,316] Trial 63 finished with value: 0.5093590894518377 and parameters: {'booster': 'dart', 'lambda': 0.00047196040262695755, 'alpha': 0.02452815184985536, 'max_depth': 8, 'subsample': 0.7607078446617147, 'colsample_bytree': 0.6399294721348365, 'learning_rate': 0.018930874598131173, 'n_estimators': 220}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:29:33,313] Trial 64 finished with value: 0.36572271013913094 and parameters: {'booster': 'dart', 'lambda': 0.005320153274640209, 'alpha': 0.3125935775108008, 'max_depth': 8, 'subsample': 0.9203942670990533, 'colsample_bytree': 0.8703816380591667, 'learning_rate': 0.044838069552507014, 'n_estimators': 235}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:29:49,177] Trial 65 finished with value: 0.36532788265785676 and parameters: {'booster': 'dart', 'lambda': 0.0003904073471188865, 'alpha': 0.09479750765835769, 'max_depth': 8, 'subsample': 0.9981129619019607, 'colsample_bytree': 0.9002993388511243, 'learning_rate': 0.03338680518011663, 'n_estimators': 285}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:30:03,369] Trial 66 finished with value: 0.3792413794939921 and parameters: {'booster': 'dart', 'lambda': 0.6231169561727892, 'alpha': 0.54955232202357, 'max_depth': 8, 'subsample': 0.8777944201592838, 'colsample_bytree': 0.747060387164497, 'learning_rate': 0.024387608417442794, 'n_estimators': 271}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:30:07,759] Trial 67 finished with value: 0.3648578315891632 and parameters: {'booster': 'dart', 'lambda': 0.0001299147756519167, 'alpha': 0.04796075288592688, 'max_depth': 7, 'subsample': 0.8014975125909339, 'colsample_bytree': 0.9531550625223663, 'learning_rate': 0.06395629741753595, 'n_estimators': 250}. Best is trial 39 with value: 0.3581119118212429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:30:08,279] Trial 68 finished with value: 0.48701659374619466 and parameters: {'booster': 'gblinear', 'lambda': 1.9327812028478787e-05, 'alpha': 0.02190055290439451, 'max_depth': 8, 'subsample': 0.7335419950392384, 'colsample_bytree': 0.7842011488958522, 'learning_rate': 0.04978546064124286, 'n_estimators': 300}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:30:22,239] Trial 69 finished with value: 0.3641404811105772 and parameters: {'booster': 'dart', 'lambda': 9.530642554866493e-06, 'alpha': 0.2142217569614281, 'max_depth': 9, 'subsample': 0.7654394267795244, 'colsample_bytree': 0.8295798623949853, 'learning_rate': 0.03971598107671305, 'n_estimators': 258}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:30:37,490] Trial 70 finished with value: 0.45791916519539544 and parameters: {'booster': 'dart', 'lambda': 0.0013983352711964196, 'alpha': 0.0702098415785187, 'max_depth': 7, 'subsample': 0.6446100517044793, 'colsample_bytree': 0.8911847920728917, 'learning_rate': 0.013981156878590082, 'n_estimators': 292}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:30:52,144] Trial 71 finished with value: 0.36030620311493206 and parameters: {'booster': 'dart', 'lambda': 3.234400240803173e-05, 'alpha': 0.3324510256562358, 'max_depth': 7, 'subsample': 0.6878654571834667, 'colsample_bytree': 0.9992391260062469, 'learning_rate': 0.0286092983724264, 'n_estimators': 287}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:31:06,463] Trial 72 finished with value: 0.371583099735382 and parameters: {'booster': 'dart', 'lambda': 3.231975419374768e-05, 'alpha': 0.707758080447138, 'max_depth': 7, 'subsample': 0.6844942136097877, 'colsample_bytree': 0.95640639838841, 'learning_rate': 0.021439461816843763, 'n_estimators': 279}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:31:22,009] Trial 73 finished with value: 0.36408975803688787 and parameters: {'booster': 'dart', 'lambda': 0.0002974662824493616, 'alpha': 0.30999306976562363, 'max_depth': 8, 'subsample': 0.6272358037932059, 'colsample_bytree': 0.917227524659223, 'learning_rate': 0.029692782689596946, 'n_estimators': 283}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:31:34,565] Trial 74 finished with value: 2.3778749246031183 and parameters: {'booster': 'dart', 'lambda': 0.00011521268579320606, 'alpha': 0.16543793595710804, 'max_depth': 6, 'subsample': 0.8300803019711315, 'colsample_bytree': 0.978843508840919, 'learning_rate': 0.006696449006960822, 'n_estimators': 270}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:31:49,742] Trial 75 finished with value: 0.3616534823097596 and parameters: {'booster': 'dart', 'lambda': 1.0041705741202753e-06, 'alpha': 0.30637102899004187, 'max_depth': 7, 'subsample': 0.8572672892446245, 'colsample_bytree': 0.9388607452532212, 'learning_rate': 0.025737360566411408, 'n_estimators': 291}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:32:01,551] Trial 76 finished with value: 0.3609228716321188 and parameters: {'booster': 'dart', 'lambda': 6.416628068884689e-05, 'alpha': 0.03379963906591768, 'max_depth': 8, 'subsample': 0.9450880266510391, 'colsample_bytree': 0.8521004985236015, 'learning_rate': 0.03567093912249936, 'n_estimators': 265}. Best is trial 39 with value: 0.3581119118212429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:32:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:32:01,895] Trial 77 finished with value: 0.982001479791656 and parameters: {'booster': 'gblinear', 'lambda': 2.275057696880392e-06, 'alpha': 0.09143819394747513, 'max_depth': 6, 'subsample': 0.9009856276707946, 'colsample_bytree': 0.8873587278216295, 'learning_rate': 0.01812628862011524, 'n_estimators': 174}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:32:06,384] Trial 78 finished with value: 0.3699288841251913 and parameters: {'booster': 'dart', 'lambda': 2.223721998195954e-05, 'alpha': 0.01733805771126235, 'max_depth': 9, 'subsample': 0.5520278568158997, 'colsample_bytree': 0.9983621629623924, 'learning_rate': 0.06520578532930733, 'n_estimators': 273}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:32:12,329] Trial 79 finished with value: 0.3592552133727836 and parameters: {'booster': 'dart', 'lambda': 1.0969789588438586e-05, 'alpha': 5.39522157983236e-08, 'max_depth': 7, 'subsample': 0.7286688141078844, 'colsample_bytree': 0.9167143024113233, 'learning_rate': 0.05198047799029482, 'n_estimators': 285}. Best is trial 39 with value: 0.3581119118212429.\n",
      "[I 2023-12-26 16:32:18,838] Trial 80 finished with value: 0.35732193241380666 and parameters: {'booster': 'dart', 'lambda': 5.65247063787582e-06, 'alpha': 2.840357354246965e-07, 'max_depth': 7, 'subsample': 0.7266510810953657, 'colsample_bytree': 0.9230891653783706, 'learning_rate': 0.04986793154009173, 'n_estimators': 244}. Best is trial 80 with value: 0.35732193241380666.\n",
      "[I 2023-12-26 16:32:24,529] Trial 81 finished with value: 0.35613359086045393 and parameters: {'booster': 'dart', 'lambda': 6.744450302482755e-06, 'alpha': 2.9555663371045144e-08, 'max_depth': 7, 'subsample': 0.7789321898596863, 'colsample_bytree': 0.9238087757922164, 'learning_rate': 0.05339206544212388, 'n_estimators': 261}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:32:29,444] Trial 82 finished with value: 0.36219369840404214 and parameters: {'booster': 'dart', 'lambda': 2.855453958880174e-07, 'alpha': 4.163391897747159e-08, 'max_depth': 7, 'subsample': 0.782364005342871, 'colsample_bytree': 0.9456444275872737, 'learning_rate': 0.052941985000165594, 'n_estimators': 246}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:32:32,453] Trial 83 finished with value: 0.3630433786350843 and parameters: {'booster': 'dart', 'lambda': 3.175796466440322e-06, 'alpha': 7.502962972375626e-08, 'max_depth': 7, 'subsample': 0.7207170658721818, 'colsample_bytree': 0.9167184416608747, 'learning_rate': 0.07791608541738419, 'n_estimators': 254}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:32:37,228] Trial 84 finished with value: 0.3638667955736048 and parameters: {'booster': 'dart', 'lambda': 6.332482209397657e-06, 'alpha': 6.729988028403454e-08, 'max_depth': 6, 'subsample': 0.7539445109788626, 'colsample_bytree': 0.8175014407972749, 'learning_rate': 0.05934233068068519, 'n_estimators': 258}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:32:44,056] Trial 85 finished with value: 0.36344973124325547 and parameters: {'booster': 'dart', 'lambda': 1.3564380967070383e-06, 'alpha': 2.674372153000305e-07, 'max_depth': 7, 'subsample': 0.8122747125741729, 'colsample_bytree': 0.9057326047785966, 'learning_rate': 0.046846804173942914, 'n_estimators': 234}. Best is trial 81 with value: 0.35613359086045393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:32:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-26 16:32:44,549] Trial 86 finished with value: 0.4866046320276172 and parameters: {'booster': 'gblinear', 'lambda': 0.002926086150138653, 'alpha': 2.253453504224915e-08, 'max_depth': 6, 'subsample': 0.8571989957515808, 'colsample_bytree': 0.9328362849063314, 'learning_rate': 0.05548917028479323, 'n_estimators': 278}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:32:46,500] Trial 87 finished with value: 0.367554754198414 and parameters: {'booster': 'dart', 'lambda': 8.796758109991034e-07, 'alpha': 1.475626314549499e-07, 'max_depth': 7, 'subsample': 0.7309522187103643, 'colsample_bytree': 0.8436167518682414, 'learning_rate': 0.08881092275910185, 'n_estimators': 260}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:32:53,433] Trial 88 finished with value: 0.3606212627615558 and parameters: {'booster': 'dart', 'lambda': 5.401879706478306e-06, 'alpha': 1.3950981091630666e-06, 'max_depth': 7, 'subsample': 0.7782330163873865, 'colsample_bytree': 0.9706195087768662, 'learning_rate': 0.04308808021752932, 'n_estimators': 239}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:32:59,202] Trial 89 finished with value: 0.36323599287908376 and parameters: {'booster': 'dart', 'lambda': 0.0007720895625760697, 'alpha': 4.8185232232635735e-06, 'max_depth': 6, 'subsample': 0.5306262814534771, 'colsample_bytree': 0.8808813200557474, 'learning_rate': 0.049053057490629215, 'n_estimators': 265}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:33:00,419] Trial 90 finished with value: 0.36653448070480266 and parameters: {'booster': 'gbtree', 'lambda': 0.15483013903832402, 'alpha': 2.2496863739259736e-08, 'max_depth': 7, 'subsample': 0.48524913463988806, 'colsample_bytree': 0.9135732870167559, 'learning_rate': 0.06322160963988385, 'n_estimators': 223}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:33:08,984] Trial 91 finished with value: 0.35752358041397514 and parameters: {'booster': 'dart', 'lambda': 3.990723089677484e-05, 'alpha': 3.680628702498277e-08, 'max_depth': 7, 'subsample': 0.6867446882818172, 'colsample_bytree': 0.9713121747759715, 'learning_rate': 0.03930325604121983, 'n_estimators': 286}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:33:21,484] Trial 92 finished with value: 0.3601058521553806 and parameters: {'booster': 'dart', 'lambda': 1.3996742020813034e-05, 'alpha': 5.143275995901123e-07, 'max_depth': 7, 'subsample': 0.7467745242849761, 'colsample_bytree': 0.9715046546777835, 'learning_rate': 0.03320310266505288, 'n_estimators': 275}. Best is trial 81 with value: 0.35613359086045393.\n",
      "[I 2023-12-26 16:33:35,824] Trial 93 finished with value: 0.3558615060048561 and parameters: {'booster': 'dart', 'lambda': 1.620266765011867e-05, 'alpha': 5.635046283951203e-07, 'max_depth': 7, 'subsample': 0.7103084548037503, 'colsample_bytree': 0.9679218656115167, 'learning_rate': 0.03883120762643073, 'n_estimators': 275}. Best is trial 93 with value: 0.3558615060048561.\n",
      "[I 2023-12-26 16:33:43,578] Trial 94 finished with value: 0.3606014210285118 and parameters: {'booster': 'dart', 'lambda': 5.0864735584205464e-05, 'alpha': 3.8554387245271635e-08, 'max_depth': 7, 'subsample': 0.7086474716620372, 'colsample_bytree': 0.9475628564613964, 'learning_rate': 0.04035822375999649, 'n_estimators': 282}. Best is trial 93 with value: 0.3558615060048561.\n",
      "[I 2023-12-26 16:33:50,439] Trial 95 finished with value: 0.36401115332019934 and parameters: {'booster': 'dart', 'lambda': 2.1655789880674924e-05, 'alpha': 5.367563258151449e-07, 'max_depth': 7, 'subsample': 0.8981802837573362, 'colsample_bytree': 0.9337060281313556, 'learning_rate': 0.05340304011343861, 'n_estimators': 253}. Best is trial 93 with value: 0.3558615060048561.\n",
      "[I 2023-12-26 16:34:05,241] Trial 96 finished with value: 0.6833059177224494 and parameters: {'booster': 'dart', 'lambda': 8.440674967237196e-06, 'alpha': 1.0164513552539704e-08, 'max_depth': 7, 'subsample': 0.6517241722665267, 'colsample_bytree': 0.31948575896416376, 'learning_rate': 0.03810690269588411, 'n_estimators': 263}. Best is trial 93 with value: 0.3558615060048561.\n",
      "[I 2023-12-26 16:34:06,179] Trial 97 finished with value: 0.3616133430218282 and parameters: {'booster': 'gbtree', 'lambda': 8.736681455190804e-05, 'alpha': 2.0974907027899847e-08, 'max_depth': 6, 'subsample': 0.45260812601410105, 'colsample_bytree': 0.8585664228680489, 'learning_rate': 0.07166991090408024, 'n_estimators': 272}. Best is trial 93 with value: 0.3558615060048561.\n",
      "[I 2023-12-26 16:34:07,997] Trial 98 finished with value: 0.5094974653252727 and parameters: {'booster': 'dart', 'lambda': 2.680298951810921e-06, 'alpha': 1.2461805755635438e-07, 'max_depth': 7, 'subsample': 0.8380640954524836, 'colsample_bytree': 0.8925843902475832, 'learning_rate': 0.0449991937201172, 'n_estimators': 83}. Best is trial 93 with value: 0.3558615060048561.\n",
      "[I 2023-12-26 16:34:21,474] Trial 99 finished with value: 0.3606728722679017 and parameters: {'booster': 'dart', 'lambda': 4.004258270127143e-06, 'alpha': 2.0406435653335107e-06, 'max_depth': 6, 'subsample': 0.5743358612403683, 'colsample_bytree': 0.7417027446548838, 'learning_rate': 0.03194918416477058, 'n_estimators': 294}. Best is trial 93 with value: 0.3558615060048561.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.3558615060048561\n",
      "  Params: \n",
      "    booster: dart\n",
      "    lambda: 1.620266765011867e-05\n",
      "    alpha: 5.635046283951203e-07\n",
      "    max_depth: 7\n",
      "    subsample: 0.7103084548037503\n",
      "    colsample_bytree: 0.9679218656115167\n",
      "    learning_rate: 0.03883120762643073\n",
      "    n_estimators: 275\n"
     ]
    }
   ],
   "source": [
    "main_model = make_model_opt(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce419270-8750-4873-8350-2abf68617854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    booster: dart\n",
      "    lambda: 1.620266765011867e-05\n",
      "    alpha: 5.635046283951203e-07\n",
      "    max_depth: 7\n",
      "    subsample: 0.7103084548037503\n",
      "    colsample_bytree: 0.9679218656115167\n",
      "    learning_rate: 0.03883120762643073\n",
      "    n_estimators: 275\n"
     ]
    }
   ],
   "source": [
    "for key, value in main_model.best_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191085bd-714c-423b-810d-8bd2fc63da82",
   "metadata": {},
   "source": [
    "##### 일조율 제외 Best Parameters: OrderedDict([('colsample_bytree', 0.8828609870729205), ('gamma', 3), ('learning_rate', 0.10496395941543749), ('max_depth', 7), ('n_estimators', 1760), ('subsample', 0.16884742956302834)]) Cross-Validation Score: 0.38765606817069787\n",
    "\n",
    "##### 일사합 제외 Best Parameters: OrderedDict([('colsample_bytree', 0.5362786341288028), ('gamma', 2), ('learning_rate', 0.3362751905628303), ('max_depth', 3), ('n_estimators', 1819), ('subsample', 0.5797241067611393)]) Cross-Validation Score: 0.3882969067325051\n",
    "\n",
    "##### 일사합, 일조율, 강수량 제외 Best Parameters: OrderedDict([('colsample_bytree', 0.8725043517301599), ('gamma', 8), ('learning_rate', 0.05309603877595388), ('max_depth', 12), ('n_estimators', 457), ('subsample', 0.4391305289890164)]) Cross-Validation Score: 0.38738144746374126\n",
    "\n",
    "##### 일조율, 평균풍속 제외 Best Parameters: OrderedDict([('colsample_bytree', 0.6730910375307264), ('gamma', 1), ('learning_rate', 0.056228955612066124), ('max_depth', 10), ('n_estimators', 868), ('subsample', 0.9840445522115008)]) Cross-Validation Score: 0.39200003326815436\n",
    "\n",
    "##### 일조, 일사, 풍속 제외 Best Parameters: OrderedDict([('colsample_bytree', 0.17537998974601415), ('gamma', 3), ('learning_rate', 0.3143511882114139), ('max_depth', 4), ('n_estimators', 1980), ('subsample', 0.9483620738655641)])Cross-Validation Score: 0.4345285045763367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d3772a9-a95f-45b3-979f-80e38c62b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = [최고기온_model, 최저기온_model, 평균습도_model, 평균풍속_model, 일사합_model,\n",
    "      일조율_model, 강수량_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30aecc8a-5466-438a-8d80-a90fa4c4f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:47:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m, label in zip(mds, labels):\n",
    "    \n",
    "    X, y = base_select_label(data, labels, label)\n",
    "    \n",
    "    X['months'] = X['months'].astype(int)\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_data(X,y, 1095)\n",
    "    \n",
    "    model = xgb.XGBRegressor(**m.best_trial.params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "    \n",
    "    globals()[label+\"_md\"] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6062bd6-0d5d-4e30-bd10-4ade80379f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\",\"일조율\", \"강수량\"]]\n",
    "y = data[\"평균기온\"]\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_data(X,y, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96032aa7-83df-4679-b22e-9006372edf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=5.635046283951203e-07, base_score=0.5, booster='dart',\n",
       "             callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.9679218656115167, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='mae', gamma=0, gpu_id=-1,\n",
       "             grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', lambda=1.620266765011867e-05,\n",
       "             learning_rate=0.03883120762643073, max_bin=256,\n",
       "             max_cat_to_onehot=4, max_delta_step=0, max_depth=7, max_leaves=0,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=275, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=0, ...)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(**main_model.best_trial.params, eval_metric = \"mae\")\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9176cd27-27d4-4437-9819-3d0b4866423a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Study' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_88756\\2603622696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'최고기온'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m최고기온_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"years\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"months\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"days\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'최저기온'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m최저기온_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"years\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"months\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"days\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'평균습도'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m평균습도_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"years\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"months\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"days\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'평균풍속'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m평균풍속_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"years\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"months\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"days\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# X_test['일사합'] = 일사합_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Study' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "X_test['최고기온'] = 최고기온_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['최저기온'] = 최저기온_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['평균습도'] = 평균습도_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['평균풍속'] = 평균풍속_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "# X_test['일사합'] = 일사합_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['일조율'] = 일조율_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['강수량'] = 강수량_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b70410bd-d6a9-4ef5-9fd2-d77c948bc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['최고기온'] = 최고기온_md.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['최저기온'] = 최저기온_md.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['평균습도'] = 평균습도_md.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['평균풍속'] = 평균풍속_md.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "# X_test['일사합'] = 일사합_md.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['일조율'] = 일조율_md.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['강수량'] = 강수량_md.predict(X_test[[\"years\", \"months\", \"days\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1c55e75-7b1d-481d-b65f-cf49aa48c0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5380074480135146\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(mae)\n",
    "\n",
    "## 7개 : 2.6142990210754413\n",
    "## 일조율 제외 : 2.517694694352885\n",
    "## 일사합 제외 : 2.504838254349179\n",
    "## 일사합, 일조율, 강수량 제외 : 2.4861543731534317\n",
    "## 일조율, 평균풍속 제외 : 2.515234800046437\n",
    "## 일사합, 일조율, 풍속 제외 : 2.4652675723866238\n",
    "## 강수량 제외 : 2.5520137255893993\n",
    "## 일사/일조 제외 : 2.5530409243228296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e907ce5-6d96-4309-94a4-a0d28f10feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4652675723866238\n"
     ]
    }
   ],
   "source": [
    "y_pred = main_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87ebd30d-aabf-4377-a300-fb0e7f518305",
   "metadata": {},
   "outputs": [],
   "source": [
    "forms = summit_form.copy()\n",
    "forms.일시 = pd.to_datetime(forms.일시)\n",
    "forms['days'] = forms.일시.dt.day\n",
    "forms['months'] = forms.일시.dt.month\n",
    "forms['years']= forms.일시.dt.year\n",
    "forms.drop(['일시','평균기온'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aecb9383-905e-4f8b-97a3-9e1686b65684",
   "metadata": {},
   "outputs": [],
   "source": [
    "forms['최고기온'] = 최고기온_model.best_estimator_.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['최저기온'] = 최저기온_model.best_estimator_.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['평균습도'] = 평균습도_model.best_estimator_.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['평균풍속'] = 평균풍속_model.best_estimator_.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "# forms['일사합'] = 일사합_model.best_estimator_.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['일조율'] = 일조율_model.best_estimator_.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['강수량'] = 강수량_model.best_estimator_.predict(forms[[\"years\", \"months\", \"days\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a00f689e-9127-4b73-9347-0295fdba87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forms['최고기온'] = 최고기온_md.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['최저기온'] = 최저기온_md.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['평균습도'] = 평균습도_md.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['평균풍속'] = 평균풍속_md.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "# forms['일사합'] = 일사합_md.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['일조율'] = 일조율_md.predict(forms[[\"years\", \"months\", \"days\"]])\n",
    "forms['강수량'] = 강수량_md.predict(forms[[\"years\", \"months\", \"days\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93d2160e-654a-422b-895d-f864573e59a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/mainmodel(풍속_일조_일사_제외)_1.joblib']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# joblib.dump(최고기온_model, \"./models/최고기온_1.joblib\")\n",
    "# joblib.dump(최저기온_model, \"./models/최저기온_1.joblib\")\n",
    "# joblib.dump(평균습도_model, \"./models/평균습도_1.joblib\")\n",
    "joblib.dump(main_model, \"./models/mainmodel(풍속_일조_일사_제외)_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e36a53cb-4600-4626-89c2-1081bcc27250",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model.predict(forms)\n",
    "\n",
    "summit_form[\"평균기온\"] = answer\n",
    "\n",
    "\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbee16fb-4c6d-4832-aed7-cbdaa26f1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "summit_form.to_csv(f\"./answer/xgb_6vars_일사제외_전체_opuna.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a0c22c-d467-438f-9dc3-2c1f9b7ac40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = joblib.load(\"./models/mainmodel(일사합제외)_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d407dd6b-8fc4-40c3-93de-488e94cf8b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bytree', 0.5362786341288028),\n",
       "             ('gamma', 2),\n",
       "             ('learning_rate', 0.3362751905628303),\n",
       "             ('max_depth', 3),\n",
       "             ('n_estimators', 1819),\n",
       "             ('subsample', 0.5797241067611393)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ae7799c-b624-47b2-b548-5d1d558db085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\",\"일사합\", \"일조율\", \"강수량\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\",\"일사합\",\"강수량\"]]\n",
    "X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"평균풍속\", \"일조율\", \"강수량\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\",\"일사합\",\"강수량\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균풍속\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\", \"평균습도\", \"일조율\", \"강수량\"]]\n",
    "# X = data[[\"years\", \"months\", \"days\",\"최고기온\", \"최저기온\",\"평균풍속\",\"일조율\", \"강수량\"]]\n",
    "y = data[\"평균기온\"]\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_data(X,y, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6c107731-e6a7-45cd-9c90-76bd026c36c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1,\n",
       "             colsample_bytree=0.5362786341288028, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=2, gpu_id=-1,\n",
       "             grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.3362751905628303,\n",
       "             max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=3,\n",
       "             max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1819, n_jobs=-1,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", **bm.best_params_, n_jobs = -1, random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1fea443b-f15e-4afe-8bdf-24f2ba285fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['최고기온'] = 최고기온_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['최저기온'] = 최저기온_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['평균습도'] = 평균습도_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['평균풍속'] = 평균풍속_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "# X_test['일사합'] = 일사합_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['일조율'] = 일조율_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])\n",
    "X_test['강수량'] = 강수량_model.best_estimator_.predict(X_test[[\"years\", \"months\", \"days\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c7d0145-37b3-4e20-a4ea-fa3f101d60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5299242353878197\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47645607-ef74-4a17-bfd6-5829bbee8a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diquest",
   "language": "python",
   "name": "diquest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
